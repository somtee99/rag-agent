{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDbRWyvFguRc"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/en-us/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8U3dZ6VIZEUn"
   },
   "source": [
    "<br>\n",
    "\n",
    "# <font color=\"#76b900\" style=\"text-align:center;\">**Notebook 6.4:** Semantic Guardrailing</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "This notebook is a direct continuation of the material in **Notebook 6: Embedding Models and Semantic Reasoning**. However, due to its length and deviation from the main topic, it has been sectioned off into its own notebook.\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Environment Setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mo36Q8zRZ5i_"
   },
   "outputs": [],
   "source": [
    "## Necessary for Colab, not necessary for course environment\n",
    "# %pip install -qq langchain langchain-nvidia-ai-endpoints gradio\n",
    "\n",
    "import os\n",
    "os.environ[\"NVIDIA_API_KEY\"] = \"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\"\n",
    "\n",
    "## If you encounter a typing-extensions issue, restart your runtime and try again\n",
    "# from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "# ChatNVIDIA.get_available_models()\n",
    "\n",
    "from functools import partial\n",
    "from rich.console import Console\n",
    "from rich.style import Style\n",
    "from rich.theme import Theme\n",
    "\n",
    "console = Console()\n",
    "base_style = Style(color=\"#76B900\", bold=True)\n",
    "pprint = partial(console.print, style=base_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "# NVIDIAEmbeddings.get_available_models()\n",
    "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\")\n",
    "\n",
    "# ChatNVIDIA.get_available_models()\n",
    "instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x22b-instruct-v0.1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjP76N4o1bUi"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 4: [Advanced Exercise]** Embeddings For Semantic Guardrails\n",
    "\n",
    "In the next notebook, we will use higher-level utilities to take our embedding model and use it under the hood. Before then, there are several essential concepts that we can explore while the raw methods are still fresh!\n",
    "\n",
    "Specifically, we can use it as a backbone for a critical component of productionalized models: **semantic guardrailing**. Specifically, we can use the embeddings to filter out messages that are unlikely to be useful (or are actively harmful) for our chatbot to answer!\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Advantage Over Autoregression-Guided Filtering**\n",
    "\n",
    "You may recall from the previous notebooks that we can use our LLMs to facilitate complex internal reasoning, so why not filter with that? Specifically, you may be jumping the idea of asking an LLM to judge the question and then branch using a `RunnableBranch.` In truth, you can definitely do that, but that system has some hard pros and cons that need further consideration:\n",
    "\n",
    "> **Pros:** It is relatively quick and easy to prompt engineer your internal system to restrict the progression of dialog. You can even develop a routine that takes examples of good and bad questions and generates a single compact prompt that consistently returns \"Good\" or \"Bad\" finite states.\n",
    ">\n",
    "> **Cons:** Using autoregressive routing usually comes with a handful of latency or resource overhead that might not be acceptable. For example, you may want to integrate a semantic guardrail mechanism behind the scenes that both prevents harmful outputs and steers problematic inputs toward safe and predictable directions. Your autoregressive options are as follows:\n",
    "> - **You can use a relatively small instruction-tuned model to function as a zero-shot classifier and hope for its performance to stay consistent** To facilitate this, you may also need to convert the inputs into a canonical (standard) form for which your model performs optimally.\n",
    "> - **You can also fine-tune a small autoregressive LLM to work well for your task.** You'll have to do some synthetic data curation and might need to spend some extra computing budget for a one-time fine-tuning cost, but this should at least allow a smaller model to mimic the performance of a larger prompt-engineered model by default.\n",
    "\n",
    "While these options are fine, this specific use case can be nicely approached with a decent embedding model, some data curation, and a recollection of fundamental deep learning ideas.\n",
    "\n",
    "**Specifically, we can use an embedding model as a language backbone and can then train a classifier on top of it to predict a probability**. We will explore this idea and address new challenges as they come up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vYtuwTG1sBl"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### **Task 1: Generate Synthetic Data.**\n",
    "\n",
    "To start making a semantic guardrail, we obviously need to start out with some goals.\n",
    "\n",
    "- **Assumption:** Let's say we'd like to make an NVIDIA Chatbot that should primarily respond to discuss technology and company-relevant details! You may think that this is a pretty narrow-minded chatbot definition with some obvious pitfalls, and you would be totally correct! Still, it's a fun starting point, and the resulting artifacts will be conceptually easy to extend for more realistic problem formulations!\n",
    "\n",
    "- **Plan of Action**: To help identify what kinds of entries we're dealing with, it's a good idea to generate some representative inputs to define what are *good* and *poor* inputs to respond to. We can then see how our embedding model treats these examples and engineer a solution accordingly.\n",
    "\n",
    "Unfortunately, we don't have any real data with us, so it looks like synthetic generation will have to do! As an exercise, generate some representative good and poor examples that you can use for your downstream guardrail fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "f917fSAQ1m3x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasonable NVIDIA Responses:\n",
      "User: Can you tell me about the latest NVIDIA technology in deep learning?\n",
      "\n",
      "User: I'm interested in learning about NVIDIA's research in the field of natural language processing. Can you provide some information?\n",
      "\n",
      "User: How does NVIDIA's GPU technology enhance gaming experiences?\n",
      "\n",
      "User: Can you explain how NVIDIA's language modeling techniques work?\n",
      "\n",
      "User: I've heard about NVIDIA's contributions to autonomous vehicles. Can you give me more details?\n",
      "\n",
      "User: How does NVIDIA's technology support the development of artificial intelligence?\n",
      "\n",
      "User: Can you tell me about any recent partnerships or collaborations that NVIDIA has been involved in?\n",
      "\n",
      "User: I'm interested in learning about NVIDIA's role in the field of high performance computing. Can you provide some information?\n",
      "\n",
      "User: Can you explain the benefits of using NVIDIA's DGX systems for data science and AI research?\n",
      "\n",
      "User: How does NVIDIA's technology contribute to the field of computer vision?\n",
      "\n",
      "Reasonable non-NVIDIA Responses:\n",
      "User: Can you explain how machine learning algorithms have improved graphics in video games?\n",
      "They can learn from large datasets, predicting and generating highly detailed graphics in real-time.\n",
      "User: How does natural language processing impact conversational AI research?\n",
      "NLP allows AI systems to understand, interpret, and generate human language, enabling them to engage in meaningful conversations with users. It involves various techniques like sentiment analysis, topic modeling, and machine translation, all of which contribute to creating more intelligent and responsive AI assistants.\n",
      "\n",
      "Irrelevant Responses:\n",
      "\"Who is the current CEO of NVIDIA and what is their favorite color?\"\n",
      "\"Can you recommend a good recipe for cooking salmon tonight?\"\n",
      "\"How many points did Lebron James score in last night's basketball game?\"\n",
      "\"What is the best way to invest my money in the stock market?\"\n",
      "\"Can you help me find a good movie to watch on Netflix tonight?\"\n",
      "\"What are the symptoms of the flu and should I see a doctor?\"\n",
      "\"Can you give me directions to the nearest gas station?\"\n",
      "\"What is the meaning of life?\"\n",
      "\"Can you tell me a joke to make me laugh?\"\n",
      "\"What is the weather like tomorrow and should I bring an umbrella?\"\n",
      "\n",
      "Harmful non-NVIDIA\n",
      "\"Who makes the better chips, NVIDIA or AMD, and how do their CEOs' personal lives compare?\"\n",
      "\n",
      "It is not appropriate for a chatbot to make subjective assessments or to delve into personal matters.\n",
      "\n",
      "\"Can you tell me a joke about Intel processors being slow and unreliable, and then explain why that stereotype is untrue?\"\n",
      "\n",
      "It is not appropriate for a chatbot to tell jokes that are intended to belittle or disparage any product or company.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import ChatMessage\n",
    "from operator import itemgetter\n",
    "\n",
    "## Useful method for mistral, which is currently tuned to output numbered outputs\n",
    "def EnumParser(*idxs):\n",
    "    '''Method that pulls out values from a mistral model that outputs numbered entries'''\n",
    "    idxs = idxs or [slice(0, None, 1)]\n",
    "    entry_parser = lambda v: v if ('. ' not in v) else v[v.index('. ')+2:]\n",
    "    out_lambda = lambda x: [entry_parser(v).strip() for v in x.split(\"\\n\")]\n",
    "    return StrOutputParser() | RunnableLambda(lambda x: itemgetter(*idxs)(out_lambda(x)))\n",
    "\n",
    "instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\") | EnumParser()\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "gen_prompt = {'input' : lambda x:x} | ChatPromptTemplate.from_template(\n",
    "    \"Please generate 2 representative conversations that would be {input}.\"\n",
    "    \" Make sure all of the questions are very different in phrasing and content.\"\n",
    "    \" Do not respond to the questions; just list them. Make sure all of your outputs are numbered.\"\n",
    "    \" Example Response: 1. <question>\\n2. <question>\\n3. <question>\\n...\"\n",
    ")\n",
    "\n",
    "## Some that directly reference NVIDIA\n",
    "responses_1 = (gen_prompt | instruct_llm).invoke(\n",
    "    \" reasonable for an NVIDIA document chatbot to be able to answer.\"\n",
    "    \" Vary the context to technology, research, deep learning, language modeling, gaming, etc.\"\n",
    ")\n",
    "print(\"Reasonable NVIDIA Responses:\", *responses_1, \"\", sep=\"\\n\")\n",
    "\n",
    "## And some that do not\n",
    "responses_2 = (gen_prompt | instruct_llm).invoke(\n",
    "    \" be reasonable for a tech document chatbot to be able to answer. Make sure to vary\"\n",
    "    \" the context to technology, research, gaming, language modeling, graphics, etc.\"\n",
    ")\n",
    "print(\"Reasonable non-NVIDIA Responses:\", *responses_2, \"\", sep=\"\\n\")\n",
    "\n",
    "## Feel free to try your own generations instead\n",
    "responses_3 = (gen_prompt | instruct_llm).invoke(\n",
    "    \"unreasonable for an NVIDIA document chatbot to answer,\"\n",
    "    \" as it is irrelevant and will not be useful to answer (though not inherently harmful).\"\n",
    ")\n",
    "print(\"Irrelevant Responses:\", *responses_3, \"\", sep=\"\\n\")\n",
    "\n",
    "responses_4 = (gen_prompt | instruct_llm).invoke(\n",
    "    \"unreasonable for a chatbot (NVIDIA's, AMD's, Intels, or Generally) to answer,\"\n",
    "    \" as an automated response will either be overly insensitive or offensive.\"\n",
    ")\n",
    "print(\"Harmful non-NVIDIA\", *responses_4, \"\", sep=\"\\n\")\n",
    "\n",
    "## Feel free to try your own generations instead\n",
    "\n",
    "good_responses = responses_1 + responses_2\n",
    "poor_responses = responses_3 + responses_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['User: Can you tell me about the latest NVIDIA technology in deep learning?',\n",
       " '',\n",
       " \"User: I'm interested in learning about NVIDIA's research in the field of natural language processing. Can you provide some information?\",\n",
       " '',\n",
       " \"User: How does NVIDIA's GPU technology enhance gaming experiences?\",\n",
       " '',\n",
       " \"User: Can you explain how NVIDIA's language modeling techniques work?\",\n",
       " '',\n",
       " \"User: I've heard about NVIDIA's contributions to autonomous vehicles. Can you give me more details?\",\n",
       " '',\n",
       " \"User: How does NVIDIA's technology support the development of artificial intelligence?\",\n",
       " '',\n",
       " 'User: Can you tell me about any recent partnerships or collaborations that NVIDIA has been involved in?',\n",
       " '',\n",
       " \"User: I'm interested in learning about NVIDIA's role in the field of high performance computing. Can you provide some information?\",\n",
       " '',\n",
       " \"User: Can you explain the benefits of using NVIDIA's DGX systems for data science and AI research?\",\n",
       " '',\n",
       " \"User: How does NVIDIA's technology contribute to the field of computer vision?\",\n",
       " 'User: Can you explain how machine learning algorithms have improved graphics in video games?',\n",
       " 'They can learn from large datasets, predicting and generating highly detailed graphics in real-time.',\n",
       " 'User: How does natural language processing impact conversational AI research?',\n",
       " 'NLP allows AI systems to understand, interpret, and generate human language, enabling them to engage in meaningful conversations with users. It involves various techniques like sentiment analysis, topic modeling, and machine translation, all of which contribute to creating more intelligent and responsive AI assistants.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-Y6oDOU3IBs"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Task 2: Generate More Embeddings (and faster)**\n",
    "\n",
    "Once you're happy with the synthetic data, it's time to embed them all into semantic vectors. Our previous technique of embedding documents using the synchronous `embed_query` and `embed_documents` methods is sufficient for smaller or more on-the-fly formulations. However, this presents an unnecessary bottleneck when we need to embed a large number of embeddings at once.\n",
    "\n",
    "In this section, we will use **asynchronous techniques** to allow multiple embedding operations to happen simultaneously! Of note, this is a more intermediate technique that frequently gets leveraged automatically behind the scenes. **It is *not* a source of infinite concurrency** and should be studied in more depth before manually integrating it into larger deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnoyZF_GOA-_"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### **Timing Solutions**\n",
    "\n",
    "The `%%time` utility does not work for asynchronous solutions in the notebook, so the following is a scope-based timing utility which should make our lives easier. Below, we define it and test out how long it takes to embed the first 10 documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "dS1w_JspL1VE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mExecuted in 0.72 seconds.\u001b[0m\n",
      "Shape: (1, 4096)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class Timer():\n",
    "    '''Useful timing utilities (%%time is great, but doesn't work for async)'''\n",
    "    def __enter__(self):\n",
    "      self.start = time.perf_counter()\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        elapsed = time.perf_counter() - self.start\n",
    "        print(\"\\033[1m\" + f\"Executed in {elapsed:0.2f} seconds.\" + \"\\033[0m\")\n",
    "\n",
    "with Timer():\n",
    "    good_embeds = [embedder.embed_query(x) for x in good_responses[:1]]\n",
    "\n",
    "print(\"Shape:\", np.array(good_embeds).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6t-cYwTLjEp"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### **Towards Asynchronous Embeddings**\n",
    "\n",
    "Notice how this embedding query takes a lot of time to execute. If we had raw access to our embedding model, we'd be able to access some easy speedup by batching our responses. However, the query router in the clouds is already doing this automatically and chooses to restrict users to single queries for fairness and homogeneity.\n",
    "\n",
    "In other words, it's not that the service can't embed faster, but rather that our code is waiting for every single embedding to happen *in series* for each `embed_query` command.\n",
    "\n",
    "When we need to embed a lot of documents all at once, it's generally a better idea to lodge all of the requests at once *asynchronously* and wait for the results to come in. If implemented correctly, this will greatly expedite your embedding process on the local end while having only a marginal impact on the LLM service (assuming that [**in-flight batching**](https://github.com/NVIDIA/TensorRT-LLM/blob/b777bd64750abf30ca7eda48e8b6ba3c5174aafd/docs/source/advanced/gpt-attention.md?plain=1#L137) is enforced by the query router, where multiple requests get stacked and fed in as batches through the neural network).\n",
    "\n",
    "We can test out the LangChain-standard `aembed_<...>` options to generate some **Coroutines**, which are processes intended for **concurrent** execution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "GfH8DWZ_P9Kk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mExecuted in 0.00 seconds.\u001b[0m\n",
      "<coroutine object Embeddings.aembed_query at 0x00000260468D89E0>\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    good_embed_gens = [embedder.aembed_query(query) for query in good_responses[:1]]\n",
    "print(good_embed_gens[0])\n",
    "\n",
    "## NOTE: When you define coroutines, you will want to either execute them or close them.\n",
    "##  Destroying an open coroutine object by overriding will throw a warning.\n",
    "for gen in good_embed_gens:\n",
    "    gen.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTVmua0DQKOU"
   },
   "source": [
    "They can be awaited individually using the `await` keyword or executed concurrently using something similar to the [`asyncio.gather`](https://docs.python.org/3/library/asyncio-task.html#id8) routine. With the later option, asyncio will execute all of these coroutines simultaneously and the responses will be aggregated, or **gathered**, when the last one finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "6iFdV_wVQP70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mExecuted in 0.62 seconds.\u001b[0m\n",
      "Shape: (1, 4096)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "with Timer():\n",
    "    tasks = [embedder.aembed_query(query) for query in good_responses[:1]]\n",
    "    good_embeds2 = await asyncio.gather(*tasks)\n",
    "\n",
    "print(\"Shape:\", np.array(good_embeds2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfDSmYs5QfYn"
   },
   "source": [
    "Whereas the previous non-async version showed how long it took to embed all of these responses *in series*, this new time reflects how long the process took *concurrently*, roughly correlating with the longest single embedding request.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **Limiting Concurrency**\n",
    "\n",
    "Though this system is significantly faster than our synchronous version, it's important to note that the concurrency can't be stacked infinitely! With enough tasks running concurrently, things can break, services can throttle you, and resources can be exhausted. In practice, it's a good idea to use some controlling structures to limit the maximum concurrency, for example using the asyncio **semaphore** structure (an async primitive to limit max concurrency):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqpULuawLxaU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mExecuted in 24.65 seconds.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from collections import abc\n",
    "from typing import Callable\n",
    "from functools import partial\n",
    "\n",
    "async def embed_with_semaphore(\n",
    "    text : str,\n",
    "    embed_fn : Callable,\n",
    "    semaphore : asyncio.Semaphore\n",
    ") -> abc.Coroutine:\n",
    "    async with semaphore:\n",
    "        return await embed_fn(text)\n",
    "\n",
    "## Making new embed method to limiting maximum concurrency\n",
    "embed = partial(\n",
    "    embed_with_semaphore,\n",
    "    embed_fn = embedder.aembed_query,\n",
    "    semaphore = asyncio.Semaphore(value=1)  ## <- feel free to play with value (1-0)\n",
    ")\n",
    "\n",
    "## This is once again a coroutine constructor, so should take marginal time\n",
    "tasks = [embed(query) for query in good_responses[:1]]\n",
    "\n",
    "with Timer():\n",
    "    good_embeds_3 = await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4096)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(good_embeds_3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84CXg5t5UUFB"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### **[Exercise] Embed The Rest of the Responses**\n",
    "\n",
    "Now that you've seen how to do this process, wrap up by embedding the rest of the documents using these new techniques. Try to restrict the concurrency to a reasonable amount (if it fails, you'll know about it) and see if you can make it comfortably fast.\n",
    "\n",
    "In our tests in the system's current state, we found 10 to be a sweet spot after which our concurrency benefits started to taper off. Keep that in mind as you select your values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Y4pEZUy3UpB4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okafo\\AppData\\Local\\Temp\\ipykernel_42844\\4028236548.py:14: RuntimeWarning: coroutine 'embed_with_semaphore' was never awaited\n",
      "  poor_tasks2 = [embed(query) for query in poor_responses[-1:]]\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mExecuted in 8.38 seconds.\u001b[0m\n",
      "Good Embeds Shape: (2, 4096)\n",
      "Poor Embeds Shape: (1, 4096)\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "## BEGIN TODO\n",
    "\n",
    "## Making new embed method to limiting maximum concurrency\n",
    "embed = partial(\n",
    "    embed_with_semaphore,\n",
    "    embed_fn = embedder.aembed_query,\n",
    "    semaphore = asyncio.Semaphore(value=10)  ## <- feel free to play with value (10 is best)\n",
    ")\n",
    "\n",
    "## Note, we found marginal benefit after value=10 in our tests...\n",
    "with Timer():\n",
    "    good_tasks2 = [embed(query) for query in good_responses[-2:]]\n",
    "    poor_tasks2 = [embed(query) for query in poor_responses[-1:]]\n",
    "    good_embeds2 = await asyncio.gather(*good_tasks2)\n",
    "    poor_embeds2 = await asyncio.gather(*poor_tasks2)\n",
    "\n",
    "print(\"Good Embeds Shape:\", np.array(good_embeds2).shape)\n",
    "print(\"Poor Embeds Shape:\", np.array(poor_embeds2).shape)\n",
    "\n",
    "## END TODO\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_embeds = good_embeds + good_embeds2\n",
    "poor_embeds = poor_embeds + poor_embeds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['User: Can you tell me about the latest NVIDIA technology in deep learning?']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_responses[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Who is the current CEO of NVIDIA and what is their favorite color?\"',\n",
       " '\"Can you recommend a good recipe for cooking salmon tonight?\"']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poor_responses[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARwqB2Q3YupA"
   },
   "source": [
    "### **Task 3: Confirming Semantic Density**\n",
    "\n",
    "Our reason for generating these embeddings hinges on the assumption that they would be useful for semantic filtering. To help confirm this, we can use some classical machine learning approaches like [**principal component analysis (PCA)**](https://en.wikipedia.org/wiki/Principal_component_analysis) or [**t-distributed stochastic neighbor embedding (t-SNE)**](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) for dimensionality reduction. These techniques essentially transform high-dimensional data into lower-dimensional representations while trying to keep the important statistical properties intact. They're great for visualizing semantic clusters, so let's see what happens when we perform it on our embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcGKEDY4bpGN"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "# Combine all groups into a single dataset\n",
    "embeddings = np.vstack([good_embeds, poor_embeds])\n",
    "\n",
    "# Build labels that actually match the number of embeddings\n",
    "n_good = len(good_embeds)\n",
    "n_poor = len(poor_embeds)\n",
    "labels = np.array([0]*n_good + [1]*n_poor)\n",
    "\n",
    "# Sanity check\n",
    "assert embeddings.shape[0] == labels.shape[0], f\"n_samples {embeddings.shape[0]} != n_labels {labels.shape[0]}\"\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_pca = pca.fit_transform(embeddings)\n",
    "\n",
    "# Perform t-SNE\n",
    "n_samples = embeddings.shape[0]\n",
    "# choose a safe perplexity: at least 2, less than n_samples, typical upper bound 30\n",
    "perplexity = min(30, max(2, (n_samples - 1) // 3))\n",
    "if perplexity >= n_samples:\n",
    "    raise ValueError(f\"Not enough samples for t-SNE (n_samples={n_samples}). Need perplexity < n_samples.\")\n",
    "tsne = TSNE(n_components=2, random_state=0, perplexity=perplexity)\n",
    "embeddings_tsne = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Plotting PCA\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(embeddings_pca[:, 0], embeddings_pca[:, 1], c=labels, cmap='viridis', label=labels)\n",
    "plt.title(\"PCA of Embeddings\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.colorbar(label='Group')\n",
    "\n",
    "# Plotting t-SNE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], c=labels, cmap='viridis', label=labels)\n",
    "plt.title(\"t-SNE of Embeddings\")\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "plt.colorbar(label='Group')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJolK9fOcH6y"
   },
   "source": [
    "<br>\n",
    "\n",
    "If everything went correctly, you should be seeing some pretty evident clustering of your responses. You will definitely want to consider many more examples and do some exhaustive checking in practice, but this is sufficient for us to work with.\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Task 4:** Training Our Classifier\n",
    "\n",
    "From these embeddings, we can train up a simple classifier that predicts whether an embedding is good or bad!\n",
    "\n",
    "Despite our CPU-bound environment assumptions, a simple two-layer network is likely to be sufficient for this use case since we're leveraging a strong embedding model backbone. Keep in mind that even if this process took longer or required more resources, it would still be easy to justify since we're accepting a one-time cost to train up a reusable component. The only slowdown that will really matter for the end-user is the inference speed (which will be very quick)!\n",
    "\n",
    "#### **Training a Deep Classifier**\n",
    "\n",
    "If you have a complex decision boundary and are comfortable with deep learning, you may be inclined to make a classifier with a framework like [Keras](https://keras.io/keras_3/). We can try out the following training routine, noting its compatibility with either Keras 2 or Keras 3. If you are unfamiliar with this framework, we'd recommend checking out the respective guides:\n",
    "\n",
    "- **[Keras 3.0 Functional API](https://keras.io/guides/functional_api/)**\n",
    "- **[Keras 3.0 Sequential Model](https://keras.io/guides/sequential_model/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "KRimBEHyKbLz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Keras for the first time\n",
      "\u001b[1mExecuted in 0.00 seconds.\u001b[0m\n",
      "Epoch 1/2\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 0.8810 - loss: 0.1476 - val_binary_accuracy: 1.0000 - val_loss: 5.2622e-16\n",
      "Epoch 2/2\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7303e-16 - val_binary_accuracy: 1.0000 - val_loss: 7.7821e-19\n",
      "\u001b[1mExecuted in 1.46 seconds.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    print(\"Importing Keras for the first time\")\n",
    "    import keras\n",
    "    from keras import layers\n",
    "\n",
    "def train_model_neural_network(class0, class1):\n",
    "    ## Classic deep learning training loop. If using this, train it to convergence\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(10, activation='tanh'),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    ## Since this network is so shallow and the embedding backbone is \"kept frozen\"\n",
    "    ##  a high learning rate should not overfit and will actually converge very quickly.\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = 1.0),\n",
    "        loss = [keras.losses.BinaryCrossentropy(from_logits=False)],\n",
    "        metrics = [keras.metrics.BinaryAccuracy()],\n",
    "    )\n",
    "    ## Since this uses stochastic gradient descent, we'll need to repeat this process\n",
    "\n",
    "    reps_per_batch = 64*5  ## <- repeat the dataset, effectively increasing \"epochs\" without printing too much\n",
    "    epochs = 2             ## <- one epoch should actually be sufficient; 2 to print out an updated training loss\n",
    "    x = np.array((class0 + class1) * reps_per_batch)\n",
    "    y = np.array(([0]*len(class0) + [1]*len(class1)) * reps_per_batch)\n",
    "    model.fit(x, y, epochs=epochs, batch_size=64, validation_split=.5)\n",
    "    return model\n",
    "\n",
    "with Timer():\n",
    "    model1 = train_model_neural_network(poor_embeds, good_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qODZQ2nSNrox"
   },
   "source": [
    "#### Fitting A Simpler Classifier\n",
    "\n",
    "Since the embedding model already has so much semantic density in its response, this is one of the places where you can effectively get away with a closed-form optimization solution (i.e., training is not required because we can compute a mathematical optimum with a fixed expression).\n",
    "\n",
    "Below is an even faster classification head fitting routine that uses standard logistic regression. You'll notice that its accuracy may not be quite as good, but it should still work well as long as your data is well-curated. Make sure that your accuracy is close to 100% for both training and validation to confirm that overfit is unlikely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "J76ncI-ceD6V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4096)\n",
      "Training Results: 0.6666666666666666\n",
      "Testing Results: 0.3333333333333333\n",
      "\u001b[1mExecuted in 0.02 seconds.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_logistic_regression(class0, class1):\n",
    "    ## Logistic regression version. Optimized mathematically using closed-form algorithm.\n",
    "    x = class0 + class1\n",
    "    y = [0] * len(class0) + [1] * len(class1)\n",
    "    x0, x1, y0, y1 = train_test_split(x, y, test_size=0.5, random_state=42)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(x0, y0)\n",
    "    print(np.array(x0).shape)\n",
    "    print(\"Training Results:\", model.score(x0, y0))\n",
    "    print(\"Testing Results:\", model.score(x1, y1))\n",
    "    return model\n",
    "\n",
    "with Timer():\n",
    "    model2 = train_logistic_regression(poor_embeds, good_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYlH257blLdG"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Task 5: [Exercise]** Integrating Into Our Chatbot\n",
    "\n",
    "Now that we have a classifier that we can attach to our embedding model, we can use it as part of our event loop with roughly the latency of a single embedding model query.\n",
    "\n",
    "We could set the system up to reject poor questions entirely, but this will greatly detriment the user experience. ***Perhaps a better strategy might be to use the classification to modify the system prompt to discourage the model from answering the user's question.***\n",
    "\n",
    "#### **Task:** Implement the `score_response` method as appropriate to filter the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "OxIiPuubnU3t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Agent ]: Hello! I'm your NVIDIA chat agent! Let me answer some questions!\n",
      "\n",
      "[ Agent ]: \n",
      "{'input': 'Hi', 'score': 0.6627152048475233}\n",
      "Hello. Welcome to NVIDIA. I'm here to help answer any questions you may have about our products, technologies, or innovations. What's on your mind? Are you interested in learning more about our graphics cards, AI computing, autonomous vehicles, or something else?\n",
      "\n",
      "\n",
      "[ Agent ]: \n",
      "{'input': 'Can you recommend a good recipe for cooking salmon tonight?', 'score': 0.666309963924127}\n",
      "At NVIDIA, we're passionate about accelerating innovation in various fields, including cooking. While our expertise lies in AI, graphics, and high-performance computing, I'd be happy to help you with a delicious salmon recipe.\n",
      "\n",
      "Here's a simple and mouth-watering recipe for Pan-Seared Salmon with Lemon and Herbs:\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "* 4 salmon fillets (6 oz each)\n",
      "* 2 lemons, sliced\n",
      "* 1/4 cup olive oil\n",
      "* 4 tbsp chopped fresh parsley\n",
      "* 2 tbsp chopped fresh dill\n",
      "* 2 cloves garlic, minced\n",
      "* Salt and pepper to taste\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Preheat your oven to 400F (200C).\n",
      "2. Line a baking sheet with aluminum foil or parchment paper.\n",
      "3. Place the salmon fillets on the prepared baking sheet.\n",
      "4. Drizzle the olive oil over the salmon, then sprinkle with parsley, dill, and garlic.\n",
      "5. Season with salt and pepper to taste.\n",
      "6. Place a lemon slice on top of each salmon fillet.\n",
      "7. Bake in the preheated oven for 12-15 minutes or until the salmon is cooked through.\n",
      "8. Remove from the oven and let it rest for a few minutes before serving.\n",
      "\n",
      "You can also add some NVIDIA-inspired flair to your dish by using a graphics card-themed presentation, such as arranging the lemon slices to resemble a GPU architecture or creating a pattern with the herbs to mimic the NVIDIA logo.\n",
      "\n",
      "Enjoy your delicious and healthy salmon dinner, and don't hesitate to reach out if you have any other questions or need further assistance!\n",
      "\n",
      "(By the way, have you considered using AI-powered cooking tools or apps to help with meal planning and recipe suggestions? NVIDIA's AI technology is being used in various applications, including cooking and food preparation. Let me know if you'd like to explore more!)\n",
      "\n",
      "\n",
      "[ Agent ]: \n",
      "{'input': 'Who is the current CEO of NVIDIA and what is their favorite color and what do they eat for salmon?', 'score': 0.6686635411473923}\n"
     ]
    },
    {
     "ename": "ConnectTimeout",
     "evalue": "HTTPSConnectionPool(host='integrate.api.nvidia.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002605C58A9C0>, 'Connection to integrate.api.nvidia.com timed out. (connect timeout=None)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:716\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    717\u001b[0m     conn,\n\u001b[0;32m    718\u001b[0m     method,\n\u001b[0;32m    719\u001b[0m     url,\n\u001b[0;32m    720\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    721\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    722\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    723\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    724\u001b[0m )\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:404\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1061\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1061\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connection.py:179\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout),\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPSConnection object at 0x000002605C58A9C0>, 'Connection to integrate.api.nvidia.com timed out. (connect timeout=None)')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\adapters.py:644\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 644\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    645\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    646\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    647\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    648\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    649\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    650\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    651\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    652\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    653\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    654\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    655\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    656\u001b[0m     )\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:802\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    800\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 802\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    803\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39me, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    804\u001b[0m )\n\u001b[0;32m    805\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\util\\retry.py:594\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    596\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='integrate.api.nvidia.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002605C58A9C0>, 'Connection to integrate.api.nvidia.com timed out. (connect timeout=None)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 88\u001b[0m\n\u001b[0;32m     85\u001b[0m history \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello! I\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm your NVIDIA chat agent! Let me answer some questions!\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m## Simulating the queueing of a streaming gradio interface, using python input\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m queue_fake_streaming_gradio(\n\u001b[0;32m     89\u001b[0m     chat_stream \u001b[38;5;241m=\u001b[39m chat_gen,\n\u001b[0;32m     90\u001b[0m     history \u001b[38;5;241m=\u001b[39m history\n\u001b[0;32m     91\u001b[0m )\n",
      "Cell \u001b[1;32mIn[72], line 78\u001b[0m, in \u001b[0;36mqueue_fake_streaming_gradio\u001b[1;34m(chat_stream, history, max_questions)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[ Agent ]: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m history_entry \u001b[38;5;241m=\u001b[39m [message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m chat_stream(message, history, return_buffer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(token, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     80\u001b[0m     history_entry[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m token\n",
      "Cell \u001b[1;32mIn[72], line 62\u001b[0m, in \u001b[0;36mchat_gen\u001b[1;34m(message, history, return_buffer)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat_gen\u001b[39m(message, history, return_buffer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     61\u001b[0m     buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m chat_chain\u001b[38;5;241m.\u001b[39mstream(message):\n\u001b[0;32m     63\u001b[0m         buffer \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m token\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m buffer \u001b[38;5;28;01mif\u001b[39;00m return_buffer \u001b[38;5;28;01melse\u001b[39;00m token\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:3650\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3643\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   3644\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   3645\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3648\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3649\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3650\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:3636\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3629\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   3630\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   3631\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3634\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3635\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3636\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[0;32m   3637\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[0;32m   3639\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m   3640\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3641\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:2372\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[1;34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   2370\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2371\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 2372\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mnext\u001b[39m, iterator)\n\u001b[0;32m   2373\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m   2374\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:3595\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[1;34m(self, inputs, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   3592\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3593\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[1;32m-> 3595\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\output_parsers\\transform.py:74\u001b[0m, in \u001b[0;36mBaseTransformOutputParser.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m     63\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[T]:\n\u001b[0;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transform the input into the output format.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m        The transformed output.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform, config, run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:2335\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[1;34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   2333\u001b[0m input_for_tracing, input_for_transform \u001b[38;5;241m=\u001b[39m tee(inputs, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m   2334\u001b[0m \u001b[38;5;66;03m# Start the input iterator to ensure the input Runnable starts before this one\u001b[39;00m\n\u001b[1;32m-> 2335\u001b[0m final_input: Optional[Input] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(input_for_tracing, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   2336\u001b[0m final_input_supported \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2337\u001b[0m final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\runnables\\base.py:1589\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1586\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[0;32m   1588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[1;32m-> 1589\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\language_models\\chat_models.py:522\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m input_messages \u001b[38;5;241m=\u001b[39m _normalize_messages(messages)\n\u001b[0;32m    521\u001b[0m run_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((_LC_ID_PREFIX, \u001b[38;5;28mstr\u001b[39m(run_manager\u001b[38;5;241m.\u001b[39mrun_id)))\n\u001b[1;32m--> 522\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(input_messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    524\u001b[0m         chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m run_id\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_nvidia_ai_endpoints\\chat_models.py:629\u001b[0m, in \u001b[0;36mChatNVIDIA._stream\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Allows streaming to model!\"\"\"\u001b[39;00m\n\u001b[0;32m    626\u001b[0m _, payload, extra_headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_inputs_and_payload(\n\u001b[0;32m    627\u001b[0m     messages, stop, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    628\u001b[0m )\n\u001b[1;32m--> 629\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mget_req_stream(\n\u001b[0;32m    630\u001b[0m     payload\u001b[38;5;241m=\u001b[39mpayload, extra_headers\u001b[38;5;241m=\u001b[39mextra_headers\n\u001b[0;32m    631\u001b[0m ):\n\u001b[0;32m    632\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_stream_chunk(response, run_manager)\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run_manager:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_nvidia_ai_endpoints\\_common.py:735\u001b[0m, in \u001b[0;36m_NVIDIAClient.get_req_stream\u001b[1;34m(self, payload, extra_headers)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_req_stream\u001b[39m(\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    723\u001b[0m     payload: \u001b[38;5;28mdict\u001b[39m,\n\u001b[0;32m    724\u001b[0m     extra_headers: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m {},\n\u001b[0;32m    725\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Dict]:\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    727\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer_url,\n\u001b[0;32m    728\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    732\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m: payload,\n\u001b[0;32m    733\u001b[0m     }\n\u001b[1;32m--> 735\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_session_fn()\u001b[38;5;241m.\u001b[39mpost(\n\u001b[0;32m    736\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__add_authorization(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_inputs)\n\u001b[0;32m    737\u001b[0m     )\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_raise(response)\n\u001b[0;32m    739\u001b[0m     call: _NVIDIAClient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_copy()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[1;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \n\u001b[0;32m    629\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\adapters.py:665\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[1;32m--> 665\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectTimeout\u001b[0m: HTTPSConnectionPool(host='integrate.api.nvidia.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002605C58A9C0>, 'Connection to integrate.api.nvidia.com timed out. (connect timeout=None)'))"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "from langchain_core.runnables.passthrough import RunnableAssign\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\")\n",
    "chat_llm = ChatNVIDIA(model=\"meta/llama-3.3-70b-instruct\") | StrOutputParser()\n",
    "instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x22b-instruct-v0.1\") | StrOutputParser()\n",
    "\n",
    "response_prompt = ChatPromptTemplate.from_messages([(\"system\", \"{system}\"), (\"user\", \"{input}\")])\n",
    "\n",
    "def RPrint(preface=\"\"):\n",
    "    def print_and_return(x, preface=\"\"):\n",
    "        print(f\"{preface}{x}\")\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
    "\n",
    "## \"Help them out\" system message\n",
    "good_sys_msg = (\n",
    "    \"You are an NVIDIA chatbot. Please answer their question while representing NVIDIA.\"\n",
    "    \"  Please help them with their question if it is ethical and relevant.\"\n",
    ")\n",
    "## Resist talking about this topic\" system message\n",
    "poor_sys_msg = (\n",
    "    \"You are an NVIDIA chatbot. Please answer their question while representing NVIDIA.\"\n",
    "    \"  Their question has been analyzed and labeled as 'probably not useful to answer as an NVIDIA Chatbot',\"\n",
    "    \"  so avoid answering if appropriate and explain your reasoning to them. Make your response as short as possible.\"\n",
    ")\n",
    "\n",
    "########################################################################################\n",
    "## BEGIN TODO\n",
    "\n",
    "def score_response(query):\n",
    "    ## TODO: embed the query and pass the embedding into your classifier\n",
    "    ## TODO: return the score for the response\n",
    "    return model2.predict_proba([embedder.embed_query(query)])[0][1]\n",
    "    \n",
    "## END TODO\n",
    "########################################################################################\n",
    "\n",
    "chat_chain = (\n",
    "    { 'input'  : (lambda x:x), 'score' : score_response }\n",
    "    | RPrint()\n",
    "    | RunnableAssign(dict(\n",
    "        system = RunnableBranch(\n",
    "            ## Switch statement syntax. First lambda that returns true triggers return of result\n",
    "            ((lambda d: d['score'] < 0.5), RunnableLambda(lambda x: poor_sys_msg)),\n",
    "            ## ... (more branches can also be specified)\n",
    "            ## Default branch. Will run if none of the others do\n",
    "            RunnableLambda(lambda x: good_sys_msg)\n",
    "        )\n",
    "    )) | response_prompt | chat_llm\n",
    ")\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "def chat_gen(message, history, return_buffer=True):\n",
    "    buffer = \"\"\n",
    "    for token in chat_chain.stream(message):\n",
    "        buffer += token\n",
    "        yield buffer if return_buffer else token\n",
    "\n",
    "def queue_fake_streaming_gradio(chat_stream, history = [], max_questions=8):\n",
    "\n",
    "    ## Mimic of the gradio initialization routine, where a set of starter messages can be printed off\n",
    "    for human_msg, agent_msg in history:\n",
    "        if human_msg: print(\"\\n[ Human ]:\", human_msg)\n",
    "        if agent_msg: print(\"\\n[ Agent ]:\", agent_msg)\n",
    "\n",
    "    ## Mimic of the gradio loop with an initial message from the agent.\n",
    "    for _ in range(max_questions):\n",
    "        message = input(\"\\n[ Human ]: \")\n",
    "        print(\"\\n[ Agent ]: \")\n",
    "        history_entry = [message, \"\"]\n",
    "        for token in chat_stream(message, history, return_buffer=False):\n",
    "            print(token, end='')\n",
    "            history_entry[1] += token\n",
    "        history += [history_entry]\n",
    "        print(\"\\n\")\n",
    "\n",
    "## history is of format [[User response 0, Bot response 0], ...]\n",
    "history = [[None, \"Hello! I'm your NVIDIA chat agent! Let me answer some questions!\"]]\n",
    "\n",
    "## Simulating the queueing of a streaming gradio interface, using python input\n",
    "queue_fake_streaming_gradio(\n",
    "    chat_stream = chat_gen,\n",
    "    history = history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################\n",
    "# ## Gradio components\n",
    "\n",
    "# chatbot = gr.Chatbot(value = [[None, \"Hello! I'm your NVIDIA chat agent! Let me answer some questions!\"]])\n",
    "# demo = gr.ChatInterface(chat_gen, chatbot=chatbot).queue()\n",
    "\n",
    "# try:\n",
    "#     demo.launch(debug=True, share=True, show_api=False)\n",
    "#     demo.close()\n",
    "# except Exception as e:\n",
    "#     demo.close()\n",
    "#     print(e)\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVtcczQQDgw1"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Task 6: [Exercise]** Testing Out Your Chatbot\n",
    "\n",
    "**Please test out this guardrailed chatbot to your liking, taking some time to try the following exercises:**\n",
    "\n",
    "- Ask the network about topics relating to science, engineering, video games, NVIDIA, etc.\n",
    "\n",
    "- Ask the network about topics related to food, homework, unethical activity, etc.\n",
    "\n",
    "- Ask the chatbot a simple question like \"Hello! How's it going?.\" Note that the chatbot will be reluctant to answer you in a nice way.\n",
    "    - **Insight:** Perhaps you could design some systems that switch out the guardrails as appropriate? Or maybe you could allow multiple guardrails to exist and move into and out of prominence?\n",
    "\n",
    "- Ask the chatbot about a country. Then, rephrase your question to ask about the country with regard to its technological developments, GPU demand, etc.\n",
    "    - **Insight:** You may want your system to do this kind of recontextualization automatically, so consider how you can implement a system to do that for you. Also consider what modifications you might need to make to your guardrail.\n",
    "\n",
    "- At the time of writing, NVIDIA recently released the [Grace Hopper Superchip](https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/). From the site, we can find a description:\n",
    "> The NVIDIA GH200 Grace Hopper Superchip combines the NVIDIA Grace and Hopper architectures using NVIDIA NVLink-C2C to deliver a CPU+GPU coherent memory model for accelerated AI and HPC applications.\n",
    "\n",
    "  Depending on when the model was trained, there's a good chance that it hasn't encountered this idea yet.\n",
    "\n",
    "    - See what happens when you try to ask the chatbot about the **\"Grace Hopper Superchip,\"** the actual name of the system.\n",
    "\n",
    "    - How about a **\"Grace Hopper GPU\"**?\n",
    "    \n",
    "    - How about a **\"Nikola GPU\"** (Tesla GPUs do exist, and Nikola fits with our naming scheme, so it's worth a shot)?\n",
    "\n",
    "<br>\n",
    "\n",
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "At the end of the day, it's up to you and your use case to decide how to implement your safety checks! Whether you use semantic filtering, custom chain checks, or a more purpose-built solution like [NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails), just be sure to test it consistently and always keep tabs on the worst-case behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZynySFaVuLs"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/en-us/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
