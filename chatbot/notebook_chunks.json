{
    "course": "NVIDIA Deep Learning Institute's Instructor-Led Course titled \"Building RAG Agents with LLMs\"",
    "filenames": [
        "00_jupyterlab.ipynb",
        "01_microservices.ipynb",
        "02_llms.ipynb",
        "03_langchain_intro.ipynb",
        "04_running_state.ipynb",
        "05_documents.ipynb",
        "06_embeddings.ipynb",
        "07_vectorstores.ipynb",
        "08_evaluation.ipynb",
        "09_langserve.ipynb",
        "64_guardrails.ipynb",
        "99_table_of_contents.ipynb"
    ],
    "slides": "Here is a condensed summary of all the slides, tied to the narrative of the course:\n\n<img src='/file=slides/slide01.jpg'>: Introduction slide featuring the NVIDIA logo and the topic 'Building RAG Agents with LLMs'.\n\n<img src='/file=slides/slide02.jpg'>: Conceptual model for large language models, highlighting interconnected components like database, natural language processing, data analysis, machine learning algorithms, human-computer interaction, and voice recognition.\n\n<img src='/file=slides/slide03.jpg'>: Interaction diagram between user, agent, and LLM, illustrating the roles of retrieval, augmentation, and LLM orchestration software.\n\n<img src='/file=slides/slide05.jpg'>: LangChain platform overview, showcasing components for building chat applications: Context, Tools, Test, Extraction, Storage & Indexing, and Retrieval.\n\n<img src='/file=slides/slide06.jpg'>: NVIDIA AI capabilities, featuring AI-generated artwork and applications, emphasizing community-built AI models and deployment with NVIDIA NIM.\n\n<img src='/file=slides/slide07.jpg'>: Prerequisites for the course, including prior LLM/LangChain exposure, intermediate Python experience, and exposure to web engineering.\n\n<img src='/file=slides/slide08.jpg'>: Course objectives, covering environment setup, LLM services, LangChain (LCEL), running state chains, document loading, embeddings, document retrieval, and RAG evaluation.\n\n<img src='/file=slides/slide09.jpg'>: Jupyter Labs interface overview, showing a web browser with IP address 8888 and a graphical representation of a computer setup.\n\n<img src='/file=slides/slide10.jpg'>: Detailed view of the Jupyter Labs interface, including file explorer, notebook panels, console, and terminal options.\n\n<img src='/file=slides/slide11.jpg'>: DLI Jupyter Labs Interface diagram, illustrating the connection between user device, remote host, and additional processes.\n\n<img src='/file=slides/slide12.jpg'>: Containerization with Docker, showing compartmentalized functionality into microservices, including data loader, scheduler, proxy service, Python node, and Jupyter Labs.\n\n<img src='/file=slides/slide13.jpg'>: Microservices workflow, outlining steps: Allocate Resources, Define Services, Construct Containers, and Start Processes.\n\n<img src='/file=slides/slide14.jpg'>: Scaling containerized applications architecture, featuring company database, arbitrary host, GenAI service, data loader, Jupyter Notebook environment, and web browser.\n\n<img src='/file=slides/slide15.jpg'>: Gradio webpage overview, highlighting the build and share capabilities for machine learning apps, with a 'Get Started' button and a 'Star' icon.\n\n<img src='/file=slides/slide16.jpg'>: Simple Gradio ChatInterface, showing a GUI of a chat application with text box, 'Send' button, and code snippet for the chat interface.\n\n<img src='/file=slides/slide17.jpg'>: Gradio in HuggingFace Spaces, featuring a form with fields for 'Name', 'Email', 'Message', and a 'Submit' button, along with options for 'Image', 'Text', 'Audio', 'Video', and 'Code'.\n\n<img src='/file=slides/slide18.jpg'>: Custom Gradio Block Interface, showing a GUI with a colorful image of a cat's face and a text box, along with a code snippet for the Gradio interface.\n\n<img src='/file=slides/slide19.jpg'>: Standalone environment LLM performance metrics for the Llama-2-7B model on the INT8 data type, featuring a table and bar chart.\n\n<img src='/file=slides/slide20.jpg'>: Large model hosting platforms setup, showing a remote host with a frontend, VRAM-bound Jupyter Notebook, and CPU-only environment, connecting to the NVIDIA GPU Cloud.\n\n<img src='/file=slides/slide21.jpg'>: Query Router Access diagram, featuring a JSON object, flowchart with 'Facilitate', 'Monitor', and 'Optimize' components, and a stack of blocks labeled 'GPT4 Dalle-3 Embed'.\n\n<img src='/file=slides/slide22.jpg'>: Large Model Hosting Platforms architecture using OpenAI, showing the flow from 'End-User Application' to 'Dalle-3' through 'Retriever Microservice', 'OpenAI Gateway', and 'Server Management'.\n\n<img src='/file=slides/slide23.jpg'>: Comparison between OpenAI's GPT-4 and NVIDIA's GPU Cloud, highlighting features like integrated tools, multimodal support, and paths to local deployment.\n\n<img src='/file=slides/slide24.jpg'>: Query Router Access diagram, featuring a JSON object, flowchart with 'Facilitate', 'Monitor', and 'Optimize' components, and stacks of blocks labeled 'SDXL', 'LLM', and 'E5'.\n\n<img src='/file=slides/slide25.jpg'>: Full Deployment Stack diagram, showing layers: Application Layer, Microservice Layer, and Triton Layer, with various hardware components and software tools.\n\n<img src='/file=slides/slide26.jpg'>: NVIDIA Foundation Model Endpoints webpage, featuring top open foundation models and trending models.\n\n<img src='/file=slides/slide28.jpg'>: NVIDIA Foundation Model Endpoints webpage, featuring a code snippet and a graphic of a stack of blocks with the NVIDIA logo.\n\n<img src='/file=slides/slide29.jpg'>: Diagram illustrating the process flow from raw requests to the LangChain model, featuring components like 'Document Loaders', 'Tools', 'Output Parsers', 'Vector Stores', 'Text Splitters', and 'Example Selectors'.\n\n<img src='/file=slides/slide30.jpg'>: Process of converting raw requests into a LangChain model, featuring a 'ChatMessage', 'embedder' function, 'Query Router', and components like 'Llama', 'Mistral', and 'E5'.\n\n<img src='/file=slides/slide31.jpg'>: LLM Interfaces within The Whole Stack, showing a flow from 'ChatNVIDIA NVIDIABase' to 'ChatOpenAI OpenAI' and 'OpenAI', with URLs and functions like 'Compute WID'.\n\n<img src='/file=slides/slide32.jpg'>: LangChain Structure diagram, featuring a central green parrot with surrounding components: 'Document Loaders', 'Text Splitters', 'Vector Stores', 'Output Parsers', 'Models', 'Prompts', 'Example Selectors', and 'Tools'.\n\n<img src='/file=slides/slide33.jpg'>: Chain Building process using a Simple Prompt+LLM Chain, featuring a flow from 'Input' to 'Output' with components like 'Prompt', 'LLM', and 'StrOutputParser'.\n\n<img src='/file=slides/slide34.jpg'>: Chain Building process involving invoking runnables, featuring a flow from 'Input' to 'Prompt' to 'LLM' to 'Output', with code snippets for 'chain' and 'chain.stream()'.\n\n<img src='/file=slides/slide35.jpg'>: Chain Building process for information pipelines, featuring internal and external sequences with components like 'Prompt', 'LLM', and 'If/Else' conditions.\n\n<img src='/file=slides/slide37.jpg'>: Computing environment setup involving Jupyter Notebooks and a frontend client, showing a Jupyter Notebook Server running on a Docker container connected to a remote host.\n\n<img src='/file=slides/slide39.jpg'>: Chain Building process towards a running state, featuring a flow from 'Input' to 'Output' with components like 'Prompt', 'LLM', and 'Topic'.\n\n<img src='/file=slides/slide40.jpg'>: Chain Building process towards a running state, featuring a flow from 'Input' to 'Output' with components like 'Prompt', 'LLM', and 'Combine Sentence'.\n\n<img src='/file=slides/slide41.jpg'>: Chain Building process towards a running state, featuring a flow from 'Input' to 'Output' with components like 'Prompt', 'LLM', 'Branch Chain', and 'RunnableAssign'.\n\n<img src='/file=slides/slide42.jpg'>: Code snippet for a regular Fibonacci sequence using a while loop, featuring initialization, running state, and final output variables.\n\n<img src='/file=slides/slide43.jpg'>: Running State Chain Components towards LCEL While Loop, featuring a function 'get_initial_state' and a visual representation of the state.\n\n<img src='/file=slides/slide44.jpg'>: Running State Chain Components towards LCEL While Loop, featuring a running state represented as a dictionary and circular diagrams illustrating state transitions.\n\n<img src='/file=slides/slide45.jpg'>: Running State Chain Components towards LCEL While Loop, featuring a function 'next_fib_fn()' and visual elements representing state transitions.\n\n<img src='/file=slides/slide46.jpg'>: Running State Chain Components towards LCEL While Loop, featuring code snippets for 'next_fib_fn()' and 'state_chain', and circular diagrams representing Fibonacci sequence states.\n\n<img src='/file=slides/slide47.jpg'>: Code snippet for a function 'next_fib_fn()' implementing a running state loop in a computational context.\n\n<img src='/file=slides/slide48.jpg'>: Comparison of a typical running state loop with a running state loop in a programming context, featuring code snippets and flow diagrams.\n\n<img src='/file=slides/slide49.jpg'>: Final Running State Loop diagram, featuring components like 'RunnableAssign', 'RunnableLambda', and 'RunnableBranch', with arrows indicating flow.\n\n<img src='/file=slides/slide50.jpg'>: Airline Chatbot process flow, featuring components like 'Prompt Update Knowledge', 'Knowledge Base', 'DB Lookup', and 'Customer Info'.\n\n<img src='/file=slides/slide52.jpg'>: Modern Chain Paradigms towards a powerful running state, featuring components like 'Context', 'Tools', 'Test', 'Extraction', 'Storage & Indexing', and 'Retrieval'.\n\n<img src='/file=slides/slide53.jpg'>: Modern Chain Paradigms towards a powerful running state, featuring components like 'Prompt', 'LLM', 'Code LLM', 'Environment', 'Structured Retrieval', and 'Unstructured Generation'.\n\n<img src='/file=slides/slide54.jpg'>: Modern Chain Paradigms towards a powerful running state, featuring components like 'Prompt', 'LLM', 'Code LLM', 'Grammar/Schema', 'Tool Choice Tool Schema', 'Environment', 'Structured Retrieval', 'Unstructured Generation', and 'Tooling'.\n\n<img src='/file=slides/slide55.jpg'>: Final Objective diagram, featuring JSON objects representing states in a conversation and a code snippet for updating the knowledge base.\n\n<img src='/file=slides/slide56.jpg'>: Document Reasoning process, featuring a flow from 'Prompt Context' to 'LLM' to a response, with a URL link to a blog post.\n\n<img src='/file=slides/slide57.jpg'>: Document Reasoning process within a company database context, featuring a flow from 'Company Database' to 'Prompt Context' to 'LLM' to a response.\n\n<img src='/file=slides/slide58.jpg'>: Document Reasoning process within a company database, featuring a flow from 'Company Database' to 'Local files' to 'Prompt Context' to a question.\n\n<img src='/file=slides/slide59.jpg'>: Chunking process, featuring documents with diagrams and tables, titled 'LUXAZ 2 Open Foundation and Fine-Tune Chunk Models'.\n\n<img src='/file=slides/slide60.jpg'>: Document Stuffing process, featuring a document with a green parrot labeled 'LLM' and a speech bubble with a prompt.\n\n<img src='/file=slides/slide61.jpg'>: Map Reduce Chain process, featuring a central node labeled 'Prompt' connected to 'LLM' and 'Smaller Chunk' nodes.\n\n<img src='/file=slides/slide62.jpg'>: Refinement Chain process, featuring a central oval labeled 'LLM' connected to 'Prompt', 'Summary', and 'Main Ideas' nodes.\n\n<img src='/file=slides/slide63.jpg'>: Knowledge Graph construction process, featuring a flow from 'for doc in docs:' to 'yield doc' to various nodes like 'Abstraction Main Ideas', 'Chapters', and 'Names'.\n\n<img src='/file=slides/slide64.jpg'>: Knowledge Graph Traversal diagram, featuring a central question and a flow of information through prompts and references.\n\n<img src='/file=slides/slide65.jpg'>: Optional Tangent: LangGraph, featuring a code snippet for 'LangGraph' class and a flowchart with nodes like 'User', 'Router', 'Researcher', and 'Chart_Generator'.\n\n<img src='/file=slides/slide66.jpg'>: Modern Chain Paradigms towards a powerful running state, featuring components like 'Prompt LLM', 'Prompt Code LLM', 'Environment', 'Vector Database', 'Structured Retrieval', and 'Unstructured Retrieval'.\n\n<img src='/file=slides/slide67.jpg'>: Retrieval-Augmented Generation (RAG) process, featuring a flow from a question to a retriever to a generator to an answer.\n\n<img src='/file=slides/slide68.jpg'>: Transformer Architecture diagram, featuring components like 'Input', 'Self-Attention', 'Feed Forward', 'Output', 'Encoder', and 'Decoder'.\n\n<img src='/file=slides/slide69.jpg'>: Comparison between Autoregressive and Embedding transformer architectures, featuring sequences of letters and text outputs.\n\n<img src='/file=slides/slide70.jpg'>: NVIDIA's Retrieval QA Embedding model, featuring a document with a word cloud and a JSON code snippet.\n\n<img src='/file=slides/slide71.jpg'>: Embedding Spaces concept, featuring a 3D grid with colored dots representing questions and a central point labeled 'Classification Head'.\n\n<img src='/file=slides/slide72.jpg'>: Comparison between Bi-Encoder and Cross-Encoder language embedding schemes, featuring encoders, passages, and a 'Cosine-Similarity' function.\n\n<img src='/file=slides/slide73.jpg'>: Comparison between Symmetric and Asymmetric/Generalized language embedding schemes, featuring encoders, passages, and a 'Cosine-Similarity' function.\n\n<img src='/file=slides/slide74.jpg'>: Language Embedding Schemes flowchart, featuring 'query document' and 'memory document' inputs, 'Mixed-modal Encoders', and a 'Mean Pooling' process.\n\n<img src='/file=slides/slide75.jpg'>: Embedding and Comparing process, featuring a list of topics with vectors and a comparison between a database and an HPC system.\n\n<img src='/file=slides/slide76.jpg'>: Semantic Guardrails diagram, featuring a 'Prompt Answer Option' node branching into 'Illegal Topics' and 'Irrelevant Questions' paths.\n\n<img src='/file=slides/slide77.jpg'>: Embedding Classification process, featuring a 3D grid with colored dots representing questions and a 'Classification Head' network.\n\n<img src='/file=slides/slide78.jpg'>: Integrating a Vector Store process, featuring steps like loading source data, embedding, and retrieving the 'most similar' data.\n\n<img src='/file=slides/slide79.jpg'>: Integrating a Vector Store slide, featuring Python code for setting up a vector store using FAISS and NVIDIAEmbeddings, and a neural network model graphic.\n\n<img src='/file=slides/slide80.jpg'>: Retrieval reordering/selection process, featuring a user query, retriever, VDB, metadata, conversation snippet, 'Reranker', and 'LongContextReorderer'.\n\n<img src='/file=slides/slide81.jpg'>: RAG Fusion process, featuring a prompt, LLM, hypothesis, question, VDB Retriever, Reranker, and final output.\n\n<img src='/file=slides/slide82.jpg'>: Integrating a local vector store with a local host system, featuring components like Milvus Standalone, Frontend, Jupyter Notebook, Query Router, and LLM.\n\n<img src='/file=slides/slide83.jpg'>: GPU-Accelerating Vector Stores slide, featuring a bar chart comparing vector search algorithms and a table listing vector search algorithms and tools.\n\n<img src='/file=slides/slide84.jpg'>: Compute Scale Progression diagram, featuring a progression from 'Jupyter Notebook Server' to 'Milvus Standalone' to 'Milvus Cluster'.\n\n<img src='/file=slides/slide85.jpg'>: Simple Conversation RAG Setup flowchart, featuring a dialogue between two entities and a retrieval process from a database to a prompt context to an LLM response.\n\n<img src='/file=slides/slide86.jpg'>: Simple RAG Agents workflow, featuring a question, 'Classifier Branch', 'Prompt Question', 'Prompt Context Question', 'LLM', and output.\n\n<img src='/file=slides/slide87.jpg'>: Proper RAG Agent workflow, featuring a cyclical process with 'Prompt Question', 'LLM', 'Toolset', 'Final Answer + History', and a loop back to 'Prompt Question'.\n\n<img src='/file=slides/slide88.jpg'>: LLM-As-A-Judge pipeline evaluation process, featuring RAG Pipeline and Evaluation Pipeline with components like 'Prompt', 'Retrieval', 'Context Question', and 'LLM'.\n\n<img src='/file=slides/slide89.jpg'>: General evaluation chain components, featuring 'VDB + Embedder', 'LLM', 'Retriever', and 'RagasEvaluatorChain' with metrics like 'generation', 'retrieval', and 'context precision'.\n\n<img src='/file=slides/slide90.jpg'>: RAG Evaluation process with Quantifying System Goodness using LLM-as-a-Judge, featuring generation and retrieval sections with metrics like 'faithfulness', 'answer relevancy', 'context precision', and 'context recall'.\n\n<img src='/file=slides/slide92.jpg'>: Evaluator Agent Pipeline Evaluation diagram, featuring a sequence of prompts and responses from an LLM, connected by arrows indicating the flow of the process.\n\n<img src='/file=slides/slide93.jpg'>: Evaluation chain with various components and their interactions, featuring 'VDB', 'Doc1', 'Prompt Ask/Answer', 'LLM', 'Doc2', 'Retriever', 'Prompt Context Question', 'Prompt Which is Better?', and 'Bot 2 Better'.\n\n<img src='/file=slides/slide94.jpg'>: Evaluate RAG in the Frontend Final Assessment diagram, featuring a 'Remote Host' with 'Frontend', 'RAG', 'Jupyter Notebook', and communication with 'NVIDIA GPU CLOUD'.\n\n<img src='/file=slides/slide95.jpg'>: Congratulatory message from NVIDIA, featuring the NVIDIA logo and a stylized graphic of a computer setup, indicating a high-speed network or data transfer.",
    "summary": "00_jupyterlab.ipynb\n - JupyterLab Interface: Introduction to JupyterLab interface, including menu bar, file browser, and main work area. Covers basics of navigating the interface and executing code in code cells.\n - Special Syntax: Introduction to intermediate Python syntax, including input, getpass, and multi-line grouping. Covers basics of using these components in Python code.\n - Main Ideas and Relevance To Course: Introduction to JupyterLab interface and intermediate Python syntax. Provides foundation for using JupyterLab throughout the course and understanding Python syntax used in later notebooks.\n - Important Code: `input`, `getpass`, `SecretStr`, `f-strings`, multi-line grouping, `eval`, `try-except`.\n - Connections to previous notebooks: None, as this is the first notebook in the course.\n - Relevant Images: <img src='/file=imgs/jl_launcher.png'>.\n01_microservices.ipynb\n - Welcome To Your Cloud Environment: Introduction to the cloud environment, including the Jupyter Labs interface and the microservices used throughout the course.\n - Part 1: Hosting Containers: Overview of Docker and containerization, including the benefits of using containers for microservices orchestration.\n - Part 2: The Jupyter Labs Microservice: Explanation of the Jupyter Labs microservice and how it is used to interact with other microservices.\n - Part 3: Interacting With Microservices As The Host: Introduction to the docker-router microservice and how it is used to interact with other microservices.\n - Part 4: Checking Our Frontend: Explanation of the frontend microservice and how it is used to build interactive web applications.\n - Part 5: Wrap-Up: Summary of the notebook and next steps for the course.\n - Main Ideas and Relevance To Course: This notebook provides an overview of the course environment and the microservices used throughout the course. It introduces the concept of microservices orchestration and provides an example of how to use the docker-router microservice to interact with other microservices. This notebook is relevant to the course because it provides a foundation for understanding the course environment and the microservices used throughout the course.\n - Important Code: Docker commands, Dockerfile, docker-compose.yaml, curl commands, requests library.\n - Connections to previous notebooks: This notebook builds on the introduction to the JupyterLab interface provided in Notebook 0: JupyterLab. It also introduces the concept of microservices orchestration, which is used throughout the course.\n - Relevant Images: <img src='https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/simple-env.png' width=800px/>, <img src='https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/docker-ms.png' width=1000px/>, <img src='http://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/environment.png' width=800px/>\n02_llms.ipynb\n - **Getting Large Models Into Your Environment**: Introduction to microservices, large language models (LLMs), and the NVIDIA AI Foundation Endpoints. Covers deployment scenarios for large models, including high-end datacenter deployment, modest datacenter/specialized consumer hardware deployment, and consumer hardware deployment.\n - **Hosted Large Model Services**: Discussion on black-box hosted models and self-hosted models. Introduces the NVIDIA NGC Service and its suite of developer tools for designing and deploying AI solutions.\n - **Getting Started With Hosted Inference**: Overview of the steps to deploy a model for scaled inference, including identifying models, figuring out user controls, and creating monitoring schemes.\n - **[Exercise] Trying Out The Foundation Model Endpoints**: Hands-on exercise to interact with LLM endpoints using manual Python requests, OpenAI client requests, and ChatNVIDIA client requests.\n - **Wrap-Up**: Summary of the notebook's goals and next steps.\n - Main Ideas and Relevance To Course: This notebook introduces the concept of large language models (LLMs) and explains how they can be used to provide access to powerful models through scalable server deployments. It covers the basics of using the NVIDIA AI Foundation Endpoints and provides an example of how to use the endpoints to query live foundation models. The notebook also explains how to use the endpoints to build software that leverages generative AI capabilities.\n - Important Code: `requests`, `OpenAI`, `ChatNVIDIA`, `get_stream_token`, `invoke_url`, `headers`, `payload`, `response`, `completion`, `llm`, `model_list`, `model_name`, `model_card`, `NVIDIA_API_KEY`, `OPENAI_API_KEY`, `base_url`, `api_key`, `messages`, `temperature`, `top_p`, `max_tokens`, `stream`, `choices`, `delta`, `content`, `finish_reason`, `usage`, `completion_tokens`, `prompt_tokens`, `total_tokens`, `data`, `id`, `index`, `role`, `assistant`, `user`, `system`, `stop`, `DONE`, `json`, `decode`, `utf-8`, `iter_lines`, `raise_for_status`, `last_inputs`, `last_response`, `get_available_models`, `invoke`, `stream`, `getpass`, `os`, `environ`, `startswith`, `nvapi-`, `sk-`, `ChatNVIDIA`, `OpenAI`, `requests`, `json`, `get_stream_token`, `invoke_url`, `headers`, `payload`, `response`, `completion`, `llm`, `model_list`, `model_name`, `model_card`, `NVIDIA_API_KEY`, `OPENAI_API_KEY`, `base_url`, `api_key`, `messages`, `temperature`, `top_p`, `max_tokens`, `stream`, `choices`, `delta`, `content`, `finish_reason`, `usage`, `completion_tokens`, `prompt_tokens`, `total_tokens`, `data`, `id`, `index`, `role`, `assistant`, `user`, `system`, `stop`, `DONE`, `json`, `decode`, `utf-8`, `iter_lines`, `raise_for_status`, `last_inputs`, `last_response`, `get_available_models`, `invoke`, `stream`, `getpass`, `os`, `environ`, `startswith`, `nvapi-`, `sk-`.\n - Connections to previous notebooks: This notebook builds on the concepts introduced in Notebook 1: The Course Environment, particularly the use of microservices and the Jupyter Labs interface. It also introduces the NVIDIA AI Foundation Endpoints, which will be used in subsequent notebooks to build LLM applications.\n - Relevant Images: <img src='https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/ai-playground-api.png'>, <img src='https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/mixtral_api.png'>, <img src='https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/openai_chat.png'>.\n03_langchain_intro.ipynb\n - **Part 1: What Is LangChain?**: Introduction to LangChain, its popularity, and rapid changes. Focus on LangChain Expression Language (LCEL) for building LLM applications.\n - **Part 2: Chains and Runnables**: Explanation of Chains and Runnables in LangChain. Introduction to RunnableLambda, RunnablePassthrough, and the use of dictionaries in LCEL.\n - **Part 3: Dictionary Pipelines with Chat Models**: Using dictionaries in LCEL for tracking variables and integrating with LangChain prompts. Examples include simple LLM chains, internal response handling, and multi-component chains.\n - **Part 4: [Exercise] Rhyme Re-themer Chatbot**: Exercise to implement a poetry generation chatbot using Gradio and LangChain. Focus on integrating multiple tasks and managing dialog.\n - **Part 5: [Exercise] Using Deeper LangChain Integrations**: Introduction to LangServe for deploying LangChain chains as API endpoints. Exercise to test RemoteRunnable and integrate with a frontend.\n - **Part 6: Wrap-Up**: Summary of the notebook, emphasizing the use of LangChain, Gradio, and LangServe for building LLM applications.\n - Main Ideas and Relevance To Course: LangChain Expression Language (LCEL), Chains, Runnables, Gradio, LangServe, LLM orchestration, dictionary pipelines, chat models, internal response handling, multi-component chains, poetry generation, API endpoints.\n - Important Code: RunnableLambda, RunnablePassthrough, ChatNVIDIA, ChatPromptTemplate, StrOutputParser, Gradio, LangServe, RemoteRunnable, dictionaries, LCEL syntax, chatbot implementation.\n - Connections to previous notebooks: Builds on the introduction to LLM services and AI Foundation Models from Notebook 2. Introduces LangChain and its integration with these models, setting the stage for more advanced topics in subsequent notebooks.\n - Relevant Images: <img src='https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/langchain-diagram.png'>\n04_running_state.ipynb\n - **Keeping Variables Flowing**: Introduction to LangChain Expression Language (LCEL) and runnables, focusing on state management and variable propagation in LLM applications. Covers zero-shot classification, state mutation, and consumption.\n - **Running State Chain**: Explains the concept of running state chains for dialog management and iterative decision-making. Introduces the structure of a running state chain, including the running state, branches, and RunnableAssign.\n - **Implementing a Knowledge Base with Running State Chain**: Demonstrates how to use Pydantic and LangChain to create a dynamic knowledge base for LLM applications. Covers knowledge base definition, runnable extraction modules, and dynamic updates.\n - **Airline Customer Service Bot**: Exercise to implement a dialog management chatbot using running state chains and knowledge bases. Focuses on prompt engineering, context parsing, and branching chains.\n - Main Ideas and Relevance To Course: This notebook builds on LCEL and runnables from Notebook 3, introducing advanced state management techniques for complex dialog systems. It emphasizes the use of knowledge bases and running state chains for dynamic and interactive LLM applications.\n - Important Code: `RunnableLambda`, `RunnableAssign`, `PydanticOutputParser`, `ChatPromptTemplate`, `KnowledgeBase` class, `RExtract` function, `get_flight_info` function.\n - Connections to previous notebooks: Builds on LCEL and runnables from Notebook 3, applying them to more complex dialog management strategies. Introduces knowledge bases and running state chains as advanced techniques for state management.\n - Relevant Images: <img src='/file=imgs/running_state_chain.png'>\n05_documents.ipynb\n - **Part 1: Chatting with Documents**: Introduction to document interaction with LLMs, discussing document stuffing, knowledge bases, and document reasoning challenges. Frameworks: LangChain, LlamaIndex.\n - **Part 2: Loading Documents**: Overview of LangChain document loaders, including UnstructuredFileLoader and ArxivLoader. Topics: document loading, metadata, context window management.\n - **Part 3: Transforming The Documents**: Document chunking using RecursiveCharacterTextSplitter. Topics: chunking strategies, document transformation, context optimization.\n - **Part 4: [Exercise] Refining Summaries**: Document summarization using LLMs, introducing DocumentSummaryBase model and RExtract function. Frameworks: LangChain, Pydantic. Topics: progressive summarization, slot-filling extraction, running state chains.\n - **Part 5: Synthetic Data Processing**: Discussion on large-scale data processing challenges and potential applications like domain-specific knowledge graphs. Topics: data aggregation, categorization, consolidation, knowledge graph construction.\n - **Part 6: Wrap-Up**: Summary of notebook, introduction to semantic retrieval with embedding models in the next notebook. Topics: document handling, semantic reasoning, retrieval-augmented generation (RAG).\n - Main Ideas and Relevance To Course: This notebook focuses on techniques for handling large documents in LLM applications, including document loading, chunking, summarization, and synthetic data processing. It builds on concepts from previous notebooks, such as running state chains and LangChain Expression Language (LCEL), and sets the stage for semantic retrieval and RAG in subsequent notebooks.\n - Important Code: DocumentSummaryBase, RExtract, RSummarizer, RecursiveCharacterTextSplitter, ArxivLoader, UnstructuredFileLoader, ChatNVIDIA, PydanticOutputParser, RunnableLambda, RunnableAssign, ChatPromptTemplate, StrOutputParser.\n - Connections to previous notebooks: Builds on running state chains (Notebook 4) and LangChain Expression Language (Notebook 3). Introduces document handling techniques that will be used in semantic retrieval (Notebook 6) and RAG (Notebook 7).\n - Relevant Images: <img src='https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/doc_stuff.png'>, <img src='https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/doc_refine.png'>.\n06_embeddings.ipynb\n - Part 1: Refreshing On Embedding Models: Introduction to latent embeddings, word embeddings, sentence/document embeddings, decoder models, and encoder models. Covers semantic meanings, large-scale document processing, and transformer-like architectures.\n - Part 2: Using An NVIDIAEmbeddings Model: Utilizes LangChain and NVIDIA AI Foundation Endpoints to connect to an embedding model. Focuses on query and document pathways, and their roles in retrieval-based applications.\n - Part 3: A Synthetic - But More Realistic - Example: Explores the utility of bi-encoder models and their applications in handling longer-form documents.\n - Part 4: Embeddings For Semantic Guardrails: Introduces the concept of semantic guardrailing using embedding models to filter out harmful or irrelevant messages.\n - Part 5: Wrap-Up: Summarizes the key takeaways from the notebook and provides next steps.\n - Main Ideas and Relevance To Course: Focuses on embedding models, semantic reasoning, and their applications in large-scale document processing. Introduces the use of LangChain and NVIDIA AI Foundation Endpoints for connecting to embedding models.\n - Important Code: NVIDIAEmbeddings, ChatNVIDIA, embed_query, embed_documents, cosine_similarity, plot_cross_similarity_matrix.\n - Connections to previous notebooks: Builds on the concepts of large language models (LLMs) and LangChain introduced in earlier notebooks. Expands on the use of NVIDIA AI Foundation Endpoints for accessing powerful models.\n - Relevant Images: <img src='/file=imgs/encoder-decoder.png'>.\n07_vectorstores.ipynb\n - Retrieval-Augmented Generation with Vector Stores: Introduction to vector stores, FAISS, semantic similarity, retrieval-augmented generation (RAG), document chunking, conversational memory, LangChain, NVIDIA AI Foundation Endpoints.\n - Part 1: Summary of RAG Workflows: Overview of RAG workflows, vector stores, conversational exchanges, document retrieval, hierarchical reasoning, scalable vector databases.\n - Part 2: RAG for Conversation History: Conversational memory, FAISS vector store, semantic embedding, conversational exchanges, LangChain, NVIDIAEmbeddings, ChatNVIDIA.\n - Part 3 [Exercise]: RAG For Document Chunk Retrieval: Document loading, chunking, ArxivLoader, FAISS, LangChain, NVIDIAEmbeddings, ChatNVIDIA, Gradio.\n - Part 4: Saving Your Index For Evaluation: Saving and loading FAISS indices, evaluation, document retrieval.\n - Part 5: Wrap-Up: Summary, next steps, RAG evaluation.\n - Main Ideas and Relevance To Course: Vector stores, FAISS, RAG, document retrieval, conversational memory, LangChain, NVIDIA AI Foundation Endpoints, semantic similarity, document chunking, ArxivLoader, Gradio.\n - Important Code: FAISS, NVIDIAEmbeddings, ChatNVIDIA, ArxivLoader, LangChain, Gradio, save_memory_and_get_output, chat_gen, retrieval_chain, docstore, convstore.\n - Connections to previous notebooks: Builds on embedding models and semantic reasoning from Notebook 6, integrates with LangChain and NVIDIA AI Foundation Endpoints from Notebook 2 and Notebook 3, extends document handling from Notebook 5.\n - Relevant Images: <img src='/file=imgs/data_connection_langchain.jpeg'>, <img src='/file=imgs/vector_stores.jpeg'>.\n08_evaluation.ipynb\n - **Pre-Release Evaluation**: Introduction to comprehensive testing for chatbot performance, including typical use inspection, edge case inspection, and progressive rollout. Discusses the importance of thorough testing to ensure robustness and alignment with user expectations.\n - **LLM-as-a-Judge Formulation**: Explains the use of LLMs as evaluators for automatic testing of natural language task performance. Introduces frameworks like RAGAs and LangChain Evaluators for off-the-shelf judge formulations.\n - **Pairwise Evaluator**: Implementation of a custom pairwise string evaluator to compare RAG agent responses against synthetic \"baseline\" question-answer pairs. Focuses on evaluating whether the RAG chain outperforms a narrow chatbot with limited document access.\n - **Generating Synthetic Question-Answer Pairs**: Techniques for sampling document chunks and generating synthetic QA pairs for evaluation.\n - **Answering Synthetic Questions**: Using the RAG agent to generate answers to synthetic questions and comparing them against baseline answers.\n - **Implementing a Human Preference Metric**: Using a judge LLM to compare responses and evaluate human preference and consistency.\n - **Advanced Formulations**: Discussion of various evaluation metrics and techniques, including style evaluation, ground-truth evaluation, retrieval/augmentation evaluation, and trajectory evaluation.\n - **Assessment**: Final exercise to evaluate the RAG pipeline for course credit, ensuring the pipeline meets the evaluation criteria.\n - **Main Ideas and Relevance To Course**: This notebook focuses on evaluating the performance of RAG applications using LLM-as-a-Judge formulations. It builds on concepts from previous notebooks, such as document retrieval, RAG pipelines, and LLM integration, to provide a comprehensive evaluation framework.\n - **Important Code**: `ChatNVIDIA`, `NVIDIAEmbeddings`, `FAISS`, `ChatPromptTemplate`, `StrOutputParser`, `RunnableLambda`, `RunnableBranch`, `RunnableAssign`, `LongContextReorder`, `gradio`, `random`, `partial`, `itemgetter`, `RAGAs`, `LangChain Evaluators`.\n - **Connections to Previous Notebooks**: Builds on the RAG pipeline developed in Notebook 7 and integrates concepts from Notebook 2 (LLM services), Notebook 3 (LangChain Expression Language), and Notebook 6 (embedding models and semantic reasoning).\n - **Relevant Images**: <img src='/file=img/DLI_Header_White.png'>\n09_langserve.ipynb\n - LangServe Server Setup: Introduction to LangServe, setting up a simple API server using LangChain's Runnable interfaces with FastAPI, integrating LangChain models like ChatNVIDIA, creating and distributing accessible API routes.\n - Part 1: Delivering the /basic_chat endpoint: Instructions for launching a /basic_chat endpoint, using the endpoint in another file.\n - Part 2: Using The Server: Accessing the basic_chat endpoint using RemoteRunnable, testing the endpoint in a different file.\n - Part 3: Final Assessment: Implementing the /generator and /retriever endpoints for the final assessment, using the frontend microservice, conforming to the endpoint ingestion strategy.\n - Main Ideas and Relevance To Course: LangServe, API server setup, LangChain Runnable interfaces, FastAPI, ChatNVIDIA integration, endpoint creation, RemoteRunnable, final assessment implementation.\n - Important Code: FastAPI, LangChain Runnable interfaces, ChatNVIDIA, RemoteRunnable, endpoint paths (/basic_chat, /generator, /retriever), server_app.py, uvicorn.\n - Connections to previous notebooks: Builds on LangChain Expression Language (Notebook 3), Retrieval-Augmented Generation (Notebook 7), and RAG Evaluation (Notebook 8) by implementing a server for the developed LLM applications.\n - Relevant Images: <img src='/file=img/DLI_Header_White.png'>\n64_guardrails.ipynb\n - **Environment Setup**: Initializes the notebook environment, including necessary imports and setup for LangChain, NVIDIA AI Endpoints, and other utilities. Uses `langchain_nvidia_ai_endpoints`, `rich.console`, and `functools.partial`.\n - **Part 4: Embeddings For Semantic Guardrails**: Introduces the concept of semantic guardrailing using embedding models. Covers the generation of synthetic data, asynchronous embedding techniques, and the training of classifiers for semantic filtering. Uses `langchain_core`, `sklearn`, `keras`, and `asyncio`.\n - **Task 1: Generate Synthetic Data**: Generates synthetic data for training a semantic guardrail. Uses `langchain_core.prompts`, `langchain_core.runnables`, and `langchain_nvidia_ai_endpoints`.\n - **Task 2: Generate More Embeddings (and faster)**: Demonstrates asynchronous techniques for embedding large numbers of documents. Uses `asyncio`, `sklearn.decomposition`, and `sklearn.manifold`.\n - **Task 3: Confirming Semantic Density**: Uses PCA and t-SNE for dimensionality reduction to visualize semantic clusters. Uses `matplotlib.pyplot`, `sklearn.decomposition.PCA`, and `sklearn.manifold.TSNE`.\n - **Task 4: Training Our Classifier**: Trains a classifier using neural networks and logistic regression. Uses `keras`, `sklearn.linear_model.LogisticRegression`, and `sklearn.model_selection.train_test_split`.\n - **Task 5: Integrating Into Our Chatbot**: Integrates the trained classifier into a chatbot for semantic guardrailing. Uses `langchain_core.prompts`, `langchain_core.runnables`, and `gradio`.\n - **Task 6: Testing Out Your Chatbot**: Provides exercises to test the guardrailed chatbot. Uses `gradio.ChatInterface` and `gradio.Chatbot`.\n - Main Ideas and Relevance To Course: This notebook focuses on advanced techniques for semantic guardrailing using embedding models and classifiers. It builds on the concepts introduced in previous notebooks, particularly Notebook 6, and provides practical examples of how to implement semantic guardrails in a chatbot. Key topics include synthetic data generation, asynchronous embedding, dimensionality reduction, classifier training, and chatbot integration.\n - Important Code: `Timer` class, `embed_with_semaphore` function, `train_model_neural_network` function, `train_logistic_regression` function, `score_response` function, `chat_gen` function, `queue_fake_streaming_gradio` function.\n - Connections to previous notebooks: This notebook is a direct continuation of Notebook 6, which introduces embedding models and semantic reasoning. It builds on the concepts of embedding models and semantic reasoning introduced in Notebook 6 and provides practical examples of how to use these concepts to implement semantic guardrails in a chatbot. It also uses the LangChain Expression Language (LCEL) introduced in Notebook 3 and the concept of running state chains introduced in Notebook 4.\n - Relevant Images: <img src='/file=img/DLI_Header_White.png'>\n`99_table_of_contents.ipynb`\n - **Table Of Contents**: Overview of course structure, microservices, and resources. Includes links to Gradio chatbot and frontend, Docker-Router logs, and descriptions of microservices like chatbot, composer, docker-router, frontend, llm_client, and caches (imgs, slides, solutions).\n - **Using The Course Chatbot**: Provides a link to the Gradio chatbot interface using JavaScript.\n - **Using The Course Exercise Frontend**: Provides a link to the Gradio frontend interface using JavaScript.\n - **Using Docker-Router To Read Logs**: Demonstrates how to retrieve and display logs from running containers using the Docker-Router microservice.\n - Main Ideas and Relevance To Course: Central hub for course navigation, microservices interaction, and resource access. Introduces key tools and interfaces used throughout the course.\n - Important Code: JavaScript for embedding links, Python for retrieving and displaying Docker logs, service_name variable, from_idx variable.\n - Connections to previous notebooks: Builds on the course environment setup (Notebook 1) and microservices orchestration. Provides access to tools and interfaces introduced in earlier notebooks.\n - Relevant Images: <img src='/file=imgs/DLI_Header_White.png'>"
}