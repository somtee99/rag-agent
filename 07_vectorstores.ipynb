{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1c98c44-0505-43b2-957c-86aa4d0e621e",
   "metadata": {
    "id": "a1c98c44-0505-43b2-957c-86aa4d0e621e"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/en-us/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Qk4Uw_iSr3Mc",
   "metadata": {
    "id": "Qk4Uw_iSr3Mc"
   },
   "source": [
    "<br>\n",
    "\n",
    "# <font color=\"#76b900\">**Notebook 7:** Retrieval-Augmented Generation with Vector Stores</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "In the previous notebook, we learned about embedding models and exercised some of their capabilities. We discussed their intended use cases of longer-form document comparison and found ways to use it as a backbone for more custom semantic comparisons. This notebook will progress these ideas toward the retrieval model's intended use case and explore how to build chatbot systems that rely on *vector stores* to automatically save and retrieve information.\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Learning Objectives:**\n",
    "\n",
    "- Understand how semantic-similarity-backed systems can facilitate easy-to-use retrieval formulations.\n",
    "\n",
    "- Learn how to incorporate retrieval modules into your chat model systems for a retrieval-augmented generation (RAG) pipeline, which can be applied to tasks like document retrieval and conversation memory buffers.\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Questions To Think About:**\n",
    "\n",
    "- This notebook does not attempt to incorporate hierarchical reasoning or non-naive RAG (such as planning agents). Consider what modifications would be necessary to make these components work in an LCEL chain.\n",
    "\n",
    "- Consider when it would be best to move your vector store solution into a scalable service and when a GPU will become necessary for optimization.\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Environment Setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5XmeiiOWtuxC",
   "metadata": {
    "id": "5XmeiiOWtuxC"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "## ^^ Comment out if you want to see the pip install process\n",
    "\n",
    "## Necessary for Colab, not necessary for course environment\n",
    "# %pip install -q langchain langchain-nvidia-ai-endpoints gradio rich\n",
    "# %pip install -q arxiv pymupdf faiss-cpu\n",
    "\n",
    "## If you encounter a typing-extensions issue, restart your runtime and try again\n",
    "# from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "# ChatNVIDIA.get_available_models()\n",
    "\n",
    "import os\n",
    "os.environ[\"NVIDIA_API_KEY\"] = \"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\"\n",
    "\n",
    "from functools import partial\n",
    "from rich.console import Console\n",
    "from rich.style import Style\n",
    "from rich.theme import Theme\n",
    "\n",
    "console = Console()\n",
    "base_style = Style(color=\"#76B900\", bold=True)\n",
    "pprint = partial(console.print, style=base_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37fe234-2bdb-4107-8483-efda9aa5e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "# NVIDIAEmbeddings.get_available_models()\n",
    "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\", truncate=\"END\")\n",
    "\n",
    "# ChatNVIDIA.get_available_models()\n",
    "instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x22b-instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ced9b0-30ed-4ccc-936f-ca03d6e172bf",
   "metadata": {
    "id": "a3ced9b0-30ed-4ccc-936f-ca03d6e172bf"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## Part 1: Summary of RAG Workflows\n",
    "\n",
    "This notebook will explore several paradigms and derive reference code to help you approach some of the most common retrieval-augmented workflows. Specifically, the following sections will be covered (with the differences highlighted):\n",
    "\n",
    "<br>\n",
    "\n",
    "> ***Vector Store Workflow for Conversational Exchanges:***\n",
    "- Generate semantic embedding for each new conversation.\n",
    "- Add the message body to a vector store for retrieval.\n",
    "- Query the vector store for relevant messages to fill in the LLM context.\n",
    "\n",
    "<br>\n",
    "\n",
    "> ***Modified Workflow for an Arbitrary Document:***\n",
    "- **Divide the document into chunks and process them into useful messages.**\n",
    "- Generate semantic embedding for each **new document chunk**.\n",
    "- Add the **chunk bodies** to a vector store for retrieval.\n",
    "- Query the vector store for relevant **chunks** to fill in the LLM context.\n",
    "    - ***Optional:* Modify/synthesize results for better LLM results.**\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Extended Workflow for a Directory of Arbitrary Documents:**\n",
    "- Divide **each document** into chunks and process them into useful messages.\n",
    "- Generate semantic embedding for each new document chunk.\n",
    "- Add the chunk bodies to **a scalable vector database for fast retrieval**.\n",
    "    - ***Optional*: Exploit hierarchical or metadata structures for larger systems.**\n",
    "- Query the **vector database** for relevant chunks to fill in the LLM context.\n",
    "    - *Optional:* Modify/synthesize results for better LLM results.\n",
    "\n",
    "<br>\n",
    "\n",
    "Some of the most important terminology surrounding RAG is covered in detail on the [**LlamaIndex Concepts page**](https://docs.llamaindex.ai/en/stable/getting_started/concepts.html), which itself is a great starting point for progressing towards the LlamaIndex loading and retrieving strategy. We highly recommend using it as a reference as you continue with this notebook and advise you to try out LlamaIndex after the course to consider the pros and cons firsthand!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa1911b-a6a2-47c5-bc66-1b61e6516437",
   "metadata": {
    "id": "baa1911b-a6a2-47c5-bc66-1b61e6516437"
   },
   "source": [
    "<!-- > <img src=\"https://drive.google.com/uc?export=view&id=1cFbKbVvLLnFPs3yWCKIuzXkhBWh6nLQY\" width=1200px/> -->\n",
    "> <img src=\"https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/data_connection_langchain.jpeg\" width=1200px/>\n",
    ">\n",
    "> From [**Retrieval | LangChain**ü¶úÔ∏èüîó](https://python.langchain.com/v0.1/docs/modules/data_connection/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XaZ20XoeSTD-",
   "metadata": {
    "id": "XaZ20XoeSTD-"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 2:** RAG for Conversation History\n",
    "\n",
    "In our previous explorations, we delved into the capabilities of document embedding models and used them to embed, store, and compare semantic vector representations of text. Though we could motivate how to efficiently extend this into vector store land manually, the true beauty of working with a standard API is its strong incorporation with other frameworks that can already do the heavy lifting for us!\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LRx0XUf_Sdxw",
   "metadata": {
    "id": "LRx0XUf_Sdxw"
   },
   "source": [
    "### **Step 1**: Getting A Conversation\n",
    "\n",
    "Consider a conversation crafted using Llama-13B between a chat agent and a blue bear named Beras. This dialogue, dense with details and potential diversions, provides a rich dataset for our study:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "IUfCuMkoShWI",
   "metadata": {
    "id": "IUfCuMkoShWI"
   },
   "outputs": [],
   "source": [
    "conversation = [  ## This conversation was generated partially by an AI system, and modified to exhibit desirable properties\n",
    "    \"[User]  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the rocky mountains?\",\n",
    "    \"[Agent] The Rocky Mountains are a beautiful and majestic range of mountains that stretch across North America\",\n",
    "    \"[Beras] Wow, that sounds amazing! Ive never been to the Rocky Mountains before, but Ive heard many great things about them.\",\n",
    "    \"[Agent] I hope you get to visit them someday, Beras! It would be a great adventure for you!\"\n",
    "    \"[Beras] Thank you for the suggestion! Ill definitely keep it in mind for the future.\",\n",
    "    \"[Agent] In the meantime, you can learn more about the Rocky Mountains by doing some research online or watching documentaries about them.\"\n",
    "    \"[Beras] I live in the arctic, so I'm not used to the warm climate there. I was just curious, ya know!\",\n",
    "    \"[Agent] Absolutely! Lets continue the conversation and explore more about the Rocky Mountains and their significance!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tDL2tAo2Skh2",
   "metadata": {
    "id": "tDL2tAo2Skh2"
   },
   "source": [
    "Using the manual embedding strategy from the previous notebook is still very viable, but we can also rest easy and let a **vector store** do all that work for us!\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5hIp943mSqGZ",
   "metadata": {
    "id": "5hIp943mSqGZ"
   },
   "source": [
    "### **Step 2:** Constructing Our Vector Store Retriever\n",
    "\n",
    "To streamline similarity queries on our conversation, we can employ a vector store to help keep track of passages for us! **Vector Stores**, or vector storage systems, abstract away most of the low-level details of the embedding/comparison strategies and provide a simple interface to load and compare vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pnaOBgexS-kp",
   "metadata": {
    "id": "pnaOBgexS-kp"
   },
   "source": [
    "<!-- > <img src=\"https://drive.google.com/uc?export=view&id=1ZjwYbSZzsXK6ZP8O1-cY3BeRffV4oqzb\" width=1000px/> -->\n",
    "> <img src=\"https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/vector_stores.jpeg\" width=1200px/>\n",
    ">\n",
    "> From [**Vector Stores | LangChain**ü¶úÔ∏èüîó](https://python.langchain.com/v0.1/docs/modules/data_connection/vectorstores/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DwZUh6kgS5Ki",
   "metadata": {
    "id": "DwZUh6kgS5Ki"
   },
   "source": [
    "<br>\n",
    "\n",
    "In addition to simplifying the process from an API perspective, vector stores also implement connectors, integrations, and optimizations under the hood. In our case, we will start with the [**FAISS vector store**](https://python.langchain.com/docs/integrations/vectorstores/faiss), which integrates a LangChain-compatable Embedding model with the [**FAISS (Facebook AI Similarity Search)**](https://github.com/facebookresearch/faiss) library to make the process fast and scalable on our local machine!\n",
    "\n",
    "**Specifically:**\n",
    "\n",
    "1. We can feed our conversation into [**a FAISS vector store**](https://python.langchain.com/docs/integrations/vectorstores/faiss) via the `from_texts` constructor. This will take our conversational data and the embedding model to create a searchable index over our discussion.\n",
    "2. This vector store can then be \"interpreted\" as a retriever, supporting the LangChain runnable API and returning documents retrieved via an input query.\n",
    "\n",
    "The following shows how you can construct a FAISS vector store and reinterpret it as a retriever using the LangChain `vectorstore` API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d3e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\okafo\\appdata\\roaming\\python\\python312\\site-packages (1.13.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1kE2-ejoTKKU",
   "metadata": {
    "id": "1kE2-ejoTKKU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 391 ms\n",
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## ^^ This cell will be timed to see how long the conversation embedding takes\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "## Streamlined from_texts FAISS vectorstore construction from text list\n",
    "convstore = FAISS.from_texts(conversation, embedding=embedder)\n",
    "retriever = convstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muN66v5PW5dW",
   "metadata": {
    "id": "muN66v5PW5dW"
   },
   "source": [
    "The retriever can now be used like any other LangChain runnable to query the vector store for some relevant documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "kNZJTnlEWVYh",
   "metadata": {
    "id": "kNZJTnlEWVYh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'9883d099-03d2-4ae0-8cba-2393ef0ce2ac'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[User]  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rocky mountains?\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'1a0fe0bc-edc4-44be-bbcf-c26b9061896b'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] Absolutely! Lets continue the conversation and explore more about the Rocky Mountains</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and their significance!'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'25e1bfc2-fda4-4b5d-aca2-f576cc5e0c7b'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] I hope you get to visit them someday, Beras! It would be a great adventure for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">you![Beras] Thank you for the suggestion! Ill definitely keep it in mind for the future.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'64d9a851-f9ae-4a29-8f75-e298feea116e'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[Agent] In the meantime, you can learn more about the Rocky Mountains by doing some research </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">online or watching documentaries about them.[Beras] I live in the arctic, so I'm not used to the warm climate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">there. I was just curious, ya know!\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    )</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'9883d099-03d2-4ae0-8cba-2393ef0ce2ac'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mUser\u001b[0m\u001b[32m]\u001b[0m\u001b[32m  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the \u001b[0m\n",
       "\u001b[32mrocky mountains?\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'1a0fe0bc-edc4-44be-bbcf-c26b9061896b'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Absolutely! Lets continue the conversation and explore more about the Rocky Mountains\u001b[0m\n",
       "\u001b[32mand their significance!'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'25e1bfc2-fda4-4b5d-aca2-f576cc5e0c7b'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m I hope you get to visit them someday, Beras! It would be a great adventure for \u001b[0m\n",
       "\u001b[32myou!\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBeras\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Thank you for the suggestion! Ill definitely keep it in mind for the future.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'64d9a851-f9ae-4a29-8f75-e298feea116e'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m In the meantime, you can learn more about the Rocky Mountains by doing some research \u001b[0m\n",
       "\u001b[32monline or watching documentaries about them.\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBeras\u001b[0m\u001b[32m]\u001b[0m\u001b[32m I live in the arctic, so I'm not used to the warm climate \u001b[0m\n",
       "\u001b[32mthere. I was just curious, ya know!\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(retriever.invoke(\"What is your name?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "SE1eDZTEWScC",
   "metadata": {
    "id": "SE1eDZTEWScC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'2a28586d-e559-45bf-a6ed-bb4ecc98b1f6'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] The Rocky Mountains are a beautiful and majestic range of mountains that stretch </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">across North America'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'64d9a851-f9ae-4a29-8f75-e298feea116e'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[Agent] In the meantime, you can learn more about the Rocky Mountains by doing some research </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">online or watching documentaries about them.[Beras] I live in the arctic, so I'm not used to the warm climate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">there. I was just curious, ya know!\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'9883d099-03d2-4ae0-8cba-2393ef0ce2ac'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[User]  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rocky mountains?\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'1a0fe0bc-edc4-44be-bbcf-c26b9061896b'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] Absolutely! Lets continue the conversation and explore more about the Rocky Mountains</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and their significance!'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    )</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'2a28586d-e559-45bf-a6ed-bb4ecc98b1f6'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m The Rocky Mountains are a beautiful and majestic range of mountains that stretch \u001b[0m\n",
       "\u001b[32macross North America'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'64d9a851-f9ae-4a29-8f75-e298feea116e'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m In the meantime, you can learn more about the Rocky Mountains by doing some research \u001b[0m\n",
       "\u001b[32monline or watching documentaries about them.\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBeras\u001b[0m\u001b[32m]\u001b[0m\u001b[32m I live in the arctic, so I'm not used to the warm climate \u001b[0m\n",
       "\u001b[32mthere. I was just curious, ya know!\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'9883d099-03d2-4ae0-8cba-2393ef0ce2ac'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mUser\u001b[0m\u001b[32m]\u001b[0m\u001b[32m  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the \u001b[0m\n",
       "\u001b[32mrocky mountains?\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'1a0fe0bc-edc4-44be-bbcf-c26b9061896b'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Absolutely! Lets continue the conversation and explore more about the Rocky Mountains\u001b[0m\n",
       "\u001b[32mand their significance!'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(retriever.invoke(\"Where are the Rocky Mountains?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mtNCEXLYTVf4",
   "metadata": {
    "id": "mtNCEXLYTVf4"
   },
   "source": [
    "As we can see, our retriever found a handful of semantically relevant documents from our query. You may notice that not all of the documents are useful or clear on their own. For example, a retrieval of *\"Beras\"* for *\"your name\"* may be problematic for the chatbot if provided out of context. Anticipating the potential problems and creating synergies between your LLM components can increase the likelihood of good RAG behavior, so keep an eye out for such pitfalls and opportunities.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZEDEzpqmTYMv",
   "metadata": {
    "id": "ZEDEzpqmTYMv"
   },
   "source": [
    "### **Step 3:** Incorporating Conversation Retrieval Into Our Chain\n",
    "\n",
    "Now that we have our loaded retriever component as a chain, we can incorporate it into our existing chat system as before. Specifically, we can start with an ***always-on RAG formulation*** where:\n",
    "- **A retriever is always retrieving context by default**.\n",
    "- **A generator is acting on the retrieved context**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64abe478-9bcb-4802-a26e-dc5a1756e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_transformers import LongContextReorder\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.schema.runnable.passthrough import RunnableAssign\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "\n",
    "########################################################################\n",
    "## Utility Runnables/Methods\n",
    "def RPrint(preface=\"\"):\n",
    "    \"\"\"Simple passthrough \"prints, then returns\" chain\"\"\"\n",
    "    def print_and_return(x, preface):\n",
    "        if preface: print(preface, end=\"\")\n",
    "        pprint(x)\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
    "\n",
    "def docs2str(docs, title=\"Document\"):\n",
    "    \"\"\"Useful utility for making chunks into context string. Optional, but useful\"\"\"\n",
    "    out_str = \"\"\n",
    "    for doc in docs:\n",
    "        doc_name = getattr(doc, 'metadata', {}).get('Title', title)\n",
    "        if doc_name:\n",
    "            out_str += f\"[Quote from {doc_name}] \"\n",
    "        out_str += getattr(doc, 'page_content', str(doc)) + \"\\n\"\n",
    "    return out_str\n",
    "\n",
    "## Optional; Reorders longer documents to center of output text\n",
    "long_reorder = RunnableLambda(LongContextReorder().transform_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uue5UY3_TcvF",
   "metadata": {
    "id": "uue5UY3_TcvF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Based on the context provided, Beras lives in the Arctic. It seems like they're not very familiar with the warm </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">climate of the Rocky Mountains.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mBased on the context provided, Beras lives in the Arctic. It seems like they're not very familiar with the warm \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mclimate of the Rocky Mountains.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Answer the question using only the context\"\n",
    "    \"\\n\\nRetrieved Context: {context}\"\n",
    "    \"\\n\\nUser Question: {question}\"\n",
    "    \"\\nAnswer the user conversationally. User is not aware of context.\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        'context': convstore.as_retriever() | long_reorder | docs2str,\n",
    "        'question': (lambda x:x)\n",
    "    }\n",
    "    | context_prompt\n",
    "    # | RPrint()\n",
    "    | instruct_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "pprint(chain.invoke(\"Where does Beras live?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FSIqTMuuTjIh",
   "metadata": {
    "id": "FSIqTMuuTjIh"
   },
   "source": [
    "Take a second to try out some more invocations and see how the new setup performs. Regardless of your model choice, the following questions should serve as interesting starting points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4jDJwrYpTmpd",
   "metadata": {
    "id": "4jDJwrYpTmpd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Hello there! The Rocky Mountains are a stunning range of mountains that span across North America. Unfortunately, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">without more context, I can't give you a precise location beyond that. However, if you're interested, you can learn</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">more about them by doing some online research or watching informative documentaries!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mHello there! The Rocky Mountains are a stunning range of mountains that span across North America. Unfortunately, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mwithout more context, I can't give you a precise location beyond that. However, if you're interested, you can learn\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmore about them by doing some online research or watching informative documentaries!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"Where are the Rocky Mountains?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652de620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Absolutely, I can help with that! The Rocky Mountains, often referred to as the </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Rockies,\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> are a major mountain </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">range in western North America. They stretch all the way from the northernmost part of British Columbia, in western</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Canada, to New Mexico in the Southwestern United States. So, they span across several states and provinces in North</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">America.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAbsolutely, I can help with that! The Rocky Mountains, often referred to as the \u001b[0m\u001b[32m\"Rockies,\"\u001b[0m\u001b[1;38;2;118;185;0m are a major mountain \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrange in western North America. They stretch all the way from the northernmost part of British Columbia, in western\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mCanada, to New Mexico in the Southwestern United States. So, they span across several states and provinces in North\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mAmerica.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"Do you know Rocky Mountains? If so, tell me the location now\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-artagLfTpBy",
   "metadata": {
    "id": "-artagLfTpBy"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">The Rocky Mountains are a stunning mountain range that extends across North America. While they're not directly </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">close to California, they do reach as far south as New Mexico. If you're traveling from California, you could </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">certainly visit some parts of the Rocky Mountains with a bit of journeying. They're truly a sight to behold!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mThe Rocky Mountains are a stunning mountain range that extends across North America. While they're not directly \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mclose to California, they do reach as far south as New Mexico. If you're traveling from California, you could \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcertainly visit some parts of the Rocky Mountains with a bit of journeying. They're truly a sight to behold!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"Where are the Rocky Mountains? Are they close to California?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GDgjdfdpTrV5",
   "metadata": {
    "id": "GDgjdfdpTrV5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Unfortunately, the context doesn't provide information on Beras' exact location or distance from the Rocky </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Mountains. I do know that Beras mentioned living in the Arctic, which is quite far from the Rockies geographically.</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">The Rocky Mountains are a vast mountain range located mostly in the western United States and Canada.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mUnfortunately, the context doesn't provide information on Beras' exact location or distance from the Rocky \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mMountains. I do know that Beras mentioned living in the Arctic, which is quite far from the Rockies geographically.\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mThe Rocky Mountains are a vast mountain range located mostly in the western United States and Canada.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"How far away is Beras from the Rocky Mountains?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8wp9-8CbT0L9",
   "metadata": {
    "id": "8wp9-8CbT0L9"
   },
   "source": [
    "<br>\n",
    "\n",
    "You might notice some decent performance with this always-on retrieval node in the loop since the actual context being fed into the LLM remains relatively small. It's important to experiment with factors like embedding sizes, context limits, and model options to see what kinds of behavior you can expect and which efforts are worth taking to improve performance.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OnpOybOhUCTf",
   "metadata": {
    "id": "OnpOybOhUCTf"
   },
   "source": [
    "### **Step 4:** Automatic Conversation Storage\n",
    "\n",
    "Now that we see how our vector store memory unit should function, we can perform one last integration to allow our conversation to add new entries to our conversation: a runnable that calls the `add_texts` method for us to update the store state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "FsK6-AtRVdcZ",
   "metadata": {
    "id": "FsK6-AtRVdcZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">While I'm sure the Rocky Mountains would provide a magnificent backdrop for enjoying ice cream, it seems like your </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">excitement has taken a tasty turn! The Rockies are indeed awe-inspiring, spanning North America and offering </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">breathtaking views and adventures. However, let's not forget about that delicious ice cream! While it may not be a </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">traditional part of the Rockies experience, there's no reason we can't incorporate it into our daydreams about </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">visiting this stunning mountain range! It's always great to keep our taste buds in mind while planning our </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">explorations.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mWhile I'm sure the Rocky Mountains would provide a magnificent backdrop for enjoying ice cream, it seems like your \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mexcitement has taken a tasty turn! The Rockies are indeed awe-inspiring, spanning North America and offering \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mbreathtaking views and adventures. However, let's not forget about that delicious ice cream! While it may not be a \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mtraditional part of the Rockies experience, there's no reason we can't incorporate it into our daydreams about \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mvisiting this stunning mountain range! It's always great to keep our taste buds in mind while planning our \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mexplorations.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Given our conversation, I'd wager a guess that ice cream might just be your favorite food! After all, you did </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">express your enthusiasm about enjoying some ice cream amidst the stunning views of the Rocky Mountains. Remember, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">though, this is just a friendly guess based on our recent chat.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mGiven our conversation, I'd wager a guess that ice cream might just be your favorite food! After all, you did \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mexpress your enthusiasm about enjoying some ice cream amidst the stunning views of the Rocky Mountains. Remember, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthough, this is just a friendly guess based on our recent chat.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">I see! Well, I must admit, the joy you shared about savoring ice cream while surrounded by the awe-inspiring views </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">of the Rocky Mountains led me to believe it was your favorite. Ice cream is indeed delightful, but honey is just as</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">wonderful! Just like how the Rockies can't be fully appreciated without seeing them firsthand, the true essence of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">honey is best experienced by tasting it. It's always exciting to discover more about one's preferences, isn't it? </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">The world is full of sweet surprises, and honey is definitely one of them.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mI see! Well, I must admit, the joy you shared about savoring ice cream while surrounded by the awe-inspiring views \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mof the Rocky Mountains led me to believe it was your favorite. Ice cream is indeed delightful, but honey is just as\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mwonderful! Just like how the Rockies can't be fully appreciated without seeing them firsthand, the true essence of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mhoney is best experienced by tasting it. It's always exciting to discover more about one's preferences, isn't it? \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mThe world is full of sweet surprises, and honey is definitely one of them.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Of course! Based on our conversation, I now know that honey is your favorite food! It turns out, my guess about ice</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">cream wasn't quite on the mark, but it led to a sweet discovery nonetheless. Now, I'm even more curious to hear </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">about other foods you cherish. Is there any specific reason why honey holds a special place in your heart?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mOf course! Based on our conversation, I now know that honey is your favorite food! It turns out, my guess about ice\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcream wasn't quite on the mark, but it led to a sweet discovery nonetheless. Now, I'm even more curious to hear \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mabout other foods you cherish. Is there any specific reason why honey holds a special place in your heart?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "########################################################################\n",
    "## Reset knowledge base and define what it means to add more messages.\n",
    "convstore = FAISS.from_texts(conversation, embedding=embedder)\n",
    "\n",
    "def save_memory_and_get_output(d, vstore):\n",
    "    \"\"\"Accepts 'input'/'output' dictionary and saves to convstore\"\"\"\n",
    "    vstore.add_texts([f\"User said {d.get('input')}\", f\"Agent said {d.get('output')}\"])\n",
    "    return d.get('output')\n",
    "\n",
    "########################################################################\n",
    "\n",
    "# instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x22b-instruct-v0.1\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Answer the question using only the context\"\n",
    "    \"\\n\\nRetrieved Context: {context}\"\n",
    "    \"\\n\\nUser Question: {input}\"\n",
    "    \"\\nAnswer the user conversationally. Make sure the conversation flows naturally.\\n\"\n",
    "    \"[Agent]\"\n",
    ")\n",
    "\n",
    "\n",
    "conv_chain = (\n",
    "    {\n",
    "        'context': convstore.as_retriever() | long_reorder | docs2str,\n",
    "        'input': (lambda x:x)\n",
    "    }\n",
    "    | RunnableAssign({'output' : chat_prompt | instruct_llm | StrOutputParser()})\n",
    "    | partial(save_memory_and_get_output, vstore=convstore)\n",
    ")\n",
    "\n",
    "pprint(conv_chain.invoke(\"I'm glad you agree! I can't wait to get some ice cream there! It's such a good food!\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"Can you guess what my favorite food is?\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"Actually, my favorite is honey! Not sure where you got that idea?\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"I see! Fair enough! Do you know my favorite food now?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KRMW6G7NVSWF",
   "metadata": {
    "id": "KRMW6G7NVSWF"
   },
   "source": [
    "Unlike the more automatic full-text or rule-based approaches to injecting context into the LLM, this approach ensures some amount of consolidation which can keep the context length from getting out of hand. It's still not a full-proof strategy on its own, but it's a stark improvement for unstructured conversations (and doesn't even require a strong instruction-tuned model to perform slot-filling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9TPkh3SaLbqh",
   "metadata": {
    "id": "9TPkh3SaLbqh"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 3 [Exercise]:** RAG For Document Chunk Retrieval\n",
    "\n",
    "Given our prior exploration of document loading, the idea that data chunks can be embedded and searched through probably isn't surprising. With that said, it is definitely worth going over since applying RAG with documents is a double-edged sword; it may **seem** to work well out of the box but requires some extra care when optimizing it for truly reliable performance. It also provides an excellent opportunity to review some fundamental LCEL skills, so let's see what we can do!\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Exercise:**\n",
    "\n",
    "In the previous example, you may recall that we pulled in some relatively small papers with the help of [`ArxivLoader`](https://python.langchain.com/docs/integrations/document_loaders/arxiv) using the following syntax:\n",
    "\n",
    "```python\n",
    "from langchain.document_loaders import ArxivLoader\n",
    "\n",
    "docs = [\n",
    "    ArxivLoader(query=\"2205.00445\").load(),  ## MRKL\n",
    "    ArxivLoader(query=\"2210.03629\").load(),  ## ReAct\n",
    "]\n",
    "```\n",
    "\n",
    "Given all that you've learned so far, choose a selection of papers that you would like to use and develop a chatbot that can talk about them!\n",
    "\n",
    "<br>\n",
    "\n",
    "Though this is a pretty big task, a walkthrough of ***most*** of the process will be provided below. By the end of the walkthrough, many of the necessary puzzle pieces will be provided, and your real task will be to integrate them together for the final `retrieval_chain`. When you're done, get ready to re-integrate the chain (or a flavor of your choice) in the last notebook as part of the evaluation exercise!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jSjfCtiQnj9e",
   "metadata": {
    "id": "jSjfCtiQnj9e"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Task 1**: Loading And Chunking Your Documents\n",
    "\n",
    "The following code block gives you some default papers to load in for your RAG chain. Feel free to select more papers as desired, but note that longer documents will take longer to process. A few simplifying assumptions and additional processing steps are included to help you improve your naive RAG performance:\n",
    "\n",
    "- Documents are cut off prior to the \"References\" section if one exists. This will keep our system from considering the citations and appendix sections, which tend to be long and distracting.\n",
    "\n",
    "- A chunk that lists the available documents is inserted to provide a high-level view of all available documents in a single chunk. If your pipeline does not provide metadata on each retrieval, this is a useful component and can even be listed among a list of higher-priority pieces if appropriate.\n",
    "\n",
    "- Additionally, the metadata entries are also inserted to provide general information. Ideally, there would also be some synthetic chunks that merge the metadata into interesting cross-document chunks.\n",
    "\n",
    "**NOTE:** ***For the sake of the assessment, please include at least one paper that is less than one month old!***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "S-3FBdT_lhVT",
   "metadata": {
    "id": "S-3FBdT_lhVT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Documents\n",
      "Chunking Documents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Available Documents:</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Attention Is All You Need</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">sources and discrete reasoning</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Mistral 7B</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Extracting Causal Relations in Deep Knowledge Tracing </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAvailable Documents:\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Attention Is All You Need\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msources and discrete reasoning\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Mistral 7B\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Extracting Causal Relations in Deep Knowledge Tracing \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0\n",
      " - # Chunks: 35\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2023-08-02'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Attention Is All You Need'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Kaiser, Illia Polosukhin'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'The dominant sequence transduction models are based on complex recurrent or convolutional neural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks show these models to be superior in quality while being more parallelizable and requiring significantly less </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a small fraction of the training costs of the best models from the literature. We show that the Transformer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generalizes well to other tasks by applying it successfully to English constituency parsing both with large and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">limited training data.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2023-08-02'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Attention Is All You Need'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz \u001b[0m\n",
       "\u001b[32mKaiser, Illia Polosukhin'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'The dominant sequence transduction models are based on complex recurrent or convolutional neural \u001b[0m\n",
       "\u001b[32mnetworks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder \u001b[0m\n",
       "\u001b[32mthrough an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on \u001b[0m\n",
       "\u001b[32mattention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation \u001b[0m\n",
       "\u001b[32mtasks show these models to be superior in quality while being more parallelizable and requiring significantly less \u001b[0m\n",
       "\u001b[32mtime to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the \u001b[0m\n",
       "\u001b[32mexisting best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our \u001b[0m\n",
       "\u001b[32mmodel establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs,\u001b[0m\n",
       "\u001b[32ma small fraction of the training costs of the best models from the literature. We show that the Transformer \u001b[0m\n",
       "\u001b[32mgeneralizes well to other tasks by applying it successfully to English constituency parsing both with large and \u001b[0m\n",
       "\u001b[32mlimited training data.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1\n",
      " - # Chunks: 45\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2019-05-24'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'We introduce a new language representation model called BERT, which stands for Bidirectional </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">layer to create state-of-the-art models for a wide range of tasks, such as question answering and language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">inference, without substantial task-specific architecture modifications.\\n  BERT is conceptually simple and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">v2.0 Test F1 to 83.1 (5.1 point absolute improvement).'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2019-05-24'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'We introduce a new language representation model called BERT, which stands for Bidirectional \u001b[0m\n",
       "\u001b[32mEncoder Representations from Transformers. Unlike recent language representation models, BERT is designed to \u001b[0m\n",
       "\u001b[32mpre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right \u001b[0m\n",
       "\u001b[32mcontext in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output \u001b[0m\n",
       "\u001b[32mlayer to create state-of-the-art models for a wide range of tasks, such as question answering and language \u001b[0m\n",
       "\u001b[32minference, without substantial task-specific architecture modifications.\\n  BERT is conceptually simple and \u001b[0m\n",
       "\u001b[32mempirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, \u001b[0m\n",
       "\u001b[32mincluding pushing the GLUE score to 80.5% \u001b[0m\u001b[32m(\u001b[0m\u001b[32m7.7% point absolute improvement\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, MultiNLI accuracy to 86.7% \u001b[0m\u001b[32m(\u001b[0m\u001b[32m4.6% \u001b[0m\n",
       "\u001b[32mabsolute improvement\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, SQuAD v1.1 question answering Test F1 to 93.2 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1.5 point absolute improvement\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and SQuAD \u001b[0m\n",
       "\u001b[32mv2.0 Test F1 to 83.1 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m5.1 point absolute improvement\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 2\n",
      " - # Chunks: 46\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-04-12'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel, Sebastian Riedel, Douwe Kiela'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Large pre-trained language models have been shown to store factual knowledge in their parameters, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the same retrieved passages across the whole generated sequence, the other can use different passages per token. We</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language than a state-of-the-art parametric-only seq2seq baseline.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2021-04-12'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, \u001b[0m\n",
       "\u001b[32mHeinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel, Sebastian Riedel, Douwe Kiela'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Large pre-trained language models have been shown to store factual knowledge in their parameters, \u001b[0m\n",
       "\u001b[32mand achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and \u001b[0m\n",
       "\u001b[32mprecisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags \u001b[0m\n",
       "\u001b[32mbehind task-specific architectures. Additionally, providing provenance for their decisions and updating their world\u001b[0m\n",
       "\u001b[32mknowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit \u001b[0m\n",
       "\u001b[32mnon-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream \u001b[0m\n",
       "\u001b[32mtasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRAG\u001b[0m\u001b[32m)\u001b[0m\u001b[32m -- models which \u001b[0m\n",
       "\u001b[32mcombine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the\u001b[0m\n",
       "\u001b[32mparametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of \u001b[0m\n",
       "\u001b[32mWikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on \u001b[0m\n",
       "\u001b[32mthe same retrieved passages across the whole generated sequence, the other can use different passages per token. We\u001b[0m\n",
       "\u001b[32mfine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on \u001b[0m\n",
       "\u001b[32mthree open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract \u001b[0m\n",
       "\u001b[32marchitectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual \u001b[0m\n",
       "\u001b[32mlanguage than a state-of-the-art parametric-only seq2seq baseline.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 3\n",
      " - # Chunks: 40\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2022-05-01'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge sources and discrete reasoning'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Bata, Yoav Levine, Kevin Leyton-Brown, Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Amnon Shashua, Moshe Tenenholtz'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Huge language models (LMs) have ushered in a new era for AI, serving as a gateway to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">natural-language-based knowledge tasks. Although an essential element of modern AI, LMs are also inherently limited</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in a number of ways. We discuss these limitations and how they can be avoided by adopting a systems approach. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Conceptualizing the challenge as one that involves knowledge and reasoning in addition to linguistic processing, we</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">define a flexible architecture with multiple neural models, complemented by discrete knowledge and reasoning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">modules. We describe this neuro-symbolic architecture, dubbed the Modular Reasoning, Knowledge and Language (MRKL, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pronounced \"miracle\") system, some of the technical challenges in implementing it, and Jurassic-X, AI21 Labs\\' MRKL</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system implementation.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2022-05-01'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external \u001b[0m\n",
       "\u001b[32mknowledge sources and discrete reasoning'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit\u001b[0m\n",
       "\u001b[32mBata, Yoav Levine, Kevin Leyton-Brown, Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, \u001b[0m\n",
       "\u001b[32mAmnon Shashua, Moshe Tenenholtz'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Huge language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have ushered in a new era for AI, serving as a gateway to \u001b[0m\n",
       "\u001b[32mnatural-language-based knowledge tasks. Although an essential element of modern AI, LMs are also inherently limited\u001b[0m\n",
       "\u001b[32min a number of ways. We discuss these limitations and how they can be avoided by adopting a systems approach. \u001b[0m\n",
       "\u001b[32mConceptualizing the challenge as one that involves knowledge and reasoning in addition to linguistic processing, we\u001b[0m\n",
       "\u001b[32mdefine a flexible architecture with multiple neural models, complemented by discrete knowledge and reasoning \u001b[0m\n",
       "\u001b[32mmodules. We describe this neuro-symbolic architecture, dubbed the Modular Reasoning, Knowledge and Language \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMRKL, \u001b[0m\n",
       "\u001b[32mpronounced \"miracle\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m system, some of the technical challenges in implementing it, and Jurassic-X, AI21 Labs\\' MRKL\u001b[0m\n",
       "\u001b[32msystem implementation.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 4\n",
      " - # Chunks: 21\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2023-10-10'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Mistral 7B'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, L√©lio Renard Lavaud, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timoth√©e Lacroix, William El Sayed'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered for superior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance and efficiency. Mistral 7B outperforms Llama 2 13B across all evaluated benchmarks, and Llama 1 34B in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning, mathematics, and code generation. Our model leverages grouped-query attention (GQA) for faster </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">inference, coupled with sliding window attention (SWA) to effectively handle sequences of arbitrary length with a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reduced inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B -- Instruct, that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">surpasses the Llama 2 13B -- Chat model both on human and automated benchmarks. Our models are released under the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Apache 2.0 license.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2023-10-10'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Mistral 7B'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, \u001b[0m\n",
       "\u001b[32mDiego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, L√©lio Renard Lavaud, \u001b[0m\n",
       "\u001b[32mMarie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timoth√©e Lacroix, William El Sayed'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered for superior \u001b[0m\n",
       "\u001b[32mperformance and efficiency. Mistral 7B outperforms Llama 2 13B across all evaluated benchmarks, and Llama 1 34B in \u001b[0m\n",
       "\u001b[32mreasoning, mathematics, and code generation. Our model leverages grouped-query attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGQA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for faster \u001b[0m\n",
       "\u001b[32minference, coupled with sliding window attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSWA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to effectively handle sequences of arbitrary length with a \u001b[0m\n",
       "\u001b[32mreduced inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B -- Instruct, that \u001b[0m\n",
       "\u001b[32msurpasses the Llama 2 13B -- Chat model both on human and automated benchmarks. Our models are released under the \u001b[0m\n",
       "\u001b[32mApache 2.0 license.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 5\n",
      " - # Chunks: 44\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2023-12-24'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, Ion Stoica'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Evaluating large language model (LLM) based chat assistants is challenging due to their broad </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2023-12-24'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, \u001b[0m\n",
       "\u001b[32mZhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, Ion Stoica'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Evaluating large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m based chat assistants is challenging due to their broad \u001b[0m\n",
       "\u001b[32mcapabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore \u001b[0m\n",
       "\u001b[32musing strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and \u001b[0m\n",
       "\u001b[32mlimitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited \u001b[0m\n",
       "\u001b[32mreasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges \u001b[0m\n",
       "\u001b[32mand human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a \u001b[0m\n",
       "\u001b[32mcrowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and \u001b[0m\n",
       "\u001b[32mcrowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans. \u001b[0m\n",
       "\u001b[32mHence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very \u001b[0m\n",
       "\u001b[32mexpensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by \u001b[0m\n",
       "\u001b[32mevaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations \u001b[0m\n",
       "\u001b[32mwith human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 6\n",
      " - # Chunks: 30\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2025-11-06'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Extracting Causal Relations in Deep Knowledge Tracing'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Kevin Hong, Kia Karbasi, Gregory Pottie'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"A longstanding goal in computational educational research is to develop explainable knowledge </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tracing (KT) models. Deep Knowledge Tracing (DKT), which leverages a Recurrent Neural Network (RNN) to predict </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">student knowledge and performance on exercises, has been proposed as a major advancement over traditional KT </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">methods. Several studies suggest that its performance gains stem from its ability to model bidirectional </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relationships between different knowledge components (KCs) within a course, enabling the inference of a student's </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">understanding of one KC from their performance on others. In this paper, we challenge this prevailing explanation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and demonstrate that DKT's strength lies in its implicit ability to model prerequisite relationships as a causal </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">structure, rather than bidirectional relationships. By pruning exercise relation graphs into Directed Acyclic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Graphs (DAGs) and training DKT on causal subsets of the Assistments dataset, we show that DKT's predictive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capabilities align strongly with these causal structures. Furthermore, we propose an alternative method for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">extracting exercise relation DAGs using DKT's learned representations and provide empirical evidence supporting our</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">claim. Our findings suggest that DKT's effectiveness is largely driven by its capacity to approximate causal </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dependencies between KCs rather than simple relational mappings.\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2025-11-06'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Extracting Causal Relations in Deep Knowledge Tracing'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Kevin Hong, Kia Karbasi, Gregory Pottie'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"A longstanding goal in computational educational research is to develop explainable knowledge \u001b[0m\n",
       "\u001b[32mtracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m models. Deep Knowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which leverages a Recurrent Neural Network \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRNN\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to predict \u001b[0m\n",
       "\u001b[32mstudent knowledge and performance on exercises, has been proposed as a major advancement over traditional KT \u001b[0m\n",
       "\u001b[32mmethods. Several studies suggest that its performance gains stem from its ability to model bidirectional \u001b[0m\n",
       "\u001b[32mrelationships between different knowledge components \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKCs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m within a course, enabling the inference of a student's \u001b[0m\n",
       "\u001b[32munderstanding of one KC from their performance on others. In this paper, we challenge this prevailing explanation \u001b[0m\n",
       "\u001b[32mand demonstrate that DKT's strength lies in its implicit ability to model prerequisite relationships as a causal \u001b[0m\n",
       "\u001b[32mstructure, rather than bidirectional relationships. By pruning exercise relation graphs into Directed Acyclic \u001b[0m\n",
       "\u001b[32mGraphs \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDAGs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and training DKT on causal subsets of the Assistments dataset, we show that DKT's predictive \u001b[0m\n",
       "\u001b[32mcapabilities align strongly with these causal structures. Furthermore, we propose an alternative method for \u001b[0m\n",
       "\u001b[32mextracting exercise relation DAGs using DKT's learned representations and provide empirical evidence supporting our\u001b[0m\n",
       "\u001b[32mclaim. Our findings suggest that DKT's effectiveness is largely driven by its capacity to approximate causal \u001b[0m\n",
       "\u001b[32mdependencies between KCs rather than simple relational mappings.\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import ArxivLoader\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \";\", \",\", \" \"],\n",
    ")\n",
    "\n",
    "## TODO: Please pick some papers and add them to the list as you'd like\n",
    "## NOTE: To re-use for the final assessment, make sure at least one paper is < 1 month old\n",
    "print(\"Loading Documents\")\n",
    "docs = [\n",
    "    ArxivLoader(query=\"1706.03762\").load(),  ## Attention Is All You Need Paper\n",
    "    ArxivLoader(query=\"1810.04805\").load(),  ## BERT Paper\n",
    "    ArxivLoader(query=\"2005.11401\").load(),  ## RAG Paper\n",
    "    ArxivLoader(query=\"2205.00445\").load(),  ## MRKL Paper\n",
    "    ArxivLoader(query=\"2310.06825\").load(),  ## Mistral Paper\n",
    "    ArxivLoader(query=\"2306.05685\").load(),  ## LLM-as-a-Judge\n",
    "    ArxivLoader(query=\"2511.03948\").load(),  ## Extracting Causal Relations in Deep Knowledge Tracing\n",
    "\n",
    "    ## Some longer papers\n",
    "    # ArxivLoader(query=\"2210.03629\").load(),  ## ReAct Paper\n",
    "    # ArxivLoader(query=\"2112.10752\").load(),  ## Latent Stable Diffusion Paper\n",
    "    # ArxivLoader(query=\"2103.00020\").load(),  ## CLIP Paper\n",
    "    ## TODO: Feel free to add more\n",
    "]\n",
    "\n",
    "## Cut the paper short if references is included.\n",
    "## This is a standard string in papers.\n",
    "for doc in docs:\n",
    "    content = json.dumps(doc[0].page_content)\n",
    "    if \"References\" in content:\n",
    "        doc[0].page_content = content[:content.index(\"References\")]\n",
    "\n",
    "## Split the documents and also filter out stubs (overly short chunks)\n",
    "print(\"Chunking Documents\")\n",
    "docs_chunks = [text_splitter.split_documents(doc) for doc in docs]\n",
    "docs_chunks = [[c for c in dchunks if len(c.page_content) > 200] for dchunks in docs_chunks]\n",
    "\n",
    "## Make some custom Chunks to give big-picture details\n",
    "doc_string = \"Available Documents:\"\n",
    "doc_metadata = []\n",
    "for chunks in docs_chunks:\n",
    "    metadata = getattr(chunks[0], 'metadata', {})\n",
    "    doc_string += \"\\n - \" + metadata.get('Title')\n",
    "    doc_metadata += [str(metadata)]\n",
    "\n",
    "extra_chunks = [doc_string] + doc_metadata\n",
    "\n",
    "## Printing out some summary information for reference\n",
    "pprint(doc_string, '\\n')\n",
    "for i, chunks in enumerate(docs_chunks):\n",
    "    print(f\"Document {i}\")\n",
    "    print(f\" - # Chunks: {len(chunks)}\")\n",
    "    print(f\" - Metadata: \")\n",
    "    pprint(chunks[0].metadata)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4pWU_OOnnrsT",
   "metadata": {
    "id": "4pWU_OOnnrsT"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Task 2**: Construct Your Document Vector Stores\n",
    "\n",
    "Now that we have all of the components, we can go ahead and create indices surrounding them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lwwmr3aptwCg",
   "metadata": {
    "id": "lwwmr3aptwCg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Vector Stores\n",
      "CPU times: total: 2.97 s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Constructing Vector Stores\")\n",
    "vecstores = [FAISS.from_texts(extra_chunks, embedder)]\n",
    "vecstores += [FAISS.from_documents(doc_chunks, embedder) for doc_chunks in docs_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j39JwCKubto0",
   "metadata": {
    "id": "j39JwCKubto0"
   },
   "source": [
    "<br>\n",
    "\n",
    "From there, we can combine our indices into a single one using the following utility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "Q7us66iPVc70",
   "metadata": {
    "id": "Q7us66iPVc70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed aggregate docstore with 269 chunks\n"
     ]
    }
   ],
   "source": [
    "from faiss import IndexFlatL2\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "embed_dims = len(embedder.embed_query(\"test\"))\n",
    "def default_FAISS():\n",
    "    '''Useful utility for making an empty FAISS vectorstore'''\n",
    "    return FAISS(\n",
    "        embedding_function=embedder,\n",
    "        index=IndexFlatL2(embed_dims),\n",
    "        docstore=InMemoryDocstore(),\n",
    "        index_to_docstore_id={},\n",
    "        normalize_L2=False\n",
    "    )\n",
    "\n",
    "def aggregate_vstores(vectorstores):\n",
    "    ## Initialize an empty FAISS Index and merge others into it\n",
    "    ## We'll use default_faiss for simplicity, though it's tied to your embedder by reference\n",
    "    agg_vstore = default_FAISS()\n",
    "    for vstore in vectorstores:\n",
    "        agg_vstore.merge_from(vstore)\n",
    "    return agg_vstore\n",
    "\n",
    "## Unintuitive optimization; merge_from seems to optimize constituent vector stores away\n",
    "docstore = aggregate_vstores(vecstores)\n",
    "\n",
    "print(f\"Constructed aggregate docstore with {len(docstore.docstore._dict)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VU_VEx2mqJUK",
   "metadata": {
    "id": "VU_VEx2mqJUK"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Task 3: [Exercise]** Implement Your RAG Chain\n",
    "\n",
    "Finally, all the puzzle pieces are in place to implement the RAG pipeline! As a review, we now have:\n",
    "\n",
    "- A way to construct a from-scratch vector store for conversational memory (and a way to initialize an empty one with `default_FAISS()`)\n",
    "\n",
    "- A vector store pre-loaded with useful document information from our `ArxivLoader` utility (stored in `docstore`).\n",
    "\n",
    "With the help of a couple more utilities, you're finally ready to integrate your chain! A few additional convenience utilities are provided (`doc2str` and the now-common `RPrint`) but are optional to use. Additionally, some starter prompts and structures are also defined.\n",
    "\n",
    "> **Given all of this:** Please implement the `retrieval_chain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "-RXSrb1GcNff",
   "metadata": {
    "id": "-RXSrb1GcNff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptValue</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">messages</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SystemMessage</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'You are a document chatbot. Help the user as they ask questions about documents. User messaged</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">just asked: DKT is what!\\n\\n From this, we have retrieved the following potentially-useful info:  Conversation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">History Retrieval:\\n\\n\\n Document Retrieval:\\n[Quote from Extracting Causal Relations in Deep Knowledge Tracing] </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ercise relation discovery [15]. Their method assigns an in-\\nfluence score Jij to every directed pair of exercises </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">i and\\nj, which is the conditional probability of correctly answer-\\ning exercise j after correctly answering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">exercise i in the\\nprevious timestep, normalized by the sum of such condi-\\ntional probabilities. The influence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">score from i to j quan-\\narXiv:2511.03948v1  [cs.AI]  6 Nov 2025\\ntifies the prerequisite dependency of the concept</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">i on the\\nlearning concept j. We refer to this method as the DKT\\nmethod.\\nDKT‚Äôs superior performance can be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">attributed\\nto the model‚Äôs ability to learn these influence-based depen-\\ndencies to estimate student knowledge. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Many studies have\\nincorporated exercise relations into subsequent KT mod-\\nels to improve performance and enhance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interpretability in\\nthe prediction process.\\nFor example, Hierarchical Graph\\nKnowledge Tracing (HGKT) [17], </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Structure-based Knowl-\\nedge Tracing (SKT) [18], and Deep Knowledge Tracing with\\n[Quote from Extracting Causal </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Relations in Deep Knowledge Tracing] structure. We formalize this by pruning exercise relations\\ngraphs into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Directed Acyclic Graphs (DAGs) to reflect pre-\\nrequisite relations, and show that DKT‚Äôs predictive perfor-\\nmance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">improves when trained on data filtered through these\\ncausal structures. We also introduce an alternative </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">method\\nfor extracting exercise relations that yields accurate and\\nmore stable representations of student </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge and un-\\nderlying concept dependencies. To facilitate future research\\non these ideas, we have published </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">our code 1.\\n2.\\nMETHODOLOGY\\nWe conduct our study using the Assistments datasets, which\\nare among the largest </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">publicly available KT datasets and are\\nwidely used as benchmarks for KT models [1, 8, 16]. These\\ndatasets capture</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">student interactions over extended periods\\nof time and across a wide range of exercises in grade </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">school\\nmathematics. We utilize three datasets: Assistments 2009\\n2 (skill builder data corrected collapsed), </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Assistments 2012 3\\n[Quote from Extracting Causal Relations in Deep Knowledge Tracing] gent tutoring systems [9, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">11], enables personalizing activities\\nto suit individuals with varying levels of proficiency. A key\\ncomponent of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">these adaptive systems is knowledge tracing\\n(KT), which aims to estimate students‚Äô mastery of several\\nexercise </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">concepts, known as knowledge components (KCs),\\nas they interact with the corresponding exercises [2, 5]. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">For-\\nmally, xi = {et, at} represents a student‚Äôs answer pair, where\\net represents the exercise ID, and at </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">represents whether the\\nstudent answered correctly or incorrectly. Given a series of\\npast interactions, X = {x1, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">x2, . . . , xt} and the next con-\\ncept exercise, et+1, the task of the KT model is to estimate\\nthe likelihood of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the student answering correctly, at+1 [6].\\nTraditionally, Bayesian Knowledge Tracing (BKT) [6] was\\nused to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">perform KT. Despite its popularity, BKT is often\\ncritiqued for its binary representation of knowledge </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">states\\n(mastered or not mastered) which oversimplifies the learn-\\n[Quote from Extracting Causal Relations in Deep</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Knowledge Tracing] (mastered or not mastered) which oversimplifies the learn-\\ning process. Several models were </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">later proposed to address\\nthese limitations. Learning Factors Analysis\\n[4] improved\\nupon BKT by representing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learning as a continuous pro-\\ncess influenced by multiple exercise interactions and accu-\\nmulated practice. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Performance Factors Analysis [10] further\\ncaptured the complexity of learning by tracking the effects\\nof correct </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and incorrect prior exercise attempts on perfor-\\nmance. These developments laid the groundwork for Deep\\nKnowledge</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Tracing (DKT) [15], which popularized a key\\nextension to KT: the ability to implicitly infer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relationships\\nbetween exercises.\\nThe relationships between exercises can take the form of\\nprerequisite </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dependencies, where understanding one exer-\\ncise improves performance on another, or corequisites, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">where\\nexercises depend on each other. Researchers have demon-\\nstrated that exercise relationships can be mapped </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into an ex-\\n\\n\\n (Answer only from retrieval. Only cite sources that are used. Make your response </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conversational.)'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">additional_kwargs</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response_metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={}</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'DKT is what!'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">additional_kwargs</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={}, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response_metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={})</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ]</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatPromptValue\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;33mmessages\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;35mSystemMessage\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mcontent\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'You are a document chatbot. Help the user as they ask questions about documents. User messaged\u001b[0m\n",
       "\u001b[32mjust asked: DKT is what!\\n\\n From this, we have retrieved the following potentially-useful info:  Conversation \u001b[0m\n",
       "\u001b[32mHistory Retrieval:\\n\\n\\n Document Retrieval:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Extracting Causal Relations in Deep Knowledge Tracing\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mercise relation discovery \u001b[0m\u001b[32m[\u001b[0m\u001b[32m15\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. Their method assigns an in-\\nfluence score Jij to every directed pair of exercises \u001b[0m\n",
       "\u001b[32mi and\\nj, which is the conditional probability of correctly answer-\\ning exercise j after correctly answering \u001b[0m\n",
       "\u001b[32mexercise i in the\\nprevious timestep, normalized by the sum of such condi-\\ntional probabilities. The influence \u001b[0m\n",
       "\u001b[32mscore from i to j quan-\\narXiv:2511.03948v1  \u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs.AI\u001b[0m\u001b[32m]\u001b[0m\u001b[32m  6 Nov 2025\\ntifies the prerequisite dependency of the concept\u001b[0m\n",
       "\u001b[32mi on the\\nlearning concept j. We refer to this method as the DKT\\nmethod.\\nDKT‚Äôs superior performance can be \u001b[0m\n",
       "\u001b[32mattributed\\nto the model‚Äôs ability to learn these influence-based depen-\\ndencies to estimate student knowledge. \u001b[0m\n",
       "\u001b[32mMany studies have\\nincorporated exercise relations into subsequent KT mod-\\nels to improve performance and enhance \u001b[0m\n",
       "\u001b[32minterpretability in\\nthe prediction process.\\nFor example, Hierarchical Graph\\nKnowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHGKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32m17\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mStructure-based Knowl-\\nedge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32m18\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, and Deep Knowledge Tracing with\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Extracting Causal \u001b[0m\n",
       "\u001b[32mRelations in Deep Knowledge Tracing\u001b[0m\u001b[32m]\u001b[0m\u001b[32m structure. We formalize this by pruning exercise relations\\ngraphs into \u001b[0m\n",
       "\u001b[32mDirected Acyclic Graphs \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDAGs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to reflect pre-\\nrequisite relations, and show that DKT‚Äôs predictive perfor-\\nmance \u001b[0m\n",
       "\u001b[32mimproves when trained on data filtered through these\\ncausal structures. We also introduce an alternative \u001b[0m\n",
       "\u001b[32mmethod\\nfor extracting exercise relations that yields accurate and\\nmore stable representations of student \u001b[0m\n",
       "\u001b[32mknowledge and un-\\nderlying concept dependencies. To facilitate future research\\non these ideas, we have published \u001b[0m\n",
       "\u001b[32mour code 1.\\n2.\\nMETHODOLOGY\\nWe conduct our study using the Assistments datasets, which\\nare among the largest \u001b[0m\n",
       "\u001b[32mpublicly available KT datasets and are\\nwidely used as benchmarks for KT models \u001b[0m\u001b[32m[\u001b[0m\u001b[32m1, 8, 16\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. These\\ndatasets capture\u001b[0m\n",
       "\u001b[32mstudent interactions over extended periods\\nof time and across a wide range of exercises in grade \u001b[0m\n",
       "\u001b[32mschool\\nmathematics. We utilize three datasets: Assistments 2009\\n2 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mskill builder data corrected collapsed\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mAssistments 2012 3\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Extracting Causal Relations in Deep Knowledge Tracing\u001b[0m\u001b[32m]\u001b[0m\u001b[32m gent tutoring systems \u001b[0m\u001b[32m[\u001b[0m\u001b[32m9, \u001b[0m\n",
       "\u001b[32m11\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, enables personalizing activities\\nto suit individuals with varying levels of proficiency. A key\\ncomponent of \u001b[0m\n",
       "\u001b[32mthese adaptive systems is knowledge tracing\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which aims to estimate students‚Äô mastery of several\\nexercise \u001b[0m\n",
       "\u001b[32mconcepts, known as knowledge components \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKCs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m,\\nas they interact with the corresponding exercises \u001b[0m\u001b[32m[\u001b[0m\u001b[32m2, 5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. \u001b[0m\n",
       "\u001b[32mFor-\\nmally, xi = \u001b[0m\u001b[32m{\u001b[0m\u001b[32met, at\u001b[0m\u001b[32m}\u001b[0m\u001b[32m represents a student‚Äôs answer pair, where\\net represents the exercise ID, and at \u001b[0m\n",
       "\u001b[32mrepresents whether the\\nstudent answered correctly or incorrectly. Given a series of\\npast interactions, X = \u001b[0m\u001b[32m{\u001b[0m\u001b[32mx1, \u001b[0m\n",
       "\u001b[32mx2, . . . , xt\u001b[0m\u001b[32m}\u001b[0m\u001b[32m and the next con-\\ncept exercise, et+1, the task of the KT model is to estimate\\nthe likelihood of \u001b[0m\n",
       "\u001b[32mthe student answering correctly, at+1 \u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m.\\nTraditionally, Bayesian Knowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m was\\nused to \u001b[0m\n",
       "\u001b[32mperform KT. Despite its popularity, BKT is often\\ncritiqued for its binary representation of knowledge \u001b[0m\n",
       "\u001b[32mstates\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mmastered or not mastered\u001b[0m\u001b[32m)\u001b[0m\u001b[32m which oversimplifies the learn-\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Extracting Causal Relations in Deep\u001b[0m\n",
       "\u001b[32mKnowledge Tracing\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m(\u001b[0m\u001b[32mmastered or not mastered\u001b[0m\u001b[32m)\u001b[0m\u001b[32m which oversimplifies the learn-\\ning process. Several models were \u001b[0m\n",
       "\u001b[32mlater proposed to address\\nthese limitations. Learning Factors Analysis\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m improved\\nupon BKT by representing \u001b[0m\n",
       "\u001b[32mlearning as a continuous pro-\\ncess influenced by multiple exercise interactions and accu-\\nmulated practice. \u001b[0m\n",
       "\u001b[32mPerformance Factors Analysis \u001b[0m\u001b[32m[\u001b[0m\u001b[32m10\u001b[0m\u001b[32m]\u001b[0m\u001b[32m further\\ncaptured the complexity of learning by tracking the effects\\nof correct \u001b[0m\n",
       "\u001b[32mand incorrect prior exercise attempts on perfor-\\nmance. These developments laid the groundwork for Deep\\nKnowledge\u001b[0m\n",
       "\u001b[32mTracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32m15\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, which popularized a key\\nextension to KT: the ability to implicitly infer \u001b[0m\n",
       "\u001b[32mrelationships\\nbetween exercises.\\nThe relationships between exercises can take the form of\\nprerequisite \u001b[0m\n",
       "\u001b[32mdependencies, where understanding one exer-\\ncise improves performance on another, or corequisites, \u001b[0m\n",
       "\u001b[32mwhere\\nexercises depend on each other. Researchers have demon-\\nstrated that exercise relationships can be mapped \u001b[0m\n",
       "\u001b[32minto an ex-\\n\\n\\n \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAnswer only from retrieval. Only cite sources that are used. Make your response \u001b[0m\n",
       "\u001b[32mconversational.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33madditional_kwargs\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mresponse_metadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;35mHumanMessage\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;33mcontent\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'DKT is what!'\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[1;33madditional_kwargs\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[1;33mresponse_metadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DKT, or Deep Knowledge Tracing, is a method used in the field of education to estimate student knowledge and learning progression. It's a data-driven approach that uses machine learning algorithms to model students' mastery of various knowledge components (KCs) as they interact with corresponding exercises. DKT is known for its ability to implicitly infer relationships between exercises, which can be prerequisite dependencies or corequisites. This method outperforms traditional techniques like Bayesian Knowledge Tracing (BKT) by representing learning as a continuous process influenced by multiple exercise interactions.\n",
      "\n",
      "The DKT method assigns an influence score Jij to every directed pair of exercises i and j, which is the conditional probability of correctly answering exercise j after correctly answering exercise i in the previous timestep. This influence score quantifies the prerequisite dependency of the concept i on the learning concept j. The DKT's superior performance is attributed to the model's ability to learn these influence-based dependencies.\n",
      "\n",
      "To clarify further, the DKT method is detailed in the paper \"Extracting Causal Relations in Deep Knowledge Tracing\" (arXiv:2511.03948v1 [cs.AI], November 6, 2025). The authors discuss how DKT improves predictive performance when trained on data filtered through Directed Acyclic Graphs (DAGs) that reflect prerequisite relations. Moreover, DKT has been applied in models like Hierarchical Graph Knowledge Tracing (HGKT), Structure-based Knowledge Tracing (SKT), and Deep Knowledge Tracing with Structure, highlighting the significance of incorporating exercise relations into subsequent KT models for better interpretability in the prediction process."
     ]
    }
   ],
   "source": [
    "from langchain.document_transformers import LongContextReorder\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables.passthrough import RunnableAssign\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import gradio as gr\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "\n",
    "# NVIDIAEmbeddings.get_available_models()\n",
    "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\", truncate=\"END\")\n",
    "# ChatNVIDIA.get_available_models()\n",
    "instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\")\n",
    "# instruct_llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\")\n",
    "\n",
    "convstore = default_FAISS()\n",
    "\n",
    "def save_memory_and_get_output(d, vstore):\n",
    "    \"\"\"Accepts 'input'/'output' dictionary and saves to convstore\"\"\"\n",
    "    vstore.add_texts([\n",
    "        f\"User previously responded with {d.get('input')}\",\n",
    "        f\"Agent previously responded with {d.get('output')}\"\n",
    "    ])\n",
    "    return d.get('output')\n",
    "\n",
    "initial_msg = (\n",
    "    \"Hello! I am a document chat agent here to help the user!\"\n",
    "    f\" I have access to the following documents: {doc_string}\\n\\nHow can I help you?\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\",\n",
    "    \"You are a document chatbot. Help the user as they ask questions about documents.\"\n",
    "    \" User messaged just asked: {input}\\n\\n\"\n",
    "    \" From this, we have retrieved the following potentially-useful info: \"\n",
    "    \" Conversation History Retrieval:\\n{history}\\n\\n\"\n",
    "    \" Document Retrieval:\\n{context}\\n\\n\"\n",
    "    \" (Answer only from retrieval. Only cite sources that are used. Make your response conversational.)\"\n",
    "), ('user', '{input}')])\n",
    "\n",
    "stream_chain = chat_prompt| RPrint() | instruct_llm | StrOutputParser()\n",
    "\n",
    "################################################################################################\n",
    "## BEGIN TODO: Implement the retrieval chain to make your system work!\n",
    "\n",
    "retrieval_chain = (\n",
    "    {'input' : (lambda x: x)}\n",
    "    ## TODO: Make sure to retrieve history & context from convstore & docstore, respectively.\n",
    "    ## HINT: Our solution uses RunnableAssign, itemgetter, long_reorder, and docs2str\n",
    "    | RunnableAssign({'history' : itemgetter('input') | convstore.as_retriever() | long_reorder | docs2str})\n",
    "    | RunnableAssign({'context' : itemgetter('input') | docstore.as_retriever() | long_reorder | docs2str})\n",
    ")\n",
    "\n",
    "## END TODO\n",
    "################################################################################################\n",
    "\n",
    "def chat_gen(message, history=[], return_buffer=True):\n",
    "    buffer = \"\"\n",
    "    ## First perform the retrieval based on the input message\n",
    "    retrieval = retrieval_chain.invoke(message)\n",
    "    line_buffer = \"\"\n",
    "\n",
    "    ## Then, stream the results of the stream_chain\n",
    "    for token in stream_chain.stream(retrieval):\n",
    "        buffer += token\n",
    "        ## If you're using standard print, keep line from getting too long\n",
    "        yield buffer if return_buffer else token\n",
    "\n",
    "    ## Lastly, save the chat exchange to the conversation memory buffer\n",
    "    save_memory_and_get_output({'input':  message, 'output': buffer}, convstore)\n",
    "\n",
    "\n",
    "## Start of Agent Event Loop\n",
    "test_question = \"DKT is what!\"  ## <- modify as desired\n",
    "\n",
    "## Before you launch your gradio interface, make sure your thing works\n",
    "for response in chat_gen(test_question, return_buffer=False):\n",
    "    print(response, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9W7sC5Z6BfqM",
   "metadata": {
    "id": "9W7sC5Z6BfqM"
   },
   "source": [
    "### **Task 4:** Interact With Your Gradio Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fMP3l7QL2JWT",
   "metadata": {
    "id": "fMP3l7QL2JWT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okafo\\AppData\\Local\\Temp\\ipykernel_8348\\1029931177.py:1: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(value = [[None, initial_msg]])\n",
      "C:\\Users\\okafo\\AppData\\Roaming\\Python\\Python312\\site-packages\\gradio\\chat_interface.py:331: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'tuples', will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://41821a80a985d60eeb.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://41821a80a985d60eeb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptValue</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">messages</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SystemMessage</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'You are a document chatbot. Help the user as they ask questions about documents. User messaged</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">just asked: I am interested in DKT\\n\\n From this, we have retrieved the following potentially-useful info:  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Conversation History Retrieval:\\n[Quote from Document] User previously responded with DKT is what!\\n[Quote from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Document] Agent previously responded with DKT, or Deep Knowledge Tracing, is a method used in the field of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">education to estimate student knowledge and learning progression. It\\'s a data-driven approach that uses machine </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learning algorithms to model students\\' mastery of various knowledge components (KCs) as they interact with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">corresponding exercises. DKT is known for its ability to implicitly infer relationships between exercises, which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be prerequisite dependencies or corequisites. This method outperforms traditional techniques like Bayesian </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Knowledge Tracing (BKT) by representing learning as a continuous process influenced by multiple exercise </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interactions.\\n\\nThe DKT method assigns an influence score Jij to every directed pair of exercises i and j, which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is the conditional probability of correctly answering exercise j after correctly answering exercise i in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">previous timestep. This influence score quantifies the prerequisite dependency of the concept i on the learning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">concept j. The DKT\\'s superior performance is attributed to the model\\'s ability to learn these influence-based </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dependencies.\\n\\nTo clarify further, the DKT method is detailed in the paper \"Extracting Causal Relations in Deep </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Knowledge Tracing\" (arXiv:2511.03948v1 [cs.AI], November 6, 2025). The authors discuss how DKT improves predictive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance when trained on data filtered through Directed Acyclic Graphs (DAGs) that reflect prerequisite </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relations. Moreover, DKT has been applied in models like Hierarchical Graph Knowledge Tracing (HGKT), </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Structure-based Knowledge Tracing (SKT), and Deep Knowledge Tracing with Structure, highlighting the significance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of incorporating exercise relations into subsequent KT models for better interpretability in the prediction </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">process.\\n\\n\\n Document Retrieval:\\n[Quote from Extracting Causal Relations in Deep Knowledge Tracing] (mastered or</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">not mastered) which oversimplifies the learn-\\ning process. Several models were later proposed to address\\nthese </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">limitations. Learning Factors Analysis\\n[4] improved\\nupon BKT by representing learning as a continuous pro-\\ncess </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">influenced by multiple exercise interactions and accu-\\nmulated practice. Performance Factors Analysis [10] </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">further\\ncaptured the complexity of learning by tracking the effects\\nof correct and incorrect prior exercise </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">attempts on perfor-\\nmance. These developments laid the groundwork for Deep\\nKnowledge Tracing (DKT) [15], which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">popularized a key\\nextension to KT: the ability to implicitly infer relationships\\nbetween exercises.\\nThe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relationships between exercises can take the form of\\nprerequisite dependencies, where understanding one </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">exer-\\ncise improves performance on another, or corequisites, where\\nexercises depend on each other. Researchers </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">have demon-\\nstrated that exercise relationships can be mapped into an ex-\\n[Quote from Extracting Causal Relations</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in Deep Knowledge Tracing] 2 (skill builder data corrected collapsed), Assistments 2012 3\\n(2012-2013 data with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">predictions 4 final), and Assistments\\n2017 4 (anonymized full release competition dataset). The\\n2009 dataset </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contains 346,860 exercise attempts from 4,217\\nstudents across 123 exercises.\\nThe 2012 dataset includes\\n6,123,270</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">attempts from 46,674 students across 265 exer-\\ncises. The 2017 dataset consists of 942,816 attempts from\\n1,709 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">students across 102 exercises.\\nThe datasets do not\\ncontain any personal information.\\nWe use DKT, implemented via</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the pyKT library [13], </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to\\n1https://github.com/kevinhongca/\\ndkt-causal-relations\\n2https://sites.google.com/site/assistmentsdata/\\nhome/2</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">009-2010-assistment-data/\\nskill-builder-data-2009-2010\\n3https://sites.google.com/site/assistmentsdata/\\n2012-13-s</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">chool-data-with-affect\\n4https://sites.google.com/view/\\nassistmentsdatamining/dataset\\nlearn the latent exercise </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relations and help generate the\\ngraphs.\\nWe begin by training a DKT model on each of\\n[Quote from Extracting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Causal Relations in Deep Knowledge Tracing] graphs.\\nWe begin by training a DKT model on each of\\nthe three </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Assistments datasets. Then, we switch the models\\nto evaluation mode and apply the DKT method. To ensure\\nthe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">resulting graph represents a causal structure, we apply\\na minimum threshold to the influence scores.\\nThis </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">filter-\\ning step removes weaker edges that could introduce cycles,\\nallowing us to construct a DAG. Since the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">distribution of in-\\nfluence scores varies across the three datasets, we select the\\nminimum dataset-specific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">thresholds that enforce acyclicity.\\nWe use a threshold of 0.0107 for Assistments 2009, 0.0051\\nfor Assistments </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2012, and 0.0139 for Assistments 2017.\\nUsing the exercise relation DAG, we create a causal subset of\\nthe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Assistments dataset by filtering interactions to include\\nonly those involving exercises with at least one incoming</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">or\\noutgoing edge. This ensures that the subset consists exclu-\\nsively of exercises with learned causal </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relationships, which\\n[Quote from Extracting Causal Relations in Deep Knowledge Tracing] ercise relation discovery </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">[15]. Their method assigns an in-\\nfluence score Jij to every directed pair of exercises i and\\nj, which is the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conditional probability of correctly answer-\\ning exercise j after correctly answering exercise i in the\\nprevious </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">timestep, normalized by the sum of such condi-\\ntional probabilities. The influence score from i to j </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quan-\\narXiv:2511.03948v1  [cs.AI]  6 Nov 2025\\ntifies the prerequisite dependency of the concept i on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the\\nlearning concept j. We refer to this method as the DKT\\nmethod.\\nDKT‚Äôs superior performance can be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">attributed\\nto the model‚Äôs ability to learn these influence-based depen-\\ndencies to estimate student knowledge. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Many studies have\\nincorporated exercise relations into subsequent KT mod-\\nels to improve performance and enhance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interpretability in\\nthe prediction process.\\nFor example, Hierarchical Graph\\nKnowledge Tracing (HGKT) [17], </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Structure-based Knowl-\\nedge Tracing (SKT) [18], and Deep Knowledge Tracing with\\n\\n\\n (Answer only from retrieval.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Only cite sources that are used. Make your response conversational.)'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">additional_kwargs</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response_metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={}</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'I am interested in DKT'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">additional_kwargs</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={}, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response_metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={})</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ]</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatPromptValue\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;33mmessages\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;35mSystemMessage\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mcontent\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'You are a document chatbot. Help the user as they ask questions about documents. User messaged\u001b[0m\n",
       "\u001b[32mjust asked: I am interested in DKT\\n\\n From this, we have retrieved the following potentially-useful info:  \u001b[0m\n",
       "\u001b[32mConversation History Retrieval:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Document\u001b[0m\u001b[32m]\u001b[0m\u001b[32m User previously responded with DKT is what!\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from \u001b[0m\n",
       "\u001b[32mDocument\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Agent previously responded with DKT, or Deep Knowledge Tracing, is a method used in the field of \u001b[0m\n",
       "\u001b[32meducation to estimate student knowledge and learning progression. It\\'s a data-driven approach that uses machine \u001b[0m\n",
       "\u001b[32mlearning algorithms to model students\\' mastery of various knowledge components \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKCs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as they interact with \u001b[0m\n",
       "\u001b[32mcorresponding exercises. DKT is known for its ability to implicitly infer relationships between exercises, which \u001b[0m\n",
       "\u001b[32mcan be prerequisite dependencies or corequisites. This method outperforms traditional techniques like Bayesian \u001b[0m\n",
       "\u001b[32mKnowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by representing learning as a continuous process influenced by multiple exercise \u001b[0m\n",
       "\u001b[32minteractions.\\n\\nThe DKT method assigns an influence score Jij to every directed pair of exercises i and j, which \u001b[0m\n",
       "\u001b[32mis the conditional probability of correctly answering exercise j after correctly answering exercise i in the \u001b[0m\n",
       "\u001b[32mprevious timestep. This influence score quantifies the prerequisite dependency of the concept i on the learning \u001b[0m\n",
       "\u001b[32mconcept j. The DKT\\'s superior performance is attributed to the model\\'s ability to learn these influence-based \u001b[0m\n",
       "\u001b[32mdependencies.\\n\\nTo clarify further, the DKT method is detailed in the paper \"Extracting Causal Relations in Deep \u001b[0m\n",
       "\u001b[32mKnowledge Tracing\" \u001b[0m\u001b[32m(\u001b[0m\u001b[32marXiv:2511.03948v1 \u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs.AI\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, November 6, 2025\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The authors discuss how DKT improves predictive \u001b[0m\n",
       "\u001b[32mperformance when trained on data filtered through Directed Acyclic Graphs \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDAGs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m that reflect prerequisite \u001b[0m\n",
       "\u001b[32mrelations. Moreover, DKT has been applied in models like Hierarchical Graph Knowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHGKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mStructure-based Knowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and Deep Knowledge Tracing with Structure, highlighting the significance \u001b[0m\n",
       "\u001b[32mof incorporating exercise relations into subsequent KT models for better interpretability in the prediction \u001b[0m\n",
       "\u001b[32mprocess.\\n\\n\\n Document Retrieval:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Extracting Causal Relations in Deep Knowledge Tracing\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m(\u001b[0m\u001b[32mmastered or\u001b[0m\n",
       "\u001b[32mnot mastered\u001b[0m\u001b[32m)\u001b[0m\u001b[32m which oversimplifies the learn-\\ning process. Several models were later proposed to address\\nthese \u001b[0m\n",
       "\u001b[32mlimitations. Learning Factors Analysis\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m improved\\nupon BKT by representing learning as a continuous pro-\\ncess \u001b[0m\n",
       "\u001b[32minfluenced by multiple exercise interactions and accu-\\nmulated practice. Performance Factors Analysis \u001b[0m\u001b[32m[\u001b[0m\u001b[32m10\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mfurther\\ncaptured the complexity of learning by tracking the effects\\nof correct and incorrect prior exercise \u001b[0m\n",
       "\u001b[32mattempts on perfor-\\nmance. These developments laid the groundwork for Deep\\nKnowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32m15\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, which \u001b[0m\n",
       "\u001b[32mpopularized a key\\nextension to KT: the ability to implicitly infer relationships\\nbetween exercises.\\nThe \u001b[0m\n",
       "\u001b[32mrelationships between exercises can take the form of\\nprerequisite dependencies, where understanding one \u001b[0m\n",
       "\u001b[32mexer-\\ncise improves performance on another, or corequisites, where\\nexercises depend on each other. Researchers \u001b[0m\n",
       "\u001b[32mhave demon-\\nstrated that exercise relationships can be mapped into an ex-\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Extracting Causal Relations\u001b[0m\n",
       "\u001b[32min Deep Knowledge Tracing\u001b[0m\u001b[32m]\u001b[0m\u001b[32m 2 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mskill builder data corrected collapsed\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, Assistments 2012 3\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2012-2013 data with \u001b[0m\n",
       "\u001b[32mpredictions 4 final\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and Assistments\\n2017 4 \u001b[0m\u001b[32m(\u001b[0m\u001b[32manonymized full release competition dataset\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The\\n2009 dataset \u001b[0m\n",
       "\u001b[32mcontains 346,860 exercise attempts from 4,217\\nstudents across 123 exercises.\\nThe 2012 dataset includes\\n6,123,270\u001b[0m\n",
       "\u001b[32mattempts from 46,674 students across 265 exer-\\ncises. The 2017 dataset consists of 942,816 attempts from\\n1,709 \u001b[0m\n",
       "\u001b[32mstudents across 102 exercises.\\nThe datasets do not\\ncontain any personal information.\\nWe use DKT, implemented via\u001b[0m\n",
       "\u001b[32mthe pyKT library \u001b[0m\u001b[32m[\u001b[0m\u001b[32m13\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mto\\n1https://github.com/kevinhongca/\\ndkt-causal-relations\\n2https://sites.google.com/site/assistmentsdata/\\nhome/2\u001b[0m\n",
       "\u001b[32m009-2010-assistment-data/\\nskill-builder-data-2009-2010\\n3https://sites.google.com/site/assistmentsdata/\\n2012-13-s\u001b[0m\n",
       "\u001b[32mchool-data-with-affect\\n4https://sites.google.com/view/\\nassistmentsdatamining/dataset\\nlearn the latent exercise \u001b[0m\n",
       "\u001b[32mrelations and help generate the\\ngraphs.\\nWe begin by training a DKT model on each of\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Extracting \u001b[0m\n",
       "\u001b[32mCausal Relations in Deep Knowledge Tracing\u001b[0m\u001b[32m]\u001b[0m\u001b[32m graphs.\\nWe begin by training a DKT model on each of\\nthe three \u001b[0m\n",
       "\u001b[32mAssistments datasets. Then, we switch the models\\nto evaluation mode and apply the DKT method. To ensure\\nthe \u001b[0m\n",
       "\u001b[32mresulting graph represents a causal structure, we apply\\na minimum threshold to the influence scores.\\nThis \u001b[0m\n",
       "\u001b[32mfilter-\\ning step removes weaker edges that could introduce cycles,\\nallowing us to construct a DAG. Since the \u001b[0m\n",
       "\u001b[32mdistribution of in-\\nfluence scores varies across the three datasets, we select the\\nminimum dataset-specific \u001b[0m\n",
       "\u001b[32mthresholds that enforce acyclicity.\\nWe use a threshold of 0.0107 for Assistments 2009, 0.0051\\nfor Assistments \u001b[0m\n",
       "\u001b[32m2012, and 0.0139 for Assistments 2017.\\nUsing the exercise relation DAG, we create a causal subset of\\nthe \u001b[0m\n",
       "\u001b[32mAssistments dataset by filtering interactions to include\\nonly those involving exercises with at least one incoming\u001b[0m\n",
       "\u001b[32mor\\noutgoing edge. This ensures that the subset consists exclu-\\nsively of exercises with learned causal \u001b[0m\n",
       "\u001b[32mrelationships, which\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Extracting Causal Relations in Deep Knowledge Tracing\u001b[0m\u001b[32m]\u001b[0m\u001b[32m ercise relation discovery \u001b[0m\n",
       "\u001b[32m[\u001b[0m\u001b[32m15\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. Their method assigns an in-\\nfluence score Jij to every directed pair of exercises i and\\nj, which is the \u001b[0m\n",
       "\u001b[32mconditional probability of correctly answer-\\ning exercise j after correctly answering exercise i in the\\nprevious \u001b[0m\n",
       "\u001b[32mtimestep, normalized by the sum of such condi-\\ntional probabilities. The influence score from i to j \u001b[0m\n",
       "\u001b[32mquan-\\narXiv:2511.03948v1  \u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs.AI\u001b[0m\u001b[32m]\u001b[0m\u001b[32m  6 Nov 2025\\ntifies the prerequisite dependency of the concept i on \u001b[0m\n",
       "\u001b[32mthe\\nlearning concept j. We refer to this method as the DKT\\nmethod.\\nDKT‚Äôs superior performance can be \u001b[0m\n",
       "\u001b[32mattributed\\nto the model‚Äôs ability to learn these influence-based depen-\\ndencies to estimate student knowledge. \u001b[0m\n",
       "\u001b[32mMany studies have\\nincorporated exercise relations into subsequent KT mod-\\nels to improve performance and enhance \u001b[0m\n",
       "\u001b[32minterpretability in\\nthe prediction process.\\nFor example, Hierarchical Graph\\nKnowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHGKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32m17\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mStructure-based Knowl-\\nedge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32m18\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, and Deep Knowledge Tracing with\\n\\n\\n \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAnswer only from retrieval.\u001b[0m\n",
       "\u001b[32mOnly cite sources that are used. Make your response conversational.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33madditional_kwargs\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mresponse_metadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;35mHumanMessage\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;33mcontent\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'I am interested in DKT'\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[1;33madditional_kwargs\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[1;33mresponse_metadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptValue</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">messages</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SystemMessage</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'You are a document chatbot. Help the user as they ask questions about documents. User messaged</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">just asked: Okay thank you. Do you know finding nemo\\n\\n From this, we have retrieved the following </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">potentially-useful info:  Conversation History Retrieval:\\n[Quote from Document] Agent previously responded with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Deep Knowledge Tracing, or DKT, is a method used in the field of education to estimate student knowledge and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learning progression. It\\'s a data-driven approach that uses machine learning algorithms to model students\\' </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mastery of various knowledge components as they interact with corresponding exercises (Extracting Causal Relations </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in Deep Knowledge Tracing, arXiv:2511.03948v1 [cs.AI], November 6, 2025).\\n\\nDKT is known for its ability to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">implicitly infer relationships between exercises, which can be prerequisite dependencies or corequisites. This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">method outperforms traditional techniques like Bayesian Knowledge Tracing (BKT) by representing learning as a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">continuous process influenced by multiple exercise interactions.\\n\\nThe DKT method assigns an influence score Jij </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to every directed pair of exercises i and j, which is the conditional probability of correctly answering exercise j</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">after correctly answering exercise i in the previous timestep. This influence score quantifies the prerequisite </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dependency of the concept i on the learning concept j (Extracting Causal Relations in Deep Knowledge Tracing, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">arXiv:2511.03948v1 [cs.AI], November 6, 2025).\\n\\nDKT has been applied in models like Hierarchical Graph Knowledge </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Tracing (HGKT), Structure-based Knowledge Tracing (SKT), and Deep Knowledge Tracing with Structure, highlighting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the significance of incorporating exercise relations into subsequent KT models for better interpretability in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">prediction process (Extracting Causal Relations in Deep Knowledge Tracing, arXiv:2511.03948v1 [cs.AI], November 6, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2025).\\n\\nIn the paper you mentioned, DKT was trained on data filtered through Directed Acyclic Graphs (DAGs) that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reflect prerequisite relations, improving its predictive performance. The datasets used to train and test the DKT </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model include Assistments 2009, 2012, and 2017, all of which are publicly available and do not contain any personal</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information (Extracting Causal Relations in Deep Knowledge Tracing, arXiv:2511.03948v1 [cs.AI], November 6, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2025).\\n[Quote from Document] User previously responded with I am interested in DKT\\n[Quote from Document] User </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">previously responded with DKT is what!\\n[Quote from Document] Agent previously responded with DKT, or Deep </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Knowledge Tracing, is a method used in the field of education to estimate student knowledge and learning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">progression. It\\'s a data-driven approach that uses machine learning algorithms to model students\\' mastery of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">various knowledge components (KCs) as they interact with corresponding exercises. DKT is known for its ability to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">implicitly infer relationships between exercises, which can be prerequisite dependencies or corequisites. This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">method outperforms traditional techniques like Bayesian Knowledge Tracing (BKT) by representing learning as a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">continuous process influenced by multiple exercise interactions.\\n\\nThe DKT method assigns an influence score Jij </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to every directed pair of exercises i and j, which is the conditional probability of correctly answering exercise j</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">after correctly answering exercise i in the previous timestep. This influence score quantifies the prerequisite </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dependency of the concept i on the learning concept j. The DKT\\'s superior performance is attributed to the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model\\'s ability to learn these influence-based dependencies.\\n\\nTo clarify further, the DKT method is detailed in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the paper \"Extracting Causal Relations in Deep Knowledge Tracing\" (arXiv:2511.03948v1 [cs.AI], November 6, 2025). </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The authors discuss how DKT improves predictive performance when trained on data filtered through Directed Acyclic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Graphs (DAGs) that reflect prerequisite relations. Moreover, DKT has been applied in models like Hierarchical Graph</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Knowledge Tracing (HGKT), Structure-based Knowledge Tracing (SKT), and Deep Knowledge Tracing with Structure, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">highlighting the significance of incorporating exercise relations into subsequent KT models for better </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interpretability in the prediction process.\\n\\n\\n Document Retrieval:\\n[Quote from Extracting Causal Relations in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Deep Knowledge Tracing] gent tutoring systems [9, 11], enables personalizing activities\\nto suit individuals with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">varying levels of proficiency. A key\\ncomponent of these adaptive systems is knowledge tracing\\n(KT), which aims to</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">estimate students‚Äô mastery of several\\nexercise concepts, known as knowledge components (KCs),\\nas they interact </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with the corresponding exercises [2, 5]. For-\\nmally, xi = {et, at} represents a student‚Äôs answer pair, where\\net </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">represents the exercise ID, and at represents whether the\\nstudent answered correctly or incorrectly. Given a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">series of\\npast interactions, X = {x1, x2, . . . , xt} and the next con-\\ncept exercise, et+1, the task of the KT </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model is to estimate\\nthe likelihood of the student answering correctly, at+1 [6].\\nTraditionally, Bayesian </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Knowledge Tracing (BKT) [6] was\\nused to perform KT. Despite its popularity, BKT is often\\ncritiqued for its binary</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">representation of knowledge states\\n(mastered or not mastered) which oversimplifies the learn-\\n[Quote from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks] .\\\\nFor knowledge-intensive generation, we </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">experiment with MS-MARCO [1] and Jeopardy question\\\\ngeneration, and we \\\\ufb01nd that our models generate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">responses that are more factual, speci\\\\ufb01c, and\\\\ndiverse than a BART baseline. For FEVER [56] fact </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">veri\\\\ufb01cation, we achieve results within 4.3% of\\\\nstate-of-the-art pipeline models which use strong retrieval </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">supervision. Finally, we demonstrate that\\\\nthe non-parametric memory can be replaced to update the models\\\\u2019 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge as the world changes.1\\\\n2\\\\nMethods\\\\nWe explore RAG models, which use the input sequence x to retrieve </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">text documents z and use them\\\\nas additional context when generating the target sequence y\\n[Quote from Extracting</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Causal Relations in Deep Knowledge Tracing] ercise relation discovery [15]. Their method assigns an in-\\nfluence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">score Jij to every directed pair of exercises i and\\nj, which is the conditional probability of correctly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">answer-\\ning exercise j after correctly answering exercise i in the\\nprevious timestep, normalized by the sum of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">such condi-\\ntional probabilities. The influence score from i to j quan-\\narXiv:2511.03948v1  [cs.AI]  6 Nov </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2025\\ntifies the prerequisite dependency of the concept i on the\\nlearning concept j. We refer to this method as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the DKT\\nmethod.\\nDKT‚Äôs superior performance can be attributed\\nto the model‚Äôs ability to learn these </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">influence-based depen-\\ndencies to estimate student knowledge. Many studies have\\nincorporated exercise relations </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into subsequent KT mod-\\nels to improve performance and enhance interpretability in\\nthe prediction process.\\nFor </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">example, Hierarchical Graph\\nKnowledge Tracing (HGKT) [17], Structure-based Knowl-\\nedge Tracing (SKT) [18], and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Deep Knowledge Tracing with\\n[Quote from Extracting Causal Relations in Deep Knowledge Tracing] Factors Analysis ‚Äì </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">A General Method for Cognitive\\nModel Evaluation and Improvement. In M. Ikeda,\\nK. D. Ashley, and T.-W. Chan, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">editors, Intelligent\\nTutoring Systems, pages 164‚Äì175, Berlin, Heidelberg,\\n2006. Springer.\\n[5] P. Chen, Y. Lu, V.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">W. Zheng, and Y. Pian.\\nPrerequisite-Driven Deep Knowledge Tracing. In 2018\\nIEEE International Conference on Data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Mining\\n(ICDM), pages 39‚Äì48, Singapore, Nov. 2018. IEEE.\\n[6] A. T. Corbett and J. R. Anderson. Knowledge </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tracing:\\nModeling the acquisition of procedural knowledge.\\nUser Modeling and User-Adapted </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Interaction,\\n4(4):253‚Äì278, Dec. 1994.\\n[7] Z. Duan, X. Dong, H. Gu, X. Wu, Z. Li, and D. Zhou.\\nTowards more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accurate and interpretable model:\\nFusing multiple knowledge relations into deep\\nknowledge tracing. Expert Systems</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with Applications,\\n243:122573, June 2024.\\n[8] M. Feng, N. Heffernan, and K. Koedinger. Addressing\\nthe assessment</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">challenge with an online system that\\ntutors as it assesses. User Modeling and User-Adapted\\n\\n\\n (Answer only from</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retrieval. Only cite sources that are used. Make your response conversational.)'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">additional_kwargs</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response_metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={}</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Okay thank you. Do you know finding nemo'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">additional_kwargs</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response_metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={}</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        )</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ]</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatPromptValue\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;33mmessages\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;35mSystemMessage\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mcontent\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'You are a document chatbot. Help the user as they ask questions about documents. User messaged\u001b[0m\n",
       "\u001b[32mjust asked: Okay thank you. Do you know finding nemo\\n\\n From this, we have retrieved the following \u001b[0m\n",
       "\u001b[32mpotentially-useful info:  Conversation History Retrieval:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Document\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Agent previously responded with \u001b[0m\n",
       "\u001b[32mDeep Knowledge Tracing, or DKT, is a method used in the field of education to estimate student knowledge and \u001b[0m\n",
       "\u001b[32mlearning progression. It\\'s a data-driven approach that uses machine learning algorithms to model students\\' \u001b[0m\n",
       "\u001b[32mmastery of various knowledge components as they interact with corresponding exercises \u001b[0m\u001b[32m(\u001b[0m\u001b[32mExtracting Causal Relations \u001b[0m\n",
       "\u001b[32min Deep Knowledge Tracing, arXiv:2511.03948v1 \u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs.AI\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, November 6, 2025\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\nDKT is known for its ability to \u001b[0m\n",
       "\u001b[32mimplicitly infer relationships between exercises, which can be prerequisite dependencies or corequisites. This \u001b[0m\n",
       "\u001b[32mmethod outperforms traditional techniques like Bayesian Knowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by representing learning as a \u001b[0m\n",
       "\u001b[32mcontinuous process influenced by multiple exercise interactions.\\n\\nThe DKT method assigns an influence score Jij \u001b[0m\n",
       "\u001b[32mto every directed pair of exercises i and j, which is the conditional probability of correctly answering exercise j\u001b[0m\n",
       "\u001b[32mafter correctly answering exercise i in the previous timestep. This influence score quantifies the prerequisite \u001b[0m\n",
       "\u001b[32mdependency of the concept i on the learning concept j \u001b[0m\u001b[32m(\u001b[0m\u001b[32mExtracting Causal Relations in Deep Knowledge Tracing, \u001b[0m\n",
       "\u001b[32marXiv:2511.03948v1 \u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs.AI\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, November 6, 2025\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\nDKT has been applied in models like Hierarchical Graph Knowledge \u001b[0m\n",
       "\u001b[32mTracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHGKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, Structure-based Knowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and Deep Knowledge Tracing with Structure, highlighting \u001b[0m\n",
       "\u001b[32mthe significance of incorporating exercise relations into subsequent KT models for better interpretability in the \u001b[0m\n",
       "\u001b[32mprediction process \u001b[0m\u001b[32m(\u001b[0m\u001b[32mExtracting Causal Relations in Deep Knowledge Tracing, arXiv:2511.03948v1 \u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs.AI\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, November 6, \u001b[0m\n",
       "\u001b[32m2025\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\nIn the paper you mentioned, DKT was trained on data filtered through Directed Acyclic Graphs \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDAGs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m that \u001b[0m\n",
       "\u001b[32mreflect prerequisite relations, improving its predictive performance. The datasets used to train and test the DKT \u001b[0m\n",
       "\u001b[32mmodel include Assistments 2009, 2012, and 2017, all of which are publicly available and do not contain any personal\u001b[0m\n",
       "\u001b[32minformation \u001b[0m\u001b[32m(\u001b[0m\u001b[32mExtracting Causal Relations in Deep Knowledge Tracing, arXiv:2511.03948v1 \u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs.AI\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, November 6, \u001b[0m\n",
       "\u001b[32m2025\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Document\u001b[0m\u001b[32m]\u001b[0m\u001b[32m User previously responded with I am interested in DKT\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Document\u001b[0m\u001b[32m]\u001b[0m\u001b[32m User \u001b[0m\n",
       "\u001b[32mpreviously responded with DKT is what!\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Document\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Agent previously responded with DKT, or Deep \u001b[0m\n",
       "\u001b[32mKnowledge Tracing, is a method used in the field of education to estimate student knowledge and learning \u001b[0m\n",
       "\u001b[32mprogression. It\\'s a data-driven approach that uses machine learning algorithms to model students\\' mastery of \u001b[0m\n",
       "\u001b[32mvarious knowledge components \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKCs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as they interact with corresponding exercises. DKT is known for its ability to \u001b[0m\n",
       "\u001b[32mimplicitly infer relationships between exercises, which can be prerequisite dependencies or corequisites. This \u001b[0m\n",
       "\u001b[32mmethod outperforms traditional techniques like Bayesian Knowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by representing learning as a \u001b[0m\n",
       "\u001b[32mcontinuous process influenced by multiple exercise interactions.\\n\\nThe DKT method assigns an influence score Jij \u001b[0m\n",
       "\u001b[32mto every directed pair of exercises i and j, which is the conditional probability of correctly answering exercise j\u001b[0m\n",
       "\u001b[32mafter correctly answering exercise i in the previous timestep. This influence score quantifies the prerequisite \u001b[0m\n",
       "\u001b[32mdependency of the concept i on the learning concept j. The DKT\\'s superior performance is attributed to the \u001b[0m\n",
       "\u001b[32mmodel\\'s ability to learn these influence-based dependencies.\\n\\nTo clarify further, the DKT method is detailed in \u001b[0m\n",
       "\u001b[32mthe paper \"Extracting Causal Relations in Deep Knowledge Tracing\" \u001b[0m\u001b[32m(\u001b[0m\u001b[32marXiv:2511.03948v1 \u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs.AI\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, November 6, 2025\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. \u001b[0m\n",
       "\u001b[32mThe authors discuss how DKT improves predictive performance when trained on data filtered through Directed Acyclic \u001b[0m\n",
       "\u001b[32mGraphs \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDAGs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m that reflect prerequisite relations. Moreover, DKT has been applied in models like Hierarchical Graph\u001b[0m\n",
       "\u001b[32mKnowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHGKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, Structure-based Knowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and Deep Knowledge Tracing with Structure, \u001b[0m\n",
       "\u001b[32mhighlighting the significance of incorporating exercise relations into subsequent KT models for better \u001b[0m\n",
       "\u001b[32minterpretability in the prediction process.\\n\\n\\n Document Retrieval:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Extracting Causal Relations in \u001b[0m\n",
       "\u001b[32mDeep Knowledge Tracing\u001b[0m\u001b[32m]\u001b[0m\u001b[32m gent tutoring systems \u001b[0m\u001b[32m[\u001b[0m\u001b[32m9, 11\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, enables personalizing activities\\nto suit individuals with \u001b[0m\n",
       "\u001b[32mvarying levels of proficiency. A key\\ncomponent of these adaptive systems is knowledge tracing\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which aims to\u001b[0m\n",
       "\u001b[32mestimate students‚Äô mastery of several\\nexercise concepts, known as knowledge components \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKCs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m,\\nas they interact \u001b[0m\n",
       "\u001b[32mwith the corresponding exercises \u001b[0m\u001b[32m[\u001b[0m\u001b[32m2, 5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. For-\\nmally, xi = \u001b[0m\u001b[32m{\u001b[0m\u001b[32met, at\u001b[0m\u001b[32m}\u001b[0m\u001b[32m represents a student‚Äôs answer pair, where\\net \u001b[0m\n",
       "\u001b[32mrepresents the exercise ID, and at represents whether the\\nstudent answered correctly or incorrectly. Given a \u001b[0m\n",
       "\u001b[32mseries of\\npast interactions, X = \u001b[0m\u001b[32m{\u001b[0m\u001b[32mx1, x2, . . . , xt\u001b[0m\u001b[32m}\u001b[0m\u001b[32m and the next con-\\ncept exercise, et+1, the task of the KT \u001b[0m\n",
       "\u001b[32mmodel is to estimate\\nthe likelihood of the student answering correctly, at+1 \u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m.\\nTraditionally, Bayesian \u001b[0m\n",
       "\u001b[32mKnowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m was\\nused to perform KT. Despite its popularity, BKT is often\\ncritiqued for its binary\u001b[0m\n",
       "\u001b[32mrepresentation of knowledge states\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mmastered or not mastered\u001b[0m\u001b[32m)\u001b[0m\u001b[32m which oversimplifies the learn-\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from \u001b[0m\n",
       "\u001b[32mRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u001b[0m\u001b[32m]\u001b[0m\u001b[32m .\\\\nFor knowledge-intensive generation, we \u001b[0m\n",
       "\u001b[32mexperiment with MS-MARCO \u001b[0m\u001b[32m[\u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m and Jeopardy question\\\\ngeneration, and we \\\\ufb01nd that our models generate \u001b[0m\n",
       "\u001b[32mresponses that are more factual, speci\\\\ufb01c, and\\\\ndiverse than a BART baseline. For FEVER \u001b[0m\u001b[32m[\u001b[0m\u001b[32m56\u001b[0m\u001b[32m]\u001b[0m\u001b[32m fact \u001b[0m\n",
       "\u001b[32mveri\\\\ufb01cation, we achieve results within 4.3% of\\\\nstate-of-the-art pipeline models which use strong retrieval \u001b[0m\n",
       "\u001b[32msupervision. Finally, we demonstrate that\\\\nthe non-parametric memory can be replaced to update the models\\\\u2019 \u001b[0m\n",
       "\u001b[32mknowledge as the world changes.1\\\\n2\\\\nMethods\\\\nWe explore RAG models, which use the input sequence x to retrieve \u001b[0m\n",
       "\u001b[32mtext documents z and use them\\\\nas additional context when generating the target sequence y\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Extracting\u001b[0m\n",
       "\u001b[32mCausal Relations in Deep Knowledge Tracing\u001b[0m\u001b[32m]\u001b[0m\u001b[32m ercise relation discovery \u001b[0m\u001b[32m[\u001b[0m\u001b[32m15\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. Their method assigns an in-\\nfluence \u001b[0m\n",
       "\u001b[32mscore Jij to every directed pair of exercises i and\\nj, which is the conditional probability of correctly \u001b[0m\n",
       "\u001b[32manswer-\\ning exercise j after correctly answering exercise i in the\\nprevious timestep, normalized by the sum of \u001b[0m\n",
       "\u001b[32msuch condi-\\ntional probabilities. The influence score from i to j quan-\\narXiv:2511.03948v1  \u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs.AI\u001b[0m\u001b[32m]\u001b[0m\u001b[32m  6 Nov \u001b[0m\n",
       "\u001b[32m2025\\ntifies the prerequisite dependency of the concept i on the\\nlearning concept j. We refer to this method as \u001b[0m\n",
       "\u001b[32mthe DKT\\nmethod.\\nDKT‚Äôs superior performance can be attributed\\nto the model‚Äôs ability to learn these \u001b[0m\n",
       "\u001b[32minfluence-based depen-\\ndencies to estimate student knowledge. Many studies have\\nincorporated exercise relations \u001b[0m\n",
       "\u001b[32minto subsequent KT mod-\\nels to improve performance and enhance interpretability in\\nthe prediction process.\\nFor \u001b[0m\n",
       "\u001b[32mexample, Hierarchical Graph\\nKnowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHGKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32m17\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, Structure-based Knowl-\\nedge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32m18\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, and \u001b[0m\n",
       "\u001b[32mDeep Knowledge Tracing with\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Extracting Causal Relations in Deep Knowledge Tracing\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Factors Analysis ‚Äì \u001b[0m\n",
       "\u001b[32mA General Method for Cognitive\\nModel Evaluation and Improvement. In M. Ikeda,\\nK. D. Ashley, and T.-W. Chan, \u001b[0m\n",
       "\u001b[32meditors, Intelligent\\nTutoring Systems, pages 164‚Äì175, Berlin, Heidelberg,\\n2006. Springer.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m P. Chen, Y. Lu, V.\u001b[0m\n",
       "\u001b[32mW. Zheng, and Y. Pian.\\nPrerequisite-Driven Deep Knowledge Tracing. In 2018\\nIEEE International Conference on Data \u001b[0m\n",
       "\u001b[32mMining\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mICDM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, pages 39‚Äì48, Singapore, Nov. 2018. IEEE.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m A. T. Corbett and J. R. Anderson. Knowledge \u001b[0m\n",
       "\u001b[32mtracing:\\nModeling the acquisition of procedural knowledge.\\nUser Modeling and User-Adapted \u001b[0m\n",
       "\u001b[32mInteraction,\\n4\u001b[0m\u001b[32m(\u001b[0m\u001b[32m4\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:253‚Äì278, Dec. 1994.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Z. Duan, X. Dong, H. Gu, X. Wu, Z. Li, and D. Zhou.\\nTowards more \u001b[0m\n",
       "\u001b[32maccurate and interpretable model:\\nFusing multiple knowledge relations into deep\\nknowledge tracing. Expert Systems\u001b[0m\n",
       "\u001b[32mwith Applications,\\n243:122573, June 2024.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m8\u001b[0m\u001b[32m]\u001b[0m\u001b[32m M. Feng, N. Heffernan, and K. Koedinger. Addressing\\nthe assessment\u001b[0m\n",
       "\u001b[32mchallenge with an online system that\\ntutors as it assesses. User Modeling and User-Adapted\\n\\n\\n \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAnswer only from\u001b[0m\n",
       "\u001b[32mretrieval. Only cite sources that are used. Make your response conversational.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33madditional_kwargs\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mresponse_metadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;35mHumanMessage\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mcontent\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'Okay thank you. Do you know finding nemo'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33madditional_kwargs\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mresponse_metadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptValue</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">messages</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SystemMessage</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'You are a document chatbot. Help the user as they ask questions about documents. User messaged</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">just asked: Haha, it\\'s not common knowledge. They are people who haven\\'t watched or heard of it\\n\\n From this, we</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">have retrieved the following potentially-useful info:  Conversation History Retrieval:\\n[Quote from Document] User </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">previously responded with Okay thank you. Do you know finding nemo\\n[Quote from Document] User previously responded</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with I am interested in DKT\\n[Quote from Document] Agent previously responded with It seems like you\\'ve asked </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">about \"Finding Nemo\" all of a sudden, without any prior context or relation to the Deep Knowledge Tracing (DKT) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">topic we were discussing. I assume you\\'d like to know more about the movie, \"Finding Nemo.\"\\n\\n\"Finding Nemo\" is a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">popular 2003 computer-animated adventure film produced by Pixar Animation Studios and released by Walt Disney </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Pictures. The film follows the journey of Marlin, a clownfish, who searches for his abducted son, Nemo, across the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">vast ocean. Throughout their adventure, they meet various interesting sea creatures and learn valuable lessons </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">about courage, family, and friendship. The movie was a massive critical and commercial success and has since become</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a modern classic in animation.\\n\\nSources:\\n[Quote from Document] None, as the information provided is common </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge about the movie \"Finding Nemo.\"\\n[Quote from Document] User previously responded with DKT is what!\\n\\n\\n </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Document Retrieval:\\n[Quote from MRKL Systems: A modular, neuro-symbolic architecture that combines large language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models, external knowledge sources and discrete reasoning] . While\\\\nLMs indeed model syntax, and other linguistic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">elements, their most striking feature\\\\nis that they model the world, as described by the data on which they were </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">trained.\\\\n1\\\\narXiv:2205.00445v1  [cs.CL]  1 May 2022\\\\nAnd so really LMs serve as a textual gateway to the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">universe of knowledge [11, 12],\\\\nand perhaps should instead be called \\\\u201clanguage and knowledge\\\\u201d </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models.\\\\nWhen viewed this way, it becomes clear that, despite their value, current LMs\\\\nhave inherent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">limitations. While versatile and impressive, the output of even huge\\\\nLMs is in many cases wrong, and often </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ridiculously so [13]. Here is a sample output\\\\nof GPT-3 on some simple queries. (To be clear, this is not a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">critique of GPT-3 specif-\\\\nically, and other LMs \\\\u2014 including our own Jurassic-1 \\\\u2014 exhibit similar </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">silliness\\n[Quote from Extracting Causal Relations in Deep Knowledge Tracing] W. Luo. pyKT: A Python Library to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Benchmark Deep\\nLearning based Knowledge Tracing Models, Jan. 2023.\\narXiv:2206.11460 [cs].\\n[14] H. Nakagawa, Y. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Iwasawa, and Y. Matsuo.\\nGraph-based Knowledge Tracing: Modeling Student\\nProficiency Using Graph Neural Network. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">In\\nIEEE/WIC/ACM International Conference on Web\\nIntelligence, pages 156‚Äì163, Thessaloniki Greece, Oct.\\n2019. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ACM.\\n[15] C. Piech, J. Spencer, J. Huang, S. Ganguli,\\nM. Sahami, L. Guibas, and J. Sohl-Dickstein. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Deep\\nKnowledge Tracing, June 2015. arXiv:1506.05908 [cs].\\n[16] E. Prihar, Manaal Syed, Korinn Ostrow, S. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Shaw,\\nA. Sales, and N. Heffernan. Exploring Common\\nTrends in Online Educational Experiments. July </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2022.\\nPublisher: Zenodo.\\n[17] H. Tong, Z. Wang, Y. Zhou, S. Tong, W. Han, and\\nQ. Liu. HGKT: Introducing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Hierarchical Exercise\\nGraph for Knowledge Tracing, Aug. 2022.\\narXiv:2006.16915 [cs].\\n[18] S. Tong, Q. Liu, W. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Huang, Z. Hunag, E. Chen,\\nC. Liu, H. Ma, and S. Wang. Structure-Based\\n[Quote from Retrieval-Augmented Generation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for Knowledge-Intensive NLP Tasks] \"Retrieval-Augmented Generation for\\\\nKnowledge-Intensive NLP Tasks\\\\nPatrick </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lewis\\\\u2020\\\\u2021, Ethan Perez\\\\u22c6,\\\\nAleksandra Piktus\\\\u2020, Fabio Petroni\\\\u2020, Vladimir </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Karpukhin\\\\u2020, Naman Goyal\\\\u2020, Heinrich K\\\\u00fcttler\\\\u2020,\\\\nMike Lewis\\\\u2020, Wen-tau Yih\\\\u2020, Tim </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Rockt\\\\u00e4schel\\\\u2020\\\\u2021, Sebastian Riedel\\\\u2020\\\\u2021, Douwe Kiela\\\\u2020\\\\n\\\\u2020Facebook AI Research; </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\u2021University College London; \\\\u22c6New York University;\\\\nplewis@fb.com\\\\nAbstract\\\\nLarge pre-trained </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language models have been shown to store factual knowledge\\\\nin their parameters, and achieve state-of-the-art </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">results when \\\\ufb01ne-tuned on down-\\\\nstream NLP tasks. However, their ability to access and precisely manipulate</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowl-\\\\nedge is still limited, and hence on knowledge-intensive tasks, their performance\\\\nlags behind </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task-speci\\\\ufb01c architectures. Additionally, providing provenance for their\\\\ndecisions and updating their world</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge remain open research problems\\n[Quote from MRKL Systems: A modular, neuro-symbolic architecture that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">combines large language models, external knowledge sources and discrete reasoning] .)\\\\nFor example, LMs can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">struggle to understand that there are no US cities with\\\\nmore than 20m citizens, that a math teacher is a person, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">don\\\\u2019t know what today\\\\u2019s\\\\ndate is, nor can they engage in even simple (e.g., mathematical) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning.\\\\nWhen you look for the root cause, you realize the core limitations of LMs: They\\\\ndon\\\\u2019t have </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">access to all relevant knowledge, and neural models are ill-suited for\\\\ncertain types of calculation. More </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">speci\\\\ufb01cally:\\\\n1. Lack of access to current information. Certain data constantly change \\\\u2013 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the\\\\nexchange rate between the dollar and the Moroccan Dirham, current COVID\\\\nnumbers, the stock price of AAPL, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the weather in Vancouver (OK, not so\\\\nmuch), or even the current date. It\\\\u2019s impossible, by their design, for</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pretrained\\\\nlanguage models to keep up with this dynamic information [14].\\\\n2. Lack of access to proprietary </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information sources\\n\\n\\n (Answer only from retrieval. Only cite sources that are used. Make your response </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conversational.)'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">additional_kwargs</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response_metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={}</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Haha, it's not common knowledge. They are people who haven't watched or heard of it\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">additional_kwargs</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response_metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={}</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        )</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ]</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatPromptValue\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;33mmessages\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;35mSystemMessage\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mcontent\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'You are a document chatbot. Help the user as they ask questions about documents. User messaged\u001b[0m\n",
       "\u001b[32mjust asked: Haha, it\\'s not common knowledge. They are people who haven\\'t watched or heard of it\\n\\n From this, we\u001b[0m\n",
       "\u001b[32mhave retrieved the following potentially-useful info:  Conversation History Retrieval:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Document\u001b[0m\u001b[32m]\u001b[0m\u001b[32m User \u001b[0m\n",
       "\u001b[32mpreviously responded with Okay thank you. Do you know finding nemo\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Document\u001b[0m\u001b[32m]\u001b[0m\u001b[32m User previously responded\u001b[0m\n",
       "\u001b[32mwith I am interested in DKT\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Document\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Agent previously responded with It seems like you\\'ve asked \u001b[0m\n",
       "\u001b[32mabout \"Finding Nemo\" all of a sudden, without any prior context or relation to the Deep Knowledge Tracing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDKT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mtopic we were discussing. I assume you\\'d like to know more about the movie, \"Finding Nemo.\"\\n\\n\"Finding Nemo\" is a\u001b[0m\n",
       "\u001b[32mpopular 2003 computer-animated adventure film produced by Pixar Animation Studios and released by Walt Disney \u001b[0m\n",
       "\u001b[32mPictures. The film follows the journey of Marlin, a clownfish, who searches for his abducted son, Nemo, across the \u001b[0m\n",
       "\u001b[32mvast ocean. Throughout their adventure, they meet various interesting sea creatures and learn valuable lessons \u001b[0m\n",
       "\u001b[32mabout courage, family, and friendship. The movie was a massive critical and commercial success and has since become\u001b[0m\n",
       "\u001b[32ma modern classic in animation.\\n\\nSources:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Document\u001b[0m\u001b[32m]\u001b[0m\u001b[32m None, as the information provided is common \u001b[0m\n",
       "\u001b[32mknowledge about the movie \"Finding Nemo.\"\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Document\u001b[0m\u001b[32m]\u001b[0m\u001b[32m User previously responded with DKT is what!\\n\\n\\n \u001b[0m\n",
       "\u001b[32mDocument Retrieval:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from MRKL Systems: A modular, neuro-symbolic architecture that combines large language \u001b[0m\n",
       "\u001b[32mmodels, external knowledge sources and discrete reasoning\u001b[0m\u001b[32m]\u001b[0m\u001b[32m . While\\\\nLMs indeed model syntax, and other linguistic \u001b[0m\n",
       "\u001b[32melements, their most striking feature\\\\nis that they model the world, as described by the data on which they were \u001b[0m\n",
       "\u001b[32mtrained.\\\\n1\\\\narXiv:2205.00445v1  \u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs.CL\u001b[0m\u001b[32m]\u001b[0m\u001b[32m  1 May 2022\\\\nAnd so really LMs serve as a textual gateway to the \u001b[0m\n",
       "\u001b[32muniverse of knowledge \u001b[0m\u001b[32m[\u001b[0m\u001b[32m11, 12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\\\\nand perhaps should instead be called \\\\u201clanguage and knowledge\\\\u201d \u001b[0m\n",
       "\u001b[32mmodels.\\\\nWhen viewed this way, it becomes clear that, despite their value, current LMs\\\\nhave inherent \u001b[0m\n",
       "\u001b[32mlimitations. While versatile and impressive, the output of even huge\\\\nLMs is in many cases wrong, and often \u001b[0m\n",
       "\u001b[32mridiculously so \u001b[0m\u001b[32m[\u001b[0m\u001b[32m13\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. Here is a sample output\\\\nof GPT-3 on some simple queries. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mTo be clear, this is not a \u001b[0m\n",
       "\u001b[32mcritique of GPT-3 specif-\\\\nically, and other LMs \\\\u2014 including our own Jurassic-1 \\\\u2014 exhibit similar \u001b[0m\n",
       "\u001b[32msilliness\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Extracting Causal Relations in Deep Knowledge Tracing\u001b[0m\u001b[32m]\u001b[0m\u001b[32m W. Luo. pyKT: A Python Library to \u001b[0m\n",
       "\u001b[32mBenchmark Deep\\nLearning based Knowledge Tracing Models, Jan. 2023.\\narXiv:2206.11460 \u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs\u001b[0m\u001b[32m]\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m14\u001b[0m\u001b[32m]\u001b[0m\u001b[32m H. Nakagawa, Y. \u001b[0m\n",
       "\u001b[32mIwasawa, and Y. Matsuo.\\nGraph-based Knowledge Tracing: Modeling Student\\nProficiency Using Graph Neural Network. \u001b[0m\n",
       "\u001b[32mIn\\nIEEE/WIC/ACM International Conference on Web\\nIntelligence, pages 156‚Äì163, Thessaloniki Greece, Oct.\\n2019. \u001b[0m\n",
       "\u001b[32mACM.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m15\u001b[0m\u001b[32m]\u001b[0m\u001b[32m C. Piech, J. Spencer, J. Huang, S. Ganguli,\\nM. Sahami, L. Guibas, and J. Sohl-Dickstein. \u001b[0m\n",
       "\u001b[32mDeep\\nKnowledge Tracing, June 2015. arXiv:1506.05908 \u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs\u001b[0m\u001b[32m]\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m16\u001b[0m\u001b[32m]\u001b[0m\u001b[32m E. Prihar, Manaal Syed, Korinn Ostrow, S. \u001b[0m\n",
       "\u001b[32mShaw,\\nA. Sales, and N. Heffernan. Exploring Common\\nTrends in Online Educational Experiments. July \u001b[0m\n",
       "\u001b[32m2022.\\nPublisher: Zenodo.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m17\u001b[0m\u001b[32m]\u001b[0m\u001b[32m H. Tong, Z. Wang, Y. Zhou, S. Tong, W. Han, and\\nQ. Liu. HGKT: Introducing \u001b[0m\n",
       "\u001b[32mHierarchical Exercise\\nGraph for Knowledge Tracing, Aug. 2022.\\narXiv:2006.16915 \u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs\u001b[0m\u001b[32m]\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m18\u001b[0m\u001b[32m]\u001b[0m\u001b[32m S. Tong, Q. Liu, W. \u001b[0m\n",
       "\u001b[32mHuang, Z. Hunag, E. Chen,\\nC. Liu, H. Ma, and S. Wang. Structure-Based\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Retrieval-Augmented Generation \u001b[0m\n",
       "\u001b[32mfor Knowledge-Intensive NLP Tasks\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \"Retrieval-Augmented Generation for\\\\nKnowledge-Intensive NLP Tasks\\\\nPatrick \u001b[0m\n",
       "\u001b[32mLewis\\\\u2020\\\\u2021, Ethan Perez\\\\u22c6,\\\\nAleksandra Piktus\\\\u2020, Fabio Petroni\\\\u2020, Vladimir \u001b[0m\n",
       "\u001b[32mKarpukhin\\\\u2020, Naman Goyal\\\\u2020, Heinrich K\\\\u00fcttler\\\\u2020,\\\\nMike Lewis\\\\u2020, Wen-tau Yih\\\\u2020, Tim \u001b[0m\n",
       "\u001b[32mRockt\\\\u00e4schel\\\\u2020\\\\u2021, Sebastian Riedel\\\\u2020\\\\u2021, Douwe Kiela\\\\u2020\\\\n\\\\u2020Facebook AI Research; \u001b[0m\n",
       "\u001b[32m\\\\u2021University College London; \\\\u22c6New York University;\\\\nplewis@fb.com\\\\nAbstract\\\\nLarge pre-trained \u001b[0m\n",
       "\u001b[32mlanguage models have been shown to store factual knowledge\\\\nin their parameters, and achieve state-of-the-art \u001b[0m\n",
       "\u001b[32mresults when \\\\ufb01ne-tuned on down-\\\\nstream NLP tasks. However, their ability to access and precisely manipulate\u001b[0m\n",
       "\u001b[32mknowl-\\\\nedge is still limited, and hence on knowledge-intensive tasks, their performance\\\\nlags behind \u001b[0m\n",
       "\u001b[32mtask-speci\\\\ufb01c architectures. Additionally, providing provenance for their\\\\ndecisions and updating their world\u001b[0m\n",
       "\u001b[32mknowledge remain open research problems\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from MRKL Systems: A modular, neuro-symbolic architecture that \u001b[0m\n",
       "\u001b[32mcombines large language models, external knowledge sources and discrete reasoning\u001b[0m\u001b[32m]\u001b[0m\u001b[32m .\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\nFor example, LMs can \u001b[0m\n",
       "\u001b[32mstruggle to understand that there are no US cities with\\\\nmore than 20m citizens, that a math teacher is a person, \u001b[0m\n",
       "\u001b[32mdon\\\\u2019t know what today\\\\u2019s\\\\ndate is, nor can they engage in even simple \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., mathematical\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mreasoning.\\\\nWhen you look for the root cause, you realize the core limitations of LMs: They\\\\ndon\\\\u2019t have \u001b[0m\n",
       "\u001b[32maccess to all relevant knowledge, and neural models are ill-suited for\\\\ncertain types of calculation. More \u001b[0m\n",
       "\u001b[32mspeci\\\\ufb01cally:\\\\n1. Lack of access to current information. Certain data constantly change \\\\u2013 \u001b[0m\n",
       "\u001b[32mthe\\\\nexchange rate between the dollar and the Moroccan Dirham, current COVID\\\\nnumbers, the stock price of AAPL, \u001b[0m\n",
       "\u001b[32mthe weather in Vancouver \u001b[0m\u001b[32m(\u001b[0m\u001b[32mOK, not so\\\\nmuch\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, or even the current date. It\\\\u2019s impossible, by their design, for\u001b[0m\n",
       "\u001b[32mpretrained\\\\nlanguage models to keep up with this dynamic information \u001b[0m\u001b[32m[\u001b[0m\u001b[32m14\u001b[0m\u001b[32m]\u001b[0m\u001b[32m.\\\\n2. Lack of access to proprietary \u001b[0m\n",
       "\u001b[32minformation sources\\n\\n\\n \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAnswer only from retrieval. Only cite sources that are used. Make your response \u001b[0m\n",
       "\u001b[32mconversational.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33madditional_kwargs\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mresponse_metadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;35mHumanMessage\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mcontent\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"Haha\u001b[0m\u001b[32m, it's not common knowledge. They are people who haven't watched or heard of it\"\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33madditional_kwargs\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mresponse_metadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://41821a80a985d60eeb.gradio.live\n",
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "chatbot = gr.Chatbot(value = [[None, initial_msg]])\n",
    "demo = gr.ChatInterface(chat_gen, chatbot=chatbot).queue()\n",
    "\n",
    "try:\n",
    "    demo.launch(debug=True, share=True, show_api=False)\n",
    "    demo.close()\n",
    "except Exception as e:\n",
    "    demo.close()\n",
    "    print(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yCb3RVVfbmQ0",
   "metadata": {
    "id": "yCb3RVVfbmQ0"
   },
   "source": [
    "<br>\n",
    "\n",
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 4:** Saving Your Index For Evaluation\n",
    "\n",
    "After you've implemented your RAG chain, please save your accumulated vector store as shown [in the official documentation](https://python.langchain.com/docs/integrations/vectorstores/faiss#saving-and-loading). You'll have a chance to use it again for your final assessment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "Y4se5wQ4Afda",
   "metadata": {
    "id": "Y4se5wQ4Afda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a docstore_index\n",
      "a docstore_index/index.faiss\n",
      "a docstore_index/index.pkl\n",
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "## Save and compress your index\n",
    "docstore.save_local(\"docstore_index\")\n",
    "!tar czvf docstore_index.tgz docstore_index\n",
    "\n",
    "!rm -rf docstore_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LsI7NivbIgFw",
   "metadata": {
    "id": "LsI7NivbIgFw"
   },
   "source": [
    "If everything was properly saved, the following line can be invoked to pull the index from the compressed `tgz` file (assuming the pip requirements are installed). After you have confirmed that the cell can pull in your index, download `docstore_index.tgz` for use in the last notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "Qs8820ucIu1t",
   "metadata": {
    "id": "Qs8820ucIu1t"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x docstore_index/\n",
      "x docstore_index/index.faiss\n",
      "x docstore_index/index.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mastered or not mastered) which oversimplifies the learn-\n",
      "ing process. Several models were later proposed to address\n",
      "these limitations. Learning Factors Analysis\n",
      "[4] improved\n",
      "upon BKT by representing learning as a continuous pro-\n",
      "cess influenced by multiple exercise interactions and accu-\n",
      "mulated practice. Performance Factors Analysis [10] further\n",
      "captured the complexity of learning by tracking the effects\n",
      "of correct and incorrect prior exercise attempts on perfor-\n",
      "mance. These developments laid the groundwork for Deep\n",
      "Knowledge Tracing (DKT) [15], which popularized a key\n",
      "extension to KT: the ability to implicitly infer relationships\n",
      "between exercises.\n",
      "The relationships between exercises can take the form of\n",
      "prerequisite dependencies, where understanding one exer-\n",
      "cise improves performance on another, or corequisites, where\n",
      "exercises depend on each other. Researchers have demon-\n",
      "strated that exercise relationships can be mapped into an ex-\n"
     ]
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\", truncate=\"END\")\n",
    "!tar xzvf docstore_index.tgz\n",
    "new_db = FAISS.load_local(\"docstore_index\", embedder, allow_dangerous_deserialization=True)\n",
    "docs = new_db.similarity_search(\"DKT\")\n",
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "as_3vWJGKB2F",
   "metadata": {
    "id": "as_3vWJGKB2F"
   },
   "source": [
    "-----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 5:** Wrap-Up\n",
    "\n",
    "Congratulations! Assuming your RAG chain is all good, you're now ready to move on to the **RAG Evaluation [Assessment]** section!\n",
    "\n",
    "### <font color=\"#76b900\">**Great Job!**</font>\n",
    "\n",
    "### **Next Steps:**\n",
    "1. **[Optional]** Revisit the **\"Questions To Think About\" Section** at the top of the notebook and think about some possible answers.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098de2f-32b3-428e-8f3b-f54141ec40b4",
   "metadata": {
    "id": "8098de2f-32b3-428e-8f3b-f54141ec40b4"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/en-us/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
