{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a94a0aa-6b74-4e93-95ce-ee13bc4c06a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "def notebook_to_markdown(path: str = None, notebook: str = None) -> str:\n",
    "    \"\"\"Load a Jupyter notebook from a given path and convert it to Markdown format.\"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        notebook = json.load(file)\n",
    "    markdown_content = []\n",
    "    for cell in notebook['cells']:\n",
    "        if cell['cell_type'] == 'code':          # Combine code into one block\n",
    "            markdown_content += [f'```python\\n{\"\".join(cell[\"source\"])}\\n```']\n",
    "        elif cell['cell_type'] == 'markdown':    # Directly append markdown source\n",
    "            markdown_content += [\"\".join(cell[\"source\"])]\n",
    "        # for output in cell.get('outputs', []):   # Optionally, you can include cell outputs\n",
    "        #     if output['output_type'] == 'stream':\n",
    "        #         markdown_content.append(f'```\\n{\"\".join(output[\"text\"])}\\n```')\n",
    "    return '\\n\\n'.join(markdown_content)\n",
    "\n",
    "def process_files(directory, file_filter):\n",
    "    \"\"\"\n",
    "    Generator that finds, processes, and yields file content.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The directory to scan.\n",
    "        file_filter (callable): A function that returns True if a file should be processed.\n",
    "\n",
    "    Yields:\n",
    "        tuple: (content_type, filename, processed_content)\n",
    "    \"\"\"\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        path = os.path.join(directory, filename)\n",
    "        if os.path.isfile(path) and file_filter(filename):\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            if filename.endswith(\".ipynb\"):\n",
    "                content_type = 'notebook'\n",
    "                processed_content = notebook_to_markdown(path)\n",
    "            elif filename.endswith(\".srt\"):\n",
    "                content_type = 'script'\n",
    "                # Join dialogue, skipping timestamps and indices\n",
    "                processed_content = \" \".join(\n",
    "                    line.strip() for line in lines if not (line.strip().isdigit() or '-->' in line or not line.strip())\n",
    "                )\n",
    "            else:\n",
    "                content_type = 'code'\n",
    "                processed_content = \"\".join(lines)\n",
    "            \n",
    "            yield content_type, filename, processed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bddde3c-1281-4be5-a67b-200e90f0d66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observing Files in /dli/task\n",
      " - Wrote content_notebook.txt\n",
      "Context Generation Complete.\n"
     ]
    }
   ],
   "source": [
    "def combine_and_write_files(group, directory, file_filter=(lambda f: True), orig_path=None):\n",
    "    \"\"\"\n",
    "    Orchestrates the processing and writing of combined files by consuming the generator.\n",
    "    \"\"\"\n",
    "    buffers = defaultdict(str)\n",
    "    file_generator = process_files(directory, file_filter)\n",
    "\n",
    "    # Trivial combining syntax, as requested\n",
    "    orig_path = orig_path or os.path.abspath(directory)\n",
    "    print(f\"Observing Files in {orig_path}\")\n",
    "    for content_type, filename, content in file_generator:\n",
    "        block = f\"################\\n### <FILENAME>{os.path.join(orig_path, filename)}</FILENAME>\\n\\n{content}\\n\\n\"\n",
    "        buffers[f'{group}_{content_type}'] += block\n",
    "        # buffers['combined_context'] += block\n",
    "\n",
    "    # Write final files\n",
    "    for name, content in buffers.items():\n",
    "        with open(f\"{name}.txt\", \"w\", encoding='utf-8') as f:\n",
    "            f.write(content.replace(\"Â \", \" \")) # Replace non-breaking spaces\n",
    "        print(f\" - Wrote {name}.txt\")\n",
    "    print(\"Context Generation Complete.\")\n",
    "\n",
    "non_nb_filter = lambda f: not f.endswith(\".ipynb\")\n",
    "\n",
    "# Run the process\n",
    "combine_and_write_files('content', directory=\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9e7e81-becd-4c59-99a2-9ad6c97ba597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observing Files in /dli/task/composer\n",
      " - Wrote compose_code.txt\n",
      "Context Generation Complete.\n"
     ]
    }
   ],
   "source": [
    "combine_and_write_files('compose', directory=\"..\", file_filter=non_nb_filter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
